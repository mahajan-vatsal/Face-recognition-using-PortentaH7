\chapter{Micro Speech Training}
\hypertarget{md__arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-main_2tensorflow_2lite_6a55a41b5fb6ca08272abc21546efeaa}{}\label{md__arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-main_2tensorflow_2lite_6a55a41b5fb6ca08272abc21546efeaa}\index{Micro Speech Training@{Micro Speech Training}}
\label{md__arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-main_2tensorflow_2lite_6a55a41b5fb6ca08272abc21546efeaa_autotoc_md284}%
\Hypertarget{md__arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-main_2tensorflow_2lite_6a55a41b5fb6ca08272abc21546efeaa_autotoc_md284}%


This example shows how to train a less than 20 kB model that can recognize 2 keywords, "{}yes"{} and "{}no"{}, from speech data.

If the input does not belong to either categories, it is classified as "{}unknown"{} and if the input is silent, it is classified as "{}silence"{}.

You can retrain it to recognize any combination of words (2 or more) from this list\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{yes}
\DoxyCodeLine{no}
\DoxyCodeLine{up}
\DoxyCodeLine{down}
\DoxyCodeLine{left}
\DoxyCodeLine{right}
\DoxyCodeLine{on}
\DoxyCodeLine{off}
\DoxyCodeLine{stop}
\DoxyCodeLine{go}

\end{DoxyCode}


The scripts used in training the model have been sourced from the \href{https://www.tensorflow.org/tutorials/audio/simple_audio}{\texttt{ Simple Audio Recognition}} tutorial.\hypertarget{md__arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-main_2tensorflow_2lite_6a55a41b5fb6ca08272abc21546efeaa_autotoc_md285}{}\doxysection{\texorpdfstring{Table of contents}{Table of contents}}\label{md__arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-main_2tensorflow_2lite_6a55a41b5fb6ca08272abc21546efeaa_autotoc_md285}

\begin{DoxyItemize}
\item Overview
\item Training
\item Trained Models
\item Model Architecture
\item Dataset
\item Preprocessing Speech Input
\item Other Training Methods
\end{DoxyItemize}\hypertarget{md__arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-main_2tensorflow_2lite_6a55a41b5fb6ca08272abc21546efeaa_autotoc_md286}{}\doxysection{\texorpdfstring{Overview}{Overview}}\label{md__arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-main_2tensorflow_2lite_6a55a41b5fb6ca08272abc21546efeaa_autotoc_md286}

\begin{DoxyEnumerate}
\item Dataset\+: Speech Commands, Version 2. (\href{https://storage.cloud.google.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz}{\texttt{ Download Link}}, \href{https://arxiv.org/abs/1804.03209}{\texttt{ Paper}})
\item Dataset Type\+: {\bfseries{Speech}}
\item Deep Learning Framework\+: {\bfseries{Tensor\+Flow 1.\+5}}
\item Language\+: {\bfseries{Python 3.\+7}}
\item Model Size\+: \texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}\texorpdfstring{$<$}{<}20 k\+B\texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}
\item Model Category\+: \texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}\+Multiclass Classification\texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}
\end{DoxyEnumerate}\hypertarget{md__arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-main_2tensorflow_2lite_6a55a41b5fb6ca08272abc21546efeaa_autotoc_md287}{}\doxysection{\texorpdfstring{Training}{Training}}\label{md__arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-main_2tensorflow_2lite_6a55a41b5fb6ca08272abc21546efeaa_autotoc_md287}
Train the model in the cloud using Google Colaboratory or locally using a Jupyter Notebook.

\tabulinesep=1mm
\begin{longtabu}spread 0pt [c]{*{0}{|X[-1]}|}
\hline
\end{longtabu}
\href{https://colab.research.google.com/github/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/examples/micro_speech/train/train_micro_speech_model.ipynb}{\texttt{ Google Colaboratory}}  

\href{https://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/examples/micro_speech/train/train_micro_speech_model.ipynb}{\texttt{ Jupyter Notebook}}  

{\itshape Estimated Training Time\+: \texorpdfstring{$\sim$}{\string~}2 Hours.}

For more options, refer to the Other Training Methods section.\hypertarget{md__arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-main_2tensorflow_2lite_6a55a41b5fb6ca08272abc21546efeaa_autotoc_md288}{}\doxysection{\texorpdfstring{Trained Models}{Trained Models}}\label{md__arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-main_2tensorflow_2lite_6a55a41b5fb6ca08272abc21546efeaa_autotoc_md288}
\texorpdfstring{$\vert$}{|} Download Link \texorpdfstring{$\vert$}{|} \href{https://storage.googleapis.com/download.tensorflow.org/models/tflite/micro/micro_speech_2020_04_13.zip}{\texttt{ speech\+\_\+commands.\+zip}} \texorpdfstring{$\vert$}{|} \texorpdfstring{$\vert$}{|} -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/--- \texorpdfstring{$\vert$}{|}-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---\texorpdfstring{$\vert$}{|}

The {\ttfamily models} directory in the above zip file can be generated by following the instructions in the Training section above. It includes the following 3 model files\+:

\tabulinesep=1mm
\begin{longtabu}spread 0pt [c]{*{4}{|X[-1]}|}
\hline
\cellcolor{\tableheadbgcolor}\textbf{ Name   }&\cellcolor{\tableheadbgcolor}\textbf{ Format   }&\cellcolor{\tableheadbgcolor}\textbf{ Target Framework   }&\cellcolor{\tableheadbgcolor}\textbf{ Target Device    }\\\cline{1-4}
\endfirsthead
\hline
\endfoot
\hline
\cellcolor{\tableheadbgcolor}\textbf{ Name   }&\cellcolor{\tableheadbgcolor}\textbf{ Format   }&\cellcolor{\tableheadbgcolor}\textbf{ Target Framework   }&\cellcolor{\tableheadbgcolor}\textbf{ Target Device    }\\\cline{1-4}
\endhead
{\ttfamily model.\+pb}   &Frozen   &Tensor\+Flow   &Large-\/\+Scale/\+Cloud/\+Servers   \\\cline{1-4}
\end{longtabu}
\+: \+: Graph\+Def \+: \+: \+: \texorpdfstring{$\vert$}{|} {\ttfamily model.\+tflite} \texorpdfstring{$\vert$}{|} Fully \texorpdfstring{$\vert$}{|} Tensor\+Flow Lite \texorpdfstring{$\vert$}{|} Mobile Devices \texorpdfstring{$\vert$}{|} \+: {\itshape (\texorpdfstring{$<$}{<}20 kB)} \+: Quantized\texorpdfstring{$\ast$}{*} \+: \+: \+: \+: \+: TFLite Model \+: \+: \+: \texorpdfstring{$\vert$}{|} {\ttfamily model.\+cc} \texorpdfstring{$\vert$}{|} C Source \texorpdfstring{$\vert$}{|} Tensor\+Flow Lite \texorpdfstring{$\vert$}{|} Microcontrollers \texorpdfstring{$\vert$}{|} \+: \+: File \+: for \+: \+: \+: \+: \+: Microcontrollers \+: \+:

{\bfseries{Fully quantized implies that the model is \texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}strictly int8}} quantized {\bfseries{including}} the \doxylink{_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src5afb18c45f6346167aa977a363205143_a9cebfb3d6ddd692fbdd268cf4b9ad024}{input(s)} and \doxylink{_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcbcd3bbe90c4644d53fde1ce4e312f437_a7a2a916a8059078c2d7a05f46c7126fd}{output(s)}.\texorpdfstring{$\ast$}{*}\hypertarget{md__arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-main_2tensorflow_2lite_6a55a41b5fb6ca08272abc21546efeaa_autotoc_md289}{}\doxysection{\texorpdfstring{Model Architecture}{Model Architecture}}\label{md__arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-main_2tensorflow_2lite_6a55a41b5fb6ca08272abc21546efeaa_autotoc_md289}
This is a simple model comprised of a Convolutional 2D layer, a Fully Connected Layer or a Mat\+Mul Layer (output\+: logits) and a Softmax layer (output\+: probabilities) as shown below. Refer to the \href{https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/speech_commands/models.py\#L673}{\texttt{ {\ttfamily tiny\+\_\+conv}}} model architecture.

\href{../images/micro_speech_quantized.png}{\texttt{ }}

{\itshape This image was derived from visualizing the \textquotesingle{}models/micro\+\_\+speech\+\_\+quantized.\+tflite\textquotesingle{} file in \href{https://github.com/lutzroeder/netron}{\texttt{ Netron}}}

This doesn\textquotesingle{}t produce a highly accurate model, but it\textquotesingle{}s designed to be used as the first stage of a pipeline, running on a low-\/energy piece of hardware that can always be on, and then wake higher-\/power chips when a possible utterance has been found, so that more accurate analysis can be done. Additionally, the model takes in preprocessed speech input as a result of which we can leverage a simpler model for inference results.\hypertarget{md__arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-main_2tensorflow_2lite_6a55a41b5fb6ca08272abc21546efeaa_autotoc_md290}{}\doxysection{\texorpdfstring{Dataset}{Dataset}}\label{md__arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-main_2tensorflow_2lite_6a55a41b5fb6ca08272abc21546efeaa_autotoc_md290}
The Speech Commands Dataset. (\href{https://storage.cloud.google.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz}{\texttt{ Download Link}}, \href{https://arxiv.org/abs/1804.03209}{\texttt{ Paper}}) consists of over 105,000 WAVE audio files of people saying thirty different words. This data was collected by Google and released under a CC BY license. You can help improve it by contributing five minutes of your own voice. The archive is over 2GB, so this part may take a while, but you should see progress logs, and once it\textquotesingle{}s been downloaded you won\textquotesingle{}t need to do this again.\hypertarget{md__arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-main_2tensorflow_2lite_6a55a41b5fb6ca08272abc21546efeaa_autotoc_md291}{}\doxysection{\texorpdfstring{Preprocessing Speech Input}{Preprocessing Speech Input}}\label{md__arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-main_2tensorflow_2lite_6a55a41b5fb6ca08272abc21546efeaa_autotoc_md291}
In this section we discuss spectrograms, the preprocessed speech input to the model.

The model doesn\textquotesingle{}t take in raw audio sample data, instead it works with spectrograms which are two dimensional arrays that are made up of slices of frequency information, each taken from a different time window.

The recipe for creating the spectrogram data is that each frequency slice is created by running an FFT across a 30ms window of the audio sample data. The input samples are treated as being between -\/1 and +1 as real values (encoded as -\/32,768 and 32,767 in 16-\/bit signed integer samples). The audio sampling window stride is 20ms, thus every window overlaps by 10ms.

This results in an FFT with 257 entries. Every sequence of approximately six entries is averaged together, giving a total of 40 frequency buckets in the slice. The results are further processed by down-\/scaling, noise reduction, automatic gain control, and a final down-\/scaling.

Each adjacent frequency entry is stored in ascending memory order (frequency bucket 0 at data\mbox{[}0\mbox{]}, bucket 1 at data\mbox{[}1\mbox{]}, etc). The window for the frequency analysis is then moved forward by 20ms, and the process repeated, storing the results of the new frequency slice in the next memory row. The training is configured for raw audio samples of 1000ms in length. With a window size of 30ms and stride of 20ms, some 49 frequency slices can be created from 1000ms of audio data. Thus, the preprocessing produces a single channel image that is 40 pixels wide, and 49 rows high.\hypertarget{md__arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-main_2tensorflow_2lite_6a55a41b5fb6ca08272abc21546efeaa_autotoc_md292}{}\doxysection{\texorpdfstring{Other Training Methods}{Other Training Methods}}\label{md__arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-main_2tensorflow_2lite_6a55a41b5fb6ca08272abc21546efeaa_autotoc_md292}
\hypertarget{md__arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-main_2tensorflow_2lite_6a55a41b5fb6ca08272abc21546efeaa_autotoc_md293}{}\doxysubsection{\texorpdfstring{Use \href{https://cloud.google.com/}{\texttt{ Google Cloud}}.}{Use \href{https://cloud.google.com/}{\texttt{ Google Cloud}}.}}\label{md__arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-main_2tensorflow_2lite_6a55a41b5fb6ca08272abc21546efeaa_autotoc_md293}
{\itshape Note\+: Google Cloud isn\textquotesingle{}t free. You need to pay depending on how long you use run the VM and what resources you use.}


\begin{DoxyEnumerate}
\item Create a Virtual Machine (VM) using a pre-\/configured Deep Learning VM Image.
\end{DoxyEnumerate}


\begin{DoxyCode}{0}
\DoxyCodeLine{export\ IMAGE\_FAMILY="{}tf-\/latest-\/cpu"{}}
\DoxyCodeLine{export\ ZONE="{}us-\/west1-\/b"{}\ \#\ Or\ any\ other\ required\ region}
\DoxyCodeLine{export\ INSTANCE\_NAME="{}model-\/trainer"{}}
\DoxyCodeLine{export\ INSTANCE\_TYPE="{}n1-\/standard-\/8"{}\ \#\ or\ any\ other\ instance\ type}
\DoxyCodeLine{gcloud\ compute\ instances\ create\ \$INSTANCE\_NAME\ \(\backslash\)}
\DoxyCodeLine{\ \ \ \ \ \ \ \ -\/-\/zone=\$ZONE\ \(\backslash\)}
\DoxyCodeLine{\ \ \ \ \ \ \ \ -\/-\/image-\/family=\$IMAGE\_FAMILY\ \(\backslash\)}
\DoxyCodeLine{\ \ \ \ \ \ \ \ -\/-\/image-\/project=deeplearning-\/platform-\/release\ \(\backslash\)}
\DoxyCodeLine{\ \ \ \ \ \ \ \ -\/-\/machine-\/type=\$INSTANCE\_TYPE\ \(\backslash\)}
\DoxyCodeLine{\ \ \ \ \ \ \ \ -\/-\/boot-\/disk-\/size=120GB\ \(\backslash\)}
\DoxyCodeLine{\ \ \ \ \ \ \ \ -\/-\/min-\/cpu-\/platform=Intel\(\backslash\)\ Skylake}

\end{DoxyCode}



\begin{DoxyEnumerate}
\item As soon as instance has been created you can SSH to it\+:
\end{DoxyEnumerate}


\begin{DoxyCode}{0}
\DoxyCodeLine{gcloud\ compute\ ssh\ "{}jupyter@\$\{INSTANCE\_NAME\}"{}}

\end{DoxyCode}



\begin{DoxyEnumerate}
\item Train a model by following the instructions in the \href{train_micro_speech_model.ipynb}{\texttt{ {\ttfamily train\+\_\+micro\+\_\+speech\+\_\+model.\+ipynb}}} jupyter notebook.
\item Finally, don\textquotesingle{}t forget to remove the instance when training is done\+:
\end{DoxyEnumerate}


\begin{DoxyCode}{0}
\DoxyCodeLine{gcloud\ compute\ instances\ delete\ "{}\$\{INSTANCE\_NAME\}"{}\ -\/-\/zone="{}\$\{ZONE\}"{}}

\end{DoxyCode}
 