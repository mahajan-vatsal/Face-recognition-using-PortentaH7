\doxysection{tflite\+\_\+micro.\+runtime.\+Interpreter\+Config Class Reference}
\hypertarget{classtflite__micro_1_1runtime_1_1_interpreter_config}{}\label{classtflite__micro_1_1runtime_1_1_interpreter_config}\index{tflite\_micro.runtime.InterpreterConfig@{tflite\_micro.runtime.InterpreterConfig}}


Inheritance diagram for tflite\+\_\+micro.\+runtime.\+Interpreter\+Config\+:
% FIG 0


Collaboration diagram for tflite\+\_\+micro.\+runtime.\+Interpreter\+Config\+:
% FIG 1
\doxysubsubsection*{Static Public Attributes}
\begin{DoxyCompactItemize}
\item 
int \mbox{\hyperlink{classtflite__micro_1_1runtime_1_1_interpreter_config_a115204d0c8adb9ef7e998dbef092f2ea}{k\+Allocation\+Recording}} = 0
\item 
int \mbox{\hyperlink{classtflite__micro_1_1runtime_1_1_interpreter_config_a94ae8be90b696730281e64772ae50fd8}{k\+Preserve\+All\+Tensors}} = 1
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
\begin{DoxyVerb}There are two mutually exclusive types of way you could use the TFLM python

interpreter, this enum is made so that users can clearly choose between the
two
different usage method for the interpreter.

The first default way is kRecordingAllocation where all memory usage by the
interpreter is recorded on inference. When using this config the GetTensor()
api is disabled by the interpreter since this interpreter configuration
doesn’t
guarantee that the valid data for all tensors is available post inference.

The second way is kPreserveAllTensors where the GetTensor() api is disabled by
the interpreter since this interpreter configuration doesn’t guarantee that
the
valid data for all tensors is available post inference. But the memory usage
by
the interpreter won’t be recorded on inference.

Usage:

default_interpreter = Interpreter(…
      intrepreter_config=InterpreterConfig.kAllocationRecording)

preserve_interpreter = Interpreter(…
      intrepreter_config=InterpreterConfig.kPreserveAllTensors)
\end{DoxyVerb}
 

\doxysubsection{Member Data Documentation}
\Hypertarget{classtflite__micro_1_1runtime_1_1_interpreter_config_a115204d0c8adb9ef7e998dbef092f2ea}\index{tflite\_micro.runtime.InterpreterConfig@{tflite\_micro.runtime.InterpreterConfig}!kAllocationRecording@{kAllocationRecording}}
\index{kAllocationRecording@{kAllocationRecording}!tflite\_micro.runtime.InterpreterConfig@{tflite\_micro.runtime.InterpreterConfig}}
\doxysubsubsection{\texorpdfstring{kAllocationRecording}{kAllocationRecording}}
{\footnotesize\ttfamily \label{classtflite__micro_1_1runtime_1_1_interpreter_config_a115204d0c8adb9ef7e998dbef092f2ea} 
int tflite\+\_\+micro.\+runtime.\+Interpreter\+Config.\+k\+Allocation\+Recording = 0\hspace{0.3cm}{\ttfamily [static]}}

\Hypertarget{classtflite__micro_1_1runtime_1_1_interpreter_config_a94ae8be90b696730281e64772ae50fd8}\index{tflite\_micro.runtime.InterpreterConfig@{tflite\_micro.runtime.InterpreterConfig}!kPreserveAllTensors@{kPreserveAllTensors}}
\index{kPreserveAllTensors@{kPreserveAllTensors}!tflite\_micro.runtime.InterpreterConfig@{tflite\_micro.runtime.InterpreterConfig}}
\doxysubsubsection{\texorpdfstring{kPreserveAllTensors}{kPreserveAllTensors}}
{\footnotesize\ttfamily \label{classtflite__micro_1_1runtime_1_1_interpreter_config_a94ae8be90b696730281e64772ae50fd8} 
int tflite\+\_\+micro.\+runtime.\+Interpreter\+Config.\+k\+Preserve\+All\+Tensors = 1\hspace{0.3cm}{\ttfamily [static]}}



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
Arduino/\+Get\+Started\+With\+Machine\+Learning\+On\+Arduino/tflite-\/micro-\/main/python/tflite\+\_\+micro/\mbox{\hyperlink{python_2tflite__micro_2runtime_8py}{runtime.\+py}}\end{DoxyCompactItemize}
