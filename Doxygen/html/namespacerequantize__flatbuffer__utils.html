<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.12.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Machine Vision using Portenta H7: requantize_flatbuffer_utils Namespace Reference</title>
<link rel="icon" href="logo.png" type="image/x-icon" />
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="logo.png"/></td>
  <td id="projectalign">
   <div id="projectname">Machine Vision using Portenta H7<span id="projectnumber">&#160;2</span>
   </div>
   <div id="projectbrief">This project aims to develop a face recognition-based access control system using the Arduino Portenta H7 and Vision Shield, leveraging Edge Impulse for machine learning. The system captures facial images, processes them locally using an AI model deployed on the Portenta H7 and determines access based on authorised personnel.</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.12.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search',false);
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){ initResizable(false); });
/* @license-end */
</script>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

</div><!-- top -->
<div id="doc-content">
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle"><div class="title">requantize_flatbuffer_utils Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a9a2761897d1c77f64f3841a5d58d2aa3" id="r_a9a2761897d1c77f64f3841a5d58d2aa3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a9a2761897d1c77f64f3841a5d58d2aa3">clip_range</a> (vals, bit_width)</td></tr>
<tr class="separator:a9a2761897d1c77f64f3841a5d58d2aa3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1c2346cfe1796ca04dce2fc3cfc4ac23" id="r_a1c2346cfe1796ca04dce2fc3cfc4ac23"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a1c2346cfe1796ca04dce2fc3cfc4ac23">quantize_data</a> (<a class="el" href="hello__world__model_8cc.html#ab2a9259b73b53c0bb06a6b242aa7ae32">data</a>, <a class="el" href="batch__matmul__test_8cc.html#ab89fe30f475eefcbf59653d919c456bd">scale</a>, <a class="el" href="batch__matmul__test_8cc.html#a26c07acd3fa6a6da13ddae2bc5c64b55">zero_point</a>=0, bit_width=8)</td></tr>
<tr class="separator:a1c2346cfe1796ca04dce2fc3cfc4ac23"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6dcdea4167683c4d80a88529ffe69b2d" id="r_a6dcdea4167683c4d80a88529ffe69b2d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a6dcdea4167683c4d80a88529ffe69b2d">dequantize_data</a> (<a class="el" href="batch__matmul__test_8cc.html#a960b49b4072eb4f96ad154be724c49f5">quantized_data</a>, <a class="el" href="batch__matmul__test_8cc.html#ab89fe30f475eefcbf59653d919c456bd">scale</a>, <a class="el" href="batch__matmul__test_8cc.html#a26c07acd3fa6a6da13ddae2bc5c64b55">zero_point</a>=0)</td></tr>
<tr class="separator:a6dcdea4167683c4d80a88529ffe69b2d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af319647e1813bb96fc223e5f8ee411ac" id="r_af319647e1813bb96fc223e5f8ee411ac"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#af319647e1813bb96fc223e5f8ee411ac">change_quantization_settings_8to16</a> (tensor, buffers)</td></tr>
<tr class="separator:af319647e1813bb96fc223e5f8ee411ac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0ce427fb53c2d4f8f3f32bf4cb00c62c" id="r_a0ce427fb53c2d4f8f3f32bf4cb00c62c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a0ce427fb53c2d4f8f3f32bf4cb00c62c">change_activation_tensor_8to16</a> (tensor, buffers)</td></tr>
<tr class="separator:a0ce427fb53c2d4f8f3f32bf4cb00c62c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0cc731ff9a3e83da646a86385b10797a" id="r_a0cc731ff9a3e83da646a86385b10797a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a0cc731ff9a3e83da646a86385b10797a">requantize_bias_perlayer</a> (buffers, <a class="el" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src5afb18c45f6346167aa977a363205143.html#a9cebfb3d6ddd692fbdd268cf4b9ad024">input</a>, weight, bias)</td></tr>
<tr class="separator:a0cc731ff9a3e83da646a86385b10797a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a82dff25704dcb7aedd82960bf874c83c" id="r_a82dff25704dcb7aedd82960bf874c83c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a82dff25704dcb7aedd82960bf874c83c">requantize_bias_perchannel</a> (buffers, <a class="el" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src5afb18c45f6346167aa977a363205143.html#a9cebfb3d6ddd692fbdd268cf4b9ad024">input</a>, weight, bias)</td></tr>
<tr class="separator:a82dff25704dcb7aedd82960bf874c83c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5650c4de90e9d4816234a38421daf886" id="r_a5650c4de90e9d4816234a38421daf886"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a5650c4de90e9d4816234a38421daf886">set_bias_type_int64</a> (buffers, <a class="el" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src5afb18c45f6346167aa977a363205143.html#a9cebfb3d6ddd692fbdd268cf4b9ad024">input</a>, weight, bias)</td></tr>
<tr class="separator:a5650c4de90e9d4816234a38421daf886"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa3634fe39cf80e569c92df4929a1b8da" id="r_aa3634fe39cf80e569c92df4929a1b8da"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aa3634fe39cf80e569c92df4929a1b8da">requantize_fully_connected</a> (tensors, buffers, op)</td></tr>
<tr class="separator:aa3634fe39cf80e569c92df4929a1b8da"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4f8c97c80ef027d3d95437db4a501cf1" id="r_a4f8c97c80ef027d3d95437db4a501cf1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a4f8c97c80ef027d3d95437db4a501cf1">requantize_unidirectional_sequence_lstm</a> (tensors, buffers, op)</td></tr>
<tr class="separator:a4f8c97c80ef027d3d95437db4a501cf1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aac7d4ab56ee2bc46701c46af21011eec" id="r_aac7d4ab56ee2bc46701c46af21011eec"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aac7d4ab56ee2bc46701c46af21011eec">requantize_softmax</a> (tensors, buffers, op)</td></tr>
<tr class="separator:aac7d4ab56ee2bc46701c46af21011eec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4734a738b574eac95fc5035c537fe9ec" id="r_a4734a738b574eac95fc5035c537fe9ec"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a4734a738b574eac95fc5035c537fe9ec">requantize_transpose_conv</a> (tensors, buffers, op)</td></tr>
<tr class="separator:a4734a738b574eac95fc5035c537fe9ec"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="var-members" name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:ad62c000900d25f5de9560d35a0888f7e" id="r_ad62c000900d25f5de9560d35a0888f7e"><td class="memItemLeft" align="right" valign="top">dict&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ad62c000900d25f5de9560d35a0888f7e">TENSOR_CODE_TYPE</a></td></tr>
<tr class="separator:ad62c000900d25f5de9560d35a0888f7e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a32136596a1c56ecf92d926fb3a028a90" id="r_a32136596a1c56ecf92d926fb3a028a90"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a32136596a1c56ecf92d926fb3a028a90">TENSOR_TYPE_CODE</a> = dict((reversed(item) <a class="el" href="ei__fill__result__struct_8h.html#aed2288439daacb76715d34eb9d10e627">for</a> item in TENSOR_CODE_TYPE.items()))</td></tr>
<tr class="separator:a32136596a1c56ecf92d926fb3a028a90"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Function Documentation</h2>
<a id="a0ce427fb53c2d4f8f3f32bf4cb00c62c" name="a0ce427fb53c2d4f8f3f32bf4cb00c62c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0ce427fb53c2d4f8f3f32bf4cb00c62c">&#9670;&#160;</a></span>change_activation_tensor_8to16()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">requantize_flatbuffer_utils.change_activation_tensor_8to16 </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>buffers</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Change the quantization setting of a activation tensor from int8 to int16</pre> 
</div>
</div>
<a id="af319647e1813bb96fc223e5f8ee411ac" name="af319647e1813bb96fc223e5f8ee411ac"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af319647e1813bb96fc223e5f8ee411ac">&#9670;&#160;</a></span>change_quantization_settings_8to16()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">requantize_flatbuffer_utils.change_quantization_settings_8to16 </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>buffers</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Change the quantization seeting of the tensor from int8 to int16</pre> 
</div>
</div>
<a id="a9a2761897d1c77f64f3841a5d58d2aa3" name="a9a2761897d1c77f64f3841a5d58d2aa3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9a2761897d1c77f64f3841a5d58d2aa3">&#9670;&#160;</a></span>clip_range()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">requantize_flatbuffer_utils.clip_range </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>vals</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>bit_width</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Mimic integer calculation.

Clip the range of vals based on bit width.

e.g., clip_range([300], 8) = [127] since int8 have range [-128, 127]

Args:
    vals (np.array): float representation of the integer values
    bit_width (int): number of desired bits for vals

Returns:
    np.array : clipped vals
</pre> 
</div>
</div>
<a id="a6dcdea4167683c4d80a88529ffe69b2d" name="a6dcdea4167683c4d80a88529ffe69b2d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6dcdea4167683c4d80a88529ffe69b2d">&#9670;&#160;</a></span>dequantize_data()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">requantize_flatbuffer_utils.dequantize_data </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>quantized_data</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>zero_point</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Dequantize the data to integer type with desired bit width.

Args:
    quantized_data (np.array): quantized data
    scale (float): quantization scale of the data
    zero_point (integer): quantization zero point of the data

Returns:
    np.array : dequantized data
</pre> 
</div>
</div>
<a id="a1c2346cfe1796ca04dce2fc3cfc4ac23" name="a1c2346cfe1796ca04dce2fc3cfc4ac23"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1c2346cfe1796ca04dce2fc3cfc4ac23">&#9670;&#160;</a></span>quantize_data()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">requantize_flatbuffer_utils.quantize_data </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>data</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>zero_point</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>bit_width</em></span><span class="paramdefsep"> = </span><span class="paramdefval">8</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Quantize the data to integer type with desired bit width.

The quantized data is represented using float since integer calculation in
numpy may differ from other implementations (e.g., no integer saturation
protection in numpy)

Args:
    data (np.array): float data
    scale (float): quantization scale of the data
    zero_point (integer): quantization zero point of the data
    bit_width (int): number of representative bits for vals

Returns:
    np.array : quantized data in float but clipped range
</pre> 
</div>
</div>
<a id="a82dff25704dcb7aedd82960bf874c83c" name="a82dff25704dcb7aedd82960bf874c83c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a82dff25704dcb7aedd82960bf874c83c">&#9670;&#160;</a></span>requantize_bias_perchannel()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">requantize_flatbuffer_utils.requantize_bias_perchannel </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>buffers</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>input</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>bias</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Bias is channel wise quantized. Requantize bias one by one </pre> 
</div>
</div>
<a id="a0cc731ff9a3e83da646a86385b10797a" name="a0cc731ff9a3e83da646a86385b10797a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0cc731ff9a3e83da646a86385b10797a">&#9670;&#160;</a></span>requantize_bias_perlayer()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">requantize_flatbuffer_utils.requantize_bias_perlayer </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>buffers</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>input</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>bias</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Bias is layer wise quantized </pre> 
</div>
</div>
<a id="aa3634fe39cf80e569c92df4929a1b8da" name="aa3634fe39cf80e569c92df4929a1b8da"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa3634fe39cf80e569c92df4929a1b8da">&#9670;&#160;</a></span>requantize_fully_connected()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">requantize_flatbuffer_utils.requantize_fully_connected </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>tensors</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>buffers</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>op</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Requantize the fully connected op from int8 to int16

Note: CONV_2D and DEPTHWISE_CONV_2D also use this requantize function since they all share the same input/weight/bias configuration. 
See tensorflow/lite/micro/kernels/fully_connected_common.cc
tflite_micro/tensorflow/lite/micro/kernels/depthwise_conv_common.cc
tflite_micro/tensorflow/lite/micro/kernels/conv_common.cc
</pre> 
</div>
</div>
<a id="aac7d4ab56ee2bc46701c46af21011eec" name="aac7d4ab56ee2bc46701c46af21011eec"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aac7d4ab56ee2bc46701c46af21011eec">&#9670;&#160;</a></span>requantize_softmax()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">requantize_flatbuffer_utils.requantize_softmax </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>tensors</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>buffers</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>op</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Requantize the softmax op from int8 to int16</pre> 
</div>
</div>
<a id="a4734a738b574eac95fc5035c537fe9ec" name="a4734a738b574eac95fc5035c537fe9ec"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4734a738b574eac95fc5035c537fe9ec">&#9670;&#160;</a></span>requantize_transpose_conv()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">requantize_flatbuffer_utils.requantize_transpose_conv </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>tensors</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>buffers</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>op</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Requantize the transpose conv op from int8 to int16</pre> 
</div>
</div>
<a id="a4f8c97c80ef027d3d95437db4a501cf1" name="a4f8c97c80ef027d3d95437db4a501cf1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4f8c97c80ef027d3d95437db4a501cf1">&#9670;&#160;</a></span>requantize_unidirectional_sequence_lstm()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">requantize_flatbuffer_utils.requantize_unidirectional_sequence_lstm </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>tensors</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>buffers</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>op</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Requantize the unidirectonal sequance lstm op from int8 to int16 </pre> 
</div>
</div>
<a id="a5650c4de90e9d4816234a38421daf886" name="a5650c4de90e9d4816234a38421daf886"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5650c4de90e9d4816234a38421daf886">&#9670;&#160;</a></span>set_bias_type_int64()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">requantize_flatbuffer_utils.set_bias_type_int64 </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>buffers</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>input</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>bias</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Set the bias tensor quantization setting from int32 to int64

Args:
    buffers (list): buffers for the model 
    input (Tensor): the corresponding input tensor for the bias
    weight (Tensor): the corresponding weight tensor for the bias
    bias (Tensor): the bias tensor that need to be modified
</pre> 
</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="ad62c000900d25f5de9560d35a0888f7e" name="ad62c000900d25f5de9560d35a0888f7e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad62c000900d25f5de9560d35a0888f7e">&#9670;&#160;</a></span>TENSOR_CODE_TYPE</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">dict requantize_flatbuffer_utils.TENSOR_CODE_TYPE</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"><span class="lineno">    1</span>=  {</div>
<div class="line"><span class="lineno">    2</span>    TensorType.FLOAT32: np.float32,</div>
<div class="line"><span class="lineno">    3</span>    TensorType.FLOAT16: np.float16,</div>
<div class="line"><span class="lineno">    4</span>    TensorType.INT32: np.int32,</div>
<div class="line"><span class="lineno">    5</span>    TensorType.UINT8: np.uint8,</div>
<div class="line"><span class="lineno">    6</span>    TensorType.INT64: np.int64,</div>
<div class="line"><span class="lineno">    7</span>    TensorType.STRING: np.string_,</div>
<div class="line"><span class="lineno">    8</span>    TensorType.BOOL: np.bool_,</div>
<div class="line"><span class="lineno">    9</span>    TensorType.INT16: np.int16,</div>
<div class="line"><span class="lineno">   10</span>    TensorType.COMPLEX64: np.complex64,</div>
<div class="line"><span class="lineno">   11</span>    TensorType.INT8: np.int8,</div>
<div class="line"><span class="lineno">   12</span>    TensorType.FLOAT64: np.float64,</div>
<div class="line"><span class="lineno">   13</span>    TensorType.COMPLEX128: np.complex128,</div>
<div class="line"><span class="lineno">   14</span>    TensorType.UINT64: np.uint64,</div>
<div class="line"><span class="lineno">   15</span>    TensorType.RESOURCE: <span class="stringliteral">&quot;RESOURCE&quot;</span>,</div>
<div class="line"><span class="lineno">   16</span>    TensorType.VARIANT: <span class="stringliteral">&quot;VARIANT&quot;</span>,</div>
<div class="line"><span class="lineno">   17</span>    TensorType.UINT32: np.uint32,</div>
<div class="line"><span class="lineno">   18</span>    TensorType.UINT16: np.uint16,</div>
<div class="line"><span class="lineno">   19</span>    TensorType.INT4: <span class="stringliteral">&quot;INT4&quot;</span>,</div>
<div class="line"><span class="lineno">   20</span>}</div>
</div><!-- fragment -->
</div>
</div>
<a id="a32136596a1c56ecf92d926fb3a028a90" name="a32136596a1c56ecf92d926fb3a028a90"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a32136596a1c56ecf92d926fb3a028a90">&#9670;&#160;</a></span>TENSOR_TYPE_CODE</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">requantize_flatbuffer_utils.TENSOR_TYPE_CODE = dict((reversed(item) <a class="el" href="ei__fill__result__struct_8h.html#aed2288439daacb76715d34eb9d10e627">for</a> item in TENSOR_CODE_TYPE.items()))</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.12.0
</small></address>
</div><!-- doc-content -->
</body>
</html>
