<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.12.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Machine Vision using Portenta H7: online_memory_allocation_overview</title>
<link rel="icon" href="logo.png" type="image/x-icon" />
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="logo.png"/></td>
  <td id="projectalign">
   <div id="projectname">Machine Vision using Portenta H7<span id="projectnumber">&#160;2</span>
   </div>
   <div id="projectbrief">This project aims to develop a face recognition-based access control system using the Arduino Portenta H7 and Vision Shield, leveraging Edge Impulse for machine learning. The system captures facial images, processes them locally using an AI model deployed on the Portenta H7 and determines access based on authorised personnel.</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.12.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search',false);
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){ initResizable(false); });
/* @license-end */
</script>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

</div><!-- top -->
<div id="doc-content">
<div><div class="header">
  <div class="headertitle"><div class="title">online_memory_allocation_overview</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><ul>
<li>Online Memory Allocation Overview in TensorFlow Lite Micro<ul>
<li>Arena</li>
<li>Existing buffers in the flatbuffer</li>
<li>Model Init Phase</li>
<li>Model Prepare Phase</li>
<li>Finish Model Allocation Phase</li>
</ul>
</li>
</ul>
<h1><a class="anchor" id="autotoc_md181"></a>
Online Memory Allocation Overview in TensorFlow Lite Micro</h1>
<p>This document outlines how "online" memory is managed in TensorFlow Lite Micro (TFLM).</p>
<h2><a class="anchor" id="autotoc_md182"></a>
Arena</h2>
<p>Online memory planning strategically places allocations in a single <code>uint8_t</code> buffer array. The buffer is split into two main sections: the “head” and the “tail”. Generally, non-persistent allocations are placed in the “head” and persistent allocations are placed in the “tail”. More details about the arena can be <a href="memory_management.md#tensor-arena">found here</a>.</p>
<h2><a class="anchor" id="autotoc_md183"></a>
Existing buffers in the flatbuffer</h2>
<p>The TFLite flatbuffer model contains a variety of information required to run a model in TFLite or TFLM. The TFLM online memory planner will walk the main subgraph and find all tensors required for the model (represented as <code><a class="el" href="struct_tf_lite_tensor.html">TfLiteTensor</a></code> and <code><a class="el" href="struct_tf_lite_eval_tensor.html">TfLiteEvalTensor</a></code> C structs at runtime). Persistent tensors in the flatbuffer (e.g. weight tensors) will point at a buffer inlined in the flatbuffer. These buffers are reused during online memory planning. The corresponding C structures will point back at the buffer packed into the flatbuffer.</p>
<h2><a class="anchor" id="autotoc_md184"></a>
Model Init Phase</h2>
<p>Either through the first call of <code>MicroInterpreter::Invoke()</code> or an explicit call to <code>MicroInterpreter::AllocateTensors()</code> the online model allocation will begin. The <code>MicroInterpreter</code> instance will invoke <code>MicroAllocator::StartModelAllocation()</code>. This function will begin pulling data out of the serialized flatbuffer and begin walking through the main subgraph.</p>
<p>The method <code>MicroAllocator::StartModelAllocation()</code> begins allocation in the following order:</p><ul>
<li>Initializes internal state for scratch buffer allocations</li>
<li>Allocates a list of <code><a class="el" href="struct_tf_lite_eval_tensor.html">TfLiteEvalTensor</a></code> C structs based on the number of tensors in the subgraph.</li>
<li>Allocations are persistent and stored in the tail section.</li>
<li>Tensors that reference buffers in the flatbuffer are assigned at this point.</li>
<li>Allocates a list of <code><a class="el" href="struct_tf_lite_registration.html">TfLiteRegistration</a></code> and <code><a class="el" href="struct_tf_lite_node.html">TfLiteNode</a></code> C structs for every operator in the model subgraph</li>
<li>Allocations are persistent and stored in the tail section.</li>
<li>Walks back through the list of subgraph operators and assigns all C structs with relevant information from the flatbuffer.</li>
</ul>
<p>At the conclusion of this phase, the operator kernel implementations are ready for calls to the <code><a class="el" href="struct_tf_lite_registration.html#af9f2e4b18f45f23a6d41c1896389f337">TfLiteRegistration::init()</a></code> function. The <code>MicroInterpreter</code> walks through the operator list and invokes all operator implementations that have this function. Typically, operator implementations return the object to store in the <code>user_data</code> field of a <code><a class="el" href="struct_tf_lite_node.html">TfLiteNode</a></code> struct.</p>
<h2><a class="anchor" id="autotoc_md185"></a>
Model Prepare Phase</h2>
<p>After the interpreter has initialized all operator kernels, another pass through the subgraph is done. This time, each operator implementations that provides a <code><a class="el" href="struct_tf_lite_registration.html#a6ecffde4e6466f86aa8f28d25de553d7">TfLiteRegistration::prepare()</a></code> function is called. This phase in TFLM is used for kernels to verify capabilities from model information, validate shapes, allocate any scratch buffers requested (through <code><a class="el" href="struct_tf_lite_context.html#a79a5ae043ca55b703fe6f4cf8c571217">TfLiteContext::GetScratchBuffer()</a></code>), and calculate quantization runtime data.</p>
<p>At this time, operator implementation will request tensor data through the <code><a class="el" href="struct_tf_lite_tensor.html">TfLiteTensor</a></code> C struct. This struct is heavier and contains more information that operators will need during this phase of initialization. Internally, TFLM will allocate these instances per request in the temp section. The temp section is the space between the head and the tail in the arena. During the prepare phase, nothing is yet been placed in the head section. This extra space between the head and tail is used to allocate buffers that are available until <code>MicroAllocator::ResetTempAllocations()</code> is called. Additional information <a href="memory_management.md#temporary-section">available here</a>.</p>
<p>NOTE: The <code><a class="el" href="struct_tf_lite_tensor.html">TfLiteTensor</a></code> struct is only available in TFLM during <code><a class="el" href="struct_tf_lite_registration.html#a6ecffde4e6466f86aa8f28d25de553d7">TfLiteRegistration::prepare()</a></code>, after this allocation phase tensor data can only be accessed via a <code><a class="el" href="struct_tf_lite_eval_tensor.html">TfLiteEvalTensor</a></code> struct.</p>
<p>Additionally, at this time each operator implementation may request scratch buffer requests through <code><a class="el" href="struct_tf_lite_context.html#a7a3778903dc181d98fe1f10a4f6e15c9">TfLiteContext::RequestScratchBufferInArena()</a></code>. These requests are limited to <code>kMaxScratchBuffersPerOp</code> and are stored in an instance variable for each operator prepare block. All requests are eventually moved to the head section when the interpreter moves to the next operator.</p>
<p>After each call to <code><a class="el" href="struct_tf_lite_registration.html#a6ecffde4e6466f86aa8f28d25de553d7">TfLiteRegistration::prepare()</a></code> the <code>MicroInterpreter</code> calls <code>MicroAllocator::FinishPrepareNodeAllocations()</code>. This method resets temp allocations and begins to store all scratch buffer requests inside the head section of the arena.</p>
<p>After all operators have been prepared, the <code>MicroInterpreter</code> calls <code>MicroAllocator::FinishModelAllocation()</code> to begin finalizing the online memory plan.</p>
<h2><a class="anchor" id="autotoc_md186"></a>
Finish Model Allocation Phase</h2>
<p>The last phase of online memory planning is handled in <code>MicroAllocator::FinishModelAllocation()</code>. This function performs the following tasks</p>
<ul>
<li>Allocates space in the tail for all persistent buffer requests that are currently in the head.</li>
<li>Commits Static Memory Plan<ul>
<li>Uses the <code>GreedyMemoryPlanner</code> to optimize the non-persistent space in the head.</li>
<li>Optimizes for the operator that requires the largest byte-width buffer.</li>
<li>Allocates pointers in the tail that provide pointers into shared space and offsets in the head.</li>
<li>Sets the size of the head based on the result of <code>GreedyMemoryPlanner::GetMaxiumMemorySize()</code>.</li>
</ul>
</li>
<li>Allocates variable tensor buffers in the tail section.</li>
</ul>
<p>Once TFLM has finalized online model allocation, all buffers are prepared and ready for optimal speed for inference. The system no longer enables operator implementations to allocate scratch buffers after this point. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.12.0
</small></address>
</div><!-- doc-content -->
</body>
</html>
