<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.12.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Machine Vision using Portenta H7: Magic Wand</title>
<link rel="icon" href="logo.png" type="image/x-icon" />
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="logo.png"/></td>
  <td id="projectalign">
   <div id="projectname">Machine Vision using Portenta H7<span id="projectnumber">&#160;2</span>
   </div>
   <div id="projectbrief">This project aims to develop a face recognition-based access control system using the Arduino Portenta H7 and Vision Shield, leveraging Edge Impulse for machine learning. The system captures facial images, processes them locally using an AI model deployed on the Portenta H7 and determines access based on authorised personnel.</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.12.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search',false);
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){ initResizable(false); });
/* @license-end */
</script>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

</div><!-- top -->
<div id="doc-content">
<div><div class="header">
  <div class="headertitle"><div class="title">Magic Wand</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="autotoc_md5"></a></p>
<p>Magic Wand example for <a href="https://www.tensorflow.org/lite/microcontrollers">TensorFlow Lite Micro</a> on the <a href="https://store-usa.arduino.cc/products/arduino-nano-33-ble-sense">Arduino Nano 33 BLE Sense</a>.</p>
<h1><a class="anchor" id="autotoc_md6"></a>
Table of contents</h1>
<ul>
<li>Introduction</li>
<li>Hardware Requirements</li>
<li>Installing the Sketch<ul>
<li>Arduino Desktop IDE</li>
</ul>
</li>
<li>Building the Wand</li>
<li>Using the wand</li>
<li>Viewing Gestures in the Browser</li>
<li>Pretrained Model</li>
<li>Recording Gestures</li>
<li>Training</li>
<li>Deployment</li>
</ul>
<h1><a class="anchor" id="autotoc_md7"></a>
Introduction</h1>
<p>This project shows you how to recognize gestures made by waving a magic wand, using machine learning to analyze accelerometer and gyroscope data. It demonstrates the three main stages of an end-to-end machine learning project:</p>
<ul>
<li><b>Gathering Data</b>. Using a Bluetooth connection to a web page, you can capture gestures, label them, and download the results.</li>
<li><b>Training</b>. A Python notebook on the free Colab service shows how to use TensorFlow to train a model to recognize gestures from your data.</li>
<li><b>Deployment</b>. You can deploy your trained model to the Arduino board using TensorFlow Lite Micro and the Arduino IDE.</li>
</ul>
<h1><a class="anchor" id="autotoc_md8"></a>
Hardware Requirements</h1>
<p>You'll need the following:</p>
<ul>
<li>Arduino Nano 33 BLE Sense board. These are available as part of <a href="https://store-usa.arduino.cc/products/arduino-tiny-machine-learning-kit">the TinyML Starter Kit</a>, or separately from Arduino or resellers. Other Arduinos won't work unfortunately, because the Bluetooth and sensor code rely on accessing the particular hardware of the Nano 33 BLE Sense.</li>
<li>MicroUSB cable. This is included in the TinyML Kit, but you'll need a USB-A adaptor too if your computer only has USB-C ports.</li>
<li>Computer. The Arduino toolchain runs on Linux, Windows, and MacOS, so you should be able to use most laptops, desktops, or even a Raspberry Pi. For the training process, you'll also need an up-to-date version of the Chrome web browser so you can use the Web Bluetooth APIs.</li>
<li>Stick. We'll be attaching your Arduino to a 'wand', but this can be practically anything, as long as it's roughly a foot (30 centimeters) long.</li>
</ul>
<h1><a class="anchor" id="autotoc_md9"></a>
Installing the Sketch</h1>
<p>You'll need to ensure you can successfully connect and load sketches onto your Arduino board, using the desktop IDE. Once you've made sure you can load a simple sketch successfully, you'll follow these steps:</p>
<h2><a class="anchor" id="autotoc_md10"></a>
Arduino Desktop IDE</h2>
<p>If you're running using the Arduino IDE application, you'll need to fetch the latest version of this sketch. To install the TensorFlow Lite Micro for Arduino library, see the <a href="../../README.md#how-to-install">how to install</a> instructions.</p>
<p>Open up the <a class="el" href="magic__wand_8ino.html">magic_wand.ino</a> file in the Arduino editor, and make sure the Arduino board is visible and connected to the right port. You'll need to search for the some libraries that the sketch depends on, using <code>Sketch-&gt;Include Library-&gt;Manage Libraries</code> from the main menu. The <a href="https://github.com/arduino-libraries/Arduino_LSM9DS1">Arduino_LSM9DS1</a> lets us access the accelerometer and gyroscope readings from the board's IMU, and you need at least version 1.1.0. We'll be using Bluetooth to communicate with the web page, so you should also search for <a href="https://www.arduino.cc/en/Reference/ArduinoBLE">ArduinoBLE</a> and make sure you've got version 1.1.3 or newer.</p>
<p>You should now be able to press the upload button to compile and install the sketch on your board.</p>
<h1><a class="anchor" id="autotoc_md11"></a>
Building the Wand</h1>
<p>The 'wand' itself can be as simple as a stick, it doesn't need to do anything other than keep the board at its end as you hold the other end and wave it about. A cheap wand from an online retailer will work. A simple piece of wood or ruler works just as well.</p>
<p>You should place the board at the end of the wand, with the USB socket facing downwards, towards where you hold it, so that the cable can run down the handle. The sketch is designed to compensate for any rotation of the board around the wand's shaft, so as long as it's parallel to the wand's length the board's twist won't matter. Use sticky tape or some other easy-to-remove method to attach the board to the wand, and hold the cable in place along the shaft. The end result should look something like this:</p>
<p><img src="../../docs/magic_wand_attachment.jpg" alt="Image of board attached to wand" class="inline"/></p>
<p>If an ASCII-art diagram is more helpful, here's what you should aim for:</p>
<div class="fragment"><div class="line"> ____</div>
<div class="line">|    |&lt;- Arduino board</div>
<div class="line">|    |</div>
<div class="line">| () |  &lt;- Reset button</div>
<div class="line">|    |</div>
<div class="line"> -TT-   &lt;- USB port</div>
<div class="line">  ||</div>
<div class="line">  ||&lt;- Wand</div>
<div class="line"> ....</div>
<div class="line">  ||</div>
<div class="line">  ||</div>
<div class="line">  ()</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md12"></a>
Using the wand</h1>
<p>The wand can be used with or without the Nano 33 BLE attached to the Tiny Machine Learning Shield. It is easier to use without, as your hand will not tire as quickly. The wand should be held as you would a pencil or pen, about 8 inches from the USB socket. Use your wrist to make strokes, not your arm. Strokes will need to be made somewhat quickly, without stopping during changes in direction.</p>
<h1><a class="anchor" id="autotoc_md13"></a>
Viewing Gestures in the Browser</h1>
<p>To preview and record gestures, we'll be connecting the sketch you've just uploaded to a web page, using Bluetooth and Chrome's WebBLE API. The code for the page is <a href="https://github.com/tensorflow/tflite-micro-arduino-examples/tree/main/examples/magic_wand/website">in this repository</a>, but it's all implemented using browser-side Javascript in a static HTML page, so you don't need to host it on your own server. Just dragging and dropping the <code>index.html</code> file into your browser should work.</p>
<p>If the sketch has uploaded successfully, the Arduino should be advertising itself through Bluetooth. On the web page, press the 'Bluetooth' button to connect, and you should see a dialog appear asking you to pair with a device. After a second or two, there should be an entry that looks something like "BLESense-2F00". Click on that to pair, and you should be returned to the web page.</p>
<p>If everything is working as expected, the Bluetooth button should turn blue, with "Connected" next to it. Now try moving the wand and look at the square below the button. As you gesture, you should see tracks appearing as lines in the web page in real time. Try doing small circles, or a 'Z' like Zorro!</p>
<h1><a class="anchor" id="autotoc_md14"></a>
Pretrained Model</h1>
<p>The sketch comes with a model that's been trained to recognize the hand-drawn digits zero to nine. This is based on a small dataset recorded by Google, so your accuracy may vary, but if you bring up the Serial Monitor in the Arduino IDE you can see what the model predicts for each gesture you make, with a confidence score between 0% and 100%, as well as ASCII art of the gesture outline.</p>
<h1><a class="anchor" id="autotoc_md15"></a>
Recording Gestures</h1>
<p>As you get familiar with the wand, so should notice that the gestures you have performed start to stack on the right side of the web page. This is where the data you'll eventually want to use for training is stored. When you leave or refresh the web page, these gestures will be lost, so make sure you use the "Download Data" link to save them locally if you've generated a number of them.</p>
<p>The gestures are automatically split up by times when the wand is kept still. These pauses act like spaces between words, and so when you've finished a gesture you should stop moving the wand so that it ends cleanly.</p>
<p>To get started, you should pick a couple of easy gestures to perform, like a 'Z' and an 'O'. As you make these gestures, you should see them appear in the right-hand stack of gestures. You can look at the shapes shown there to understand whether the gestures came out cleanly. A good rule of thumb is that if you can't tell what the gesture is by looking at it in the stack, then a model will have a hard time recognizing it too.</p>
<p>Once you have ten or so of each gesture, scroll through the stack to review them. If any don't seem very recognizable, or are too 'sloppy' (which is very subjective unfortunately), then you can press the trash can button on the top right of the image to remove it. If you removed any, try recording some more so you have at least ten of each gesture. If you are happy with a gesture, click on the label at the top left to type in the correct name for it (for example <code>O</code> or <code>Z</code>).</p>
<p>After you've reviewed and labeled all of your data, you can download it as a JSON text file that can be used for training.</p>
<h1><a class="anchor" id="autotoc_md16"></a>
Training</h1>
<p>Once you have data, you should <a href="https://colab.research.google.com/github/tensorflow/tflite-micro-arduino-examples/blob/main/examples/magic_wand/train/train_magic_wand_model.ipynb">run the Python training notebook in Colab</a> and follow the steps to create and export your own model.</p>
<h1><a class="anchor" id="autotoc_md17"></a>
Deployment</h1>
<p>The Python training process should give you a <code>magic_wand_model_data.cc</code> file. Replace the file of the same name (but with a <code>.cpp</code> suffix) that's in the sketch you're using with this version. You'll also need to update the <code>labels</code> and <code>label_count</code> variables near the top of the <code><a class="el" href="magic__wand_8ino.html">magic_wand.ino</a></code> to reflect any changes you made to the gestures you're trying to recognize.</p>
<p>Upload this modified sketch, and you should be able to perform gestures and see them recognized in the Serial Monitor of your Arduino editor. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.12.0
</small></address>
</div><!-- doc-content -->
</body>
</html>
