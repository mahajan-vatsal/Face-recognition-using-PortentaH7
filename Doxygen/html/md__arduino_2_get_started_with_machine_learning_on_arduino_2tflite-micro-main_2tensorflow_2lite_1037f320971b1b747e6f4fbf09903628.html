<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.12.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Machine Vision using Portenta H7: memory_management</title>
<link rel="icon" href="logo.png" type="image/x-icon" />
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="logo.png"/></td>
  <td id="projectalign">
   <div id="projectname">Machine Vision using Portenta H7<span id="projectnumber">&#160;2</span>
   </div>
   <div id="projectbrief">This project aims to develop a face recognition-based access control system using the Arduino Portenta H7 and Vision Shield, leveraging Edge Impulse for machine learning. The system captures facial images, processes them locally using an AI model deployed on the Portenta H7 and determines access based on authorised personnel.</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.12.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search',false);
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){ initResizable(false); });
/* @license-end */
</script>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

</div><!-- top -->
<div id="doc-content">
<div><div class="header">
  <div class="headertitle"><div class="title">memory_management</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><ul>
<li>Memory Management in TensorFlow Lite Micro<ul>
<li>Tensor Arena<ul>
<li>Head Section<ul>
<li>Offline planned tensor allocations</li>
</ul>
</li>
<li>Temporary Section</li>
<li>Tail Section</li>
</ul>
</li>
<li>Recording Memory APIs<ul>
<li>Allocation Section Details</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1><a class="anchor" id="autotoc_md162"></a>
Memory Management in TensorFlow Lite Micro</h1>
<p>This document outlines how memory is managed internally by TensorFlow Lite Micro (TFLM) today. It outlines the "online" allocation strategy used by the default TFLM APIs for loading a model into a shared tensor arena.</p>
<h2><a class="anchor" id="autotoc_md163"></a>
Tensor Arena</h2>
<p>The main "working" space for TFLM allocations is inside a single <code>char</code> or <code>int8_t</code> buffer. This buffer can be managed by passing it directly into a <code><a class="el" href="classtflite_1_1_micro_interpreter.html">tflite::MicroInterpreter</a></code> constructor or through a <code><a class="el" href="classtflite_1_1_micro_allocator.html">tflite::MicroAllocator</a></code> instance that can be passed into a <code><a class="el" href="classtflite_1_1_micro_interpreter.html">tflite::MicroInterpreter</a></code> constructor. Internally, the <code><a class="el" href="classtflite_1_1_micro_allocator.html">tflite::MicroAllocator</a></code> classifies allocations into 3 different sections:</p>
<ul>
<li><b>Head</b> - non-persistent allocations.</li>
<li><b>Temporary</b> - short term "scoped" allocations.</li>
<li><b>Tail</b> - persistent allocations.</li>
</ul>
<p>The illustration below represents typical allocations in TFLM:</p>
<div class="fragment"><div class="line">--------------------------------------------------------------------------------</div>
<div class="line">|        |                     |                                               |</div>
<div class="line">|  HEAD  |&lt;--  TEMPORARY    --&gt;|                    TAIL                       |</div>
<div class="line">|        |                     |                                               |</div>
<div class="line">--------------------------------------------------------------------------------</div>
<div class="line">* Lowest Address                                               Highest Address *</div>
</div><!-- fragment --><h3><a class="anchor" id="autotoc_md164"></a>
Head Section</h3>
<p>This non-persistent section typically holds shared Tensor buffers. This section does not allocate small iterative chunks, it can only be set by a specific length for the entire section.</p>
<p>This allocation length of this section is managed by the <code><a class="el" href="classtflite_1_1_greedy_memory_planner.html">tflite::GreedyMemoryPlanner</a></code>. That memory planner looks at the entire graph of a model and tries to reuse as many buffers as possible to create the smallest length for the head. The Tensor buffers for this section can be accessed via a <code><a class="el" href="struct_tf_lite_eval_tensor.html">TfLiteEvalTensor</a></code> or <code><a class="el" href="struct_tf_lite_tensor.html">TfLiteTensor</a></code> instance on the <code><a class="el" href="classtflite_1_1_micro_interpreter.html">tflite::MicroInterpreter</a></code>.</p>
<h4><a class="anchor" id="autotoc_md165"></a>
Offline planned tensor allocations</h4>
<p>All, or a subset of, tensors can be allocated using an offline planner. An offline planner performs tensor allocation on e.g. a host PC. The offline tensor allocation plan is added to model metadata. See format below.</p>
<p>For each non-constant tensor in the <code>tensors:[Tensor]</code> list of the subgraph, a byte offset to the start of the head section of the memory arena is given. -1 indicates that the tensor will be allocated at runtime by the <code><a class="el" href="classtflite_1_1_greedy_memory_planner.html">tflite::GreedyMemoryPlanner</a></code>. The offline plan is permitted to overlap buffers if it knows that the data will not be used at the same time.</p>
<p>The offline tensor allocation plan will be encoded in the <code>metadata:[Metadata]</code> field of the model, using the following encoding:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Metadata component   </th><th class="markdownTableHeadNone">Value    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">name:string   </td><td class="markdownTableBodyNone">“OfflineMemoryAllocation”    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">buffer:unit   </td><td class="markdownTableBodyNone">Index of buffer containing offline tensor allocation data   </td></tr>
</table>
<p>The buffer contents for the offline tensor allocation is a list of 32-bit integers of the following format:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Offset   </th><th class="markdownTableHeadNone">Value    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">0   </td><td class="markdownTableBodyNone">Offline allocation format version    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">1   </td><td class="markdownTableBodyNone">Number of subgraphs    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">2   </td><td class="markdownTableBodyNone">Number offsets following: n    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">3   </td><td class="markdownTableBodyNone">Byte offset of tensor #0 or -1 to allocate at runtime    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">4   </td><td class="markdownTableBodyNone">Byte offset of tensor #1 or -1 to allocate at runtime    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">...   </td><td class="markdownTableBodyNone">...    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">3+(n-1)   </td><td class="markdownTableBodyNone">Byte offset of tensor #(n-1) or -1 to allocate at runtime   </td></tr>
</table>
<p>Note that offsets 0 (the version) and 1 (the number of subgraphs) are currently ignored by the micro memory allocator. In case of multiple subgraphs, it assumes all tensors for all subgraphs are concatenated: all tensors for the first subgraph are first, followed by those of the second subgraph, etc.</p>
<p>The <code><a class="el" href="classtflite_1_1_greedy_memory_planner.html">tflite::GreedyMemoryPlanner</a></code> treats the provided offline tensor allocation plan as constant fixed offset to the start of the head section and will attempt to fit any other tensors (such as scratch tensors added a runtime using the <code>RequestScratchBufferInArena</code> API of <code><a class="el" href="struct_tf_lite_context.html">TfLiteContext</a></code>) around those fixed offsets.</p>
<h3><a class="anchor" id="autotoc_md166"></a>
Temporary Section</h3>
<p>This section is used to allocate "scoped" or short-term, non-guaranteed buffers. Allocations from this section start from the current end address of the head section and grow towards the tail section. An allocation chain can be reset (and must be reset before adjusting the head) and moves the current allocation start address back to the end of the head section.</p>
<p>TFLM currently uses these allocations for a scope allocation of large C structs or scratch memory that is expected to be valid for at least the lifetime of a method call. This section.</p>
<h3><a class="anchor" id="autotoc_md167"></a>
Tail Section</h3>
<p>This section holds all persistent allocations used by TFLM. This section contains many random sized allocations and grows towards the end of the head section. Allocations in this section come from a variety of areas inside of TFLM. TFLM provides a recording API to assist with auditing the contents of this section.</p>
<h2><a class="anchor" id="autotoc_md168"></a>
Recording Memory APIs</h2>
<p>TFLM provides simple APIs for auditing memory usage in the shared tensor arena. These APIs are opt-in and require some additional memory overhead and a working debug logging implementation <a href="https://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/debug_log.cc">(reference implementation)</a>.</p>
<p>A typical bare-bones TFLM interpreter setup looks as such:</p>
<div class="fragment"><div class="line"> ++</div>
<div class="line"><span class="comment">// Buffer for the tensor arena:</span></div>
<div class="line"><span class="keywordtype">size_t</span> <a class="code hl_variable" href="person__detection__test_8cc.html#a5af3a65557f88ed72dd512ad65b55096">tensor_arena_size</a> = 2048;</div>
<div class="line">uint8_t <a class="code hl_variable" href="network__tester__test_8cc.html#abf99e32bec994276b2bcf77385c93365">tensor_arena</a>[<a class="code hl_variable" href="person__detection__test_8cc.html#a5af3a65557f88ed72dd512ad65b55096">tensor_arena_size</a>];</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Interpreter using the shared tensor arena above:</span></div>
<div class="line"><a class="code hl_class" href="classtflite_1_1_micro_interpreter.html">tflite::MicroInterpreter</a> <a class="code hl_variable" href="_inference_allocate_tensor_8cpp.html#a0d8f3bb5211083760f7c593d57adb17d">interpreter</a>(</div>
<div class="line">  <a class="code hl_function" href="namespacetflite.html#a3707d04839963c9df1f3449f5196e3a4">tflite::GetModel</a>(my_model_data), ops_resolver,</div>
<div class="line">  <a class="code hl_variable" href="network__tester__test_8cc.html#abf99e32bec994276b2bcf77385c93365">tensor_arena</a>, <a class="code hl_variable" href="person__detection__test_8cc.html#a5af3a65557f88ed72dd512ad65b55096">tensor_arena_size</a>);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Invoke one time which will allocate internals:</span></div>
<div class="line"><span class="keywordflow">if</span> (<a class="code hl_variable" href="_inference_allocate_tensor_8cpp.html#a0d8f3bb5211083760f7c593d57adb17d">interpreter</a>.<a class="code hl_function" href="classtflite_1_1_micro_interpreter.html#a2d76c06ba8d41944e185c3d330e3d554">Invoke</a>() != <a class="code hl_enumvalue" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcf7df9e575f8a1f1a49c58fb0f49428b8.html#acf79d2fb5fa520303014d1303f1f6361ab25fe210808197f1b6601df8ccdcd699">kTfLiteOk</a>) {</div>
<div class="line">  <a class="code hl_define" href="_face___access__inferencing_2src_2edge-impulse-sdk_2tensorflow_2lite_2micro_2micro__log_8h.html#ab9bf491b4a37b06ba732fd7de6b04cb2">MicroPrintf</a>(<span class="stringliteral">&quot;Exception during invoke()!&quot;</span>);</div>
<div class="line">}</div>
<div class="ttc" id="a_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcf7df9e575f8a1f1a49c58fb0f49428b8_html_acf79d2fb5fa520303014d1303f1f6361ab25fe210808197f1b6601df8ccdcd699"><div class="ttname"><a href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcf7df9e575f8a1f1a49c58fb0f49428b8.html#acf79d2fb5fa520303014d1303f1f6361ab25fe210808197f1b6601df8ccdcd699">kTfLiteOk</a></div><div class="ttdeci">@ kTfLiteOk</div><div class="ttdef"><b>Definition</b> c_api_types.h:56</div></div>
<div class="ttc" id="a_face___access__inferencing_2src_2edge-impulse-sdk_2tensorflow_2lite_2micro_2micro__log_8h_html_ab9bf491b4a37b06ba732fd7de6b04cb2"><div class="ttname"><a href="_face___access__inferencing_2src_2edge-impulse-sdk_2tensorflow_2lite_2micro_2micro__log_8h.html#ab9bf491b4a37b06ba732fd7de6b04cb2">MicroPrintf</a></div><div class="ttdeci">#define MicroPrintf(...)</div><div class="ttdef"><b>Definition</b> micro_log.h:36</div></div>
<div class="ttc" id="a_inference_allocate_tensor_8cpp_html_a0d8f3bb5211083760f7c593d57adb17d"><div class="ttname"><a href="_inference_allocate_tensor_8cpp.html#a0d8f3bb5211083760f7c593d57adb17d">interpreter</a></div><div class="ttdeci">tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize, error_reporter)</div></div>
<div class="ttc" id="aclasstflite_1_1_micro_interpreter_html"><div class="ttname"><a href="classtflite_1_1_micro_interpreter.html">tflite::MicroInterpreter</a></div><div class="ttdef"><b>Definition</b> micro_interpreter.h:41</div></div>
<div class="ttc" id="aclasstflite_1_1_micro_interpreter_html_a2d76c06ba8d41944e185c3d330e3d554"><div class="ttname"><a href="classtflite_1_1_micro_interpreter.html#a2d76c06ba8d41944e185c3d330e3d554">tflite::MicroInterpreter::Invoke</a></div><div class="ttdeci">TfLiteStatus Invoke()</div><div class="ttdef"><b>Definition</b> micro_interpreter.cpp:273</div></div>
<div class="ttc" id="anamespacetflite_html_a3707d04839963c9df1f3449f5196e3a4"><div class="ttname"><a href="namespacetflite.html#a3707d04839963c9df1f3449f5196e3a4">tflite::GetModel</a></div><div class="ttdeci">const tflite::Model * GetModel(const void *buf)</div><div class="ttdef"><b>Definition</b> schema_generated.h:20105</div></div>
<div class="ttc" id="anetwork__tester__test_8cc_html_abf99e32bec994276b2bcf77385c93365"><div class="ttname"><a href="network__tester__test_8cc.html#abf99e32bec994276b2bcf77385c93365">tensor_arena</a></div><div class="ttdeci">uint8_t tensor_arena[TENSOR_ARENA_SIZE]</div><div class="ttdef"><b>Definition</b> network_tester_test.cc:43</div></div>
<div class="ttc" id="aperson__detection__test_8cc_html_a5af3a65557f88ed72dd512ad65b55096"><div class="ttname"><a href="person__detection__test_8cc.html#a5af3a65557f88ed72dd512ad65b55096">tensor_arena_size</a></div><div class="ttdeci">constexpr int tensor_arena_size</div><div class="ttdef"><b>Definition</b> person_detection_test.cc:31</div></div>
</div><!-- fragment --><p>Recording API can simply be used by including the <code>RecordingMicroInterpreter</code> class (<code>recording_micro_interpreter.h</code>) and replace <code><a class="el" href="classtflite_1_1_micro_interpreter.html">tflite::MicroInterpreter</a></code> with <code><a class="el" href="classtflite_1_1_recording_micro_interpreter.html">tflite::RecordingMicroInterpreter</a></code>. The same call to <code>invoke()</code> is performed, but another call is made to <code>PrintAllocations()</code> which will output detailed allocation logging:</p>
<div class="fragment"><div class="line"> ++</div>
<div class="line"><span class="comment">// Add an include to the recording API:</span></div>
<div class="line"><span class="preprocessor">#include &quot;recording_micro_interpreter.h&quot;</span></div>
<div class="line"> </div>
<div class="line"><span class="comment">// Simply change the class name from &#39;MicroInterpreter&#39; to &#39;RecordingMicroInterpreter&#39;:</span></div>
<div class="line"><a class="code hl_class" href="classtflite_1_1_recording_micro_interpreter.html">tflite::RecordingMicroInterpreter</a> <a class="code hl_variable" href="_inference_allocate_tensor_8cpp.html#a0d8f3bb5211083760f7c593d57adb17d">interpreter</a>(</div>
<div class="line">  <a class="code hl_function" href="namespacetflite.html#a3707d04839963c9df1f3449f5196e3a4">tflite::GetModel</a>(my_model_data), ops_resolver,</div>
<div class="line">  <a class="code hl_variable" href="network__tester__test_8cc.html#abf99e32bec994276b2bcf77385c93365">tensor_arena</a>, <a class="code hl_variable" href="person__detection__test_8cc.html#a5af3a65557f88ed72dd512ad65b55096">tensor_arena_size</a>);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Invoke one time which will allocate internals:</span></div>
<div class="line"><span class="keywordflow">if</span> (<a class="code hl_variable" href="_inference_allocate_tensor_8cpp.html#a0d8f3bb5211083760f7c593d57adb17d">interpreter</a>.<a class="code hl_function" href="classtflite_1_1_micro_interpreter.html#a2d76c06ba8d41944e185c3d330e3d554">Invoke</a>() != <a class="code hl_enumvalue" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcf7df9e575f8a1f1a49c58fb0f49428b8.html#acf79d2fb5fa520303014d1303f1f6361ab25fe210808197f1b6601df8ccdcd699">kTfLiteOk</a>) {</div>
<div class="line">  <a class="code hl_define" href="_face___access__inferencing_2src_2edge-impulse-sdk_2tensorflow_2lite_2micro_2micro__log_8h.html#ab9bf491b4a37b06ba732fd7de6b04cb2">MicroPrintf</a>(<span class="stringliteral">&quot;Exception during invoke()!&quot;</span>);</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Print out detailed allocation information:</span></div>
<div class="line"><a class="code hl_variable" href="_inference_allocate_tensor_8cpp.html#a0d8f3bb5211083760f7c593d57adb17d">interpreter</a>.GetMicroAllocator().PrintAllocations();</div>
<div class="ttc" id="aclasstflite_1_1_recording_micro_interpreter_html"><div class="ttname"><a href="classtflite_1_1_recording_micro_interpreter.html">tflite::RecordingMicroInterpreter</a></div><div class="ttdef"><b>Definition</b> recording_micro_interpreter.h:36</div></div>
</div><!-- fragment --><p>The output of this call will look something similar to this (output from the <a href="https://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/memory_arena_threshold_test.cc#L205">memory_arena_threshold_test</a>):</p>
<div class="fragment"><div class="line">[RecordingMicroAllocator] Arena allocation total 9568 bytes</div>
<div class="line">[RecordingMicroAllocator] Arena allocation head 7744 bytes</div>
<div class="line">[RecordingMicroAllocator] Arena allocation tail 1824 bytes</div>
<div class="line">[RecordingMicroAllocator] &#39;TfLiteEvalTensor data&#39; used 360 bytes with alignment overhead (requested 360 bytes for 15 allocations)</div>
<div class="line">[RecordingMicroAllocator] &#39;Persistent TfLiteTensor data&#39; used 0 bytes with alignment overhead (requested 0 bytes for 0 tensors)</div>
<div class="line">[RecordingMicroAllocator] &#39;Persistent TfLiteTensor quantization data&#39; used 0 bytes with alignment overhead (requested 0 bytes for 0 allocations)</div>
<div class="line">[RecordingMicroAllocator] &#39;TfLiteTensor variable buffer data&#39; used 0 bytes with alignment overhead (requested 0 bytes for 0 allocations)</div>
<div class="line">[RecordingMicroAllocator] &#39;NodeAndRegistration struct&#39; used 392 bytes with alignment overhead (requested 392 bytes for 7 NodeAndRegistration structs)</div>
<div class="line">[RecordingMicroAllocator] &#39;Operator runtime data&#39; used 136 bytes with alignment overhead (requested 136 bytes for 5 OpData structs)</div>
</div><!-- fragment --><h3><a class="anchor" id="autotoc_md169"></a>
Allocation Section Details</h3>
<p>More information about each recorded allocation section:</p>
<ul>
<li>'<a class="el" href="struct_tf_lite_eval_tensor.html">TfLiteEvalTensor</a> data'<ul>
<li>C struct that holds the data type, dimension, and a pointer to the buffer representing the Tensor.</li>
</ul>
</li>
<li>'Persistent <a class="el" href="struct_tf_lite_tensor.html">TfLiteTensor</a> data'<ul>
<li>C struct that holds more information than a <code><a class="el" href="struct_tf_lite_eval_tensor.html">TfLiteEvalTensor</a></code> struct in the graph.</li>
<li>Allocations in this bucket will only show up when accessing tensors from the accessors on <code><a class="el" href="classtflite_1_1_micro_interpreter.html">tflite::MicroInterpreter</a></code>.</li>
</ul>
</li>
<li>'Persistent <a class="el" href="struct_tf_lite_tensor.html">TfLiteTensor</a> quantization data'<ul>
<li>Length of persistent quantization data assigned to persistent <code><a class="el" href="struct_tf_lite_tensor.html">TfLiteTensor</a></code> structs.</li>
<li>Allocations in this bucket will only show up when accessing tensors from the accessors on <code><a class="el" href="classtflite_1_1_micro_interpreter.html">tflite::MicroInterpreter</a></code>.</li>
</ul>
</li>
<li>'<a class="el" href="struct_tf_lite_tensor.html">TfLiteTensor</a> variable buffer data'<ul>
<li>Length of buffer data from a variable tensor (retains data throughout calls to <code>invoke()</code>).</li>
</ul>
</li>
<li>'NodeAndRegistration struct'<ul>
<li>C struct that holds a <code><a class="el" href="struct_tf_lite_registration.html">TfLiteRegistration</a></code> and <code><a class="el" href="struct_tf_lite_node.html">TfLiteNode</a></code> struct instance.</li>
<li>Each operator in a model will contain one <code>NodeAndRegistration</code> struct.</li>
</ul>
</li>
<li>'Operator runtime data'<ul>
<li>Persistent allocations of data cached by TFLM kernels (e.g. quantization params, multipliers, etc). </li>
</ul>
</li>
</ul>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.12.0
</small></address>
</div><!-- doc-content -->
</body>
</html>
