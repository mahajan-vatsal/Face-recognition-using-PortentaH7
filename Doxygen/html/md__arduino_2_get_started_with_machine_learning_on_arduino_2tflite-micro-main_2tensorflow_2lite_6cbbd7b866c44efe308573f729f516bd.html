<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.12.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Machine Vision using Portenta H7: new_platform_support</title>
<link rel="icon" href="logo.png" type="image/x-icon" />
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="logo.png"/></td>
  <td id="projectalign">
   <div id="projectname">Machine Vision using Portenta H7<span id="projectnumber">&#160;2</span>
   </div>
   <div id="projectbrief">This project aims to develop a face recognition-based access control system using the Arduino Portenta H7 and Vision Shield, leveraging Edge Impulse for machine learning. The system captures facial images, processes them locally using an AI model deployed on the Portenta H7 and determines access based on authorised personnel.</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.12.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search',false);
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){ initResizable(false); });
/* @license-end */
</script>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

</div><!-- top -->
<div id="doc-content">
<div><div class="header">
  <div class="headertitle"><div class="title">new_platform_support</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><ul>
<li>Porting to a new platform<ul>
<li>Step 1: Build TFLM Static Library with Reference Kernels</li>
<li>Step 2: Customize Logging and Timing Function for your Platform</li>
<li>Step 3: Running the hello_world Example</li>
<li>Step 4: Building and Customizing Additional Examples</li>
<li>Step 5: Integrating Optimized Kernel Implementations</li>
</ul>
</li>
<li>Advanced Integration Topics</li>
<li>Getting Help</li>
</ul>
<h1><a class="anchor" id="autotoc_md170"></a>
Porting to a new platform</h1>
<p>At its core, TFLM is a portable library that can be used on a variety of target hardware to run inference on TfLite models.</p>
<p>Prior to integrating TFLM with a specific hardware involves tasks that is outside the scope of the TFLM project, including:</p>
<ul>
<li>Toolchain setup - TFLM requires support for C++11</li>
<li>Set up and installation of board-specific SDKs and IDEs</li>
<li>Compiler flags and Linker setup</li>
<li>Integrating peripherals such as cameras, microphones and accelerometers to provide the sensor inputs for the ML models.</li>
</ul>
<p>In this guide we outline our recommended approach for integrating TFLM with a new target hardware assuming that you have already set up a development and debugging environment for you board independent of TLFLM.</p>
<h2><a class="anchor" id="autotoc_md171"></a>
Step 1: Build TFLM Static Library with Reference Kernels</h2>
<p>Use the TFLM project generation script to create a directory tree containing only the sources that are necessary to build the code TFLM library.</p>
<div class="fragment"><div class="line">python3 tensorflow/lite/micro/tools/project_generation/create_tflm_tree.py \</div>
<div class="line">  -e hello_world \</div>
<div class="line">  -e micro_speech \</div>
<div class="line">  -e person_detection \</div>
<div class="line">  /tmp/tflm-tree</div>
</div><!-- fragment --><p>This will create a folder that looks like the following at the top-level: </p><div class="fragment"><div class="line">examples  LICENSE  tensorflow  third_party</div>
</div><!-- fragment --><p>All the code in the <code>tensorflow</code> and <code>third_party</code> folders can be compiled into a single static library (for example <code>libtflm.a</code>) using your platform-specific build system.</p>
<p>TFLM's third party dependencies are spearated out in case there is a need to have shared libraries for the third party code to avoid symbol collisions.</p>
<p>Note that for IDEs, it might be sufficient to simply include the folder created by the TFLM project generation script into the overall IDE tree.</p>
<h2><a class="anchor" id="autotoc_md172"></a>
Step 2: Customize Logging and Timing Function for your Platform</h2>
<p>Replace the following files with a version that is specific to your target platform:</p>
<ul>
<li><a href="https://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/debug_log.cc">debug_log.cc</a></li>
<li><a href="https://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/micro_time.cc">micro_time.cc</a></li>
<li><a href="https://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/system_setup.cc">system_setup.cc</a></li>
</ul>
<p>These can be placed anywhere in your directory tree. The only requirement is that when linking TFLM into a binary, the implementations of the functions in <a href="https://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/debug_log.h">debug_log.h</a>, <a href="https://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/micro_time.h">micro_time.h</a> and <a href="https://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/debug_log.h">system_setup.h</a> can be found.</p>
<p>For example, the implementations of these functions for:</p><ul>
<li><a href="https://github.com/advaitjain/tflite-micro-sparkfun-edge-examples/tree/120f68ace95ae3d66963977ac7754acd0c86540d/tensorflow/lite/micro/sparkfun_edge">Sparkfun Edge</a> is the implementation of these functions for the Sparkfun Edge.</li>
</ul>
<h2><a class="anchor" id="autotoc_md173"></a>
Step 3: Running the hello_world Example</h2>
<p>Once you have completed step 2, you should be set up to run the <code>hello_world</code> example and see the output over the UART.</p>
<div class="fragment"><div class="line">cp -r /tmp/tflm-tree/examples/hello_world &lt;path-to-platform-specific-hello-world&gt;</div>
</div><!-- fragment --><p> The <code>hello_world</code> example should not need any customization and you should be able to directly build and run it.</p>
<h2><a class="anchor" id="autotoc_md174"></a>
Step 4: Building and Customizing Additional Examples</h2>
<p>We recommend that you fork the <a href="https://github.com/tensorflow/tflite-micro/tree/main/tensorflow/lite/micro/examples">TFLM examples</a> and then modify them as needed (to add support for peripherals etc.) to run on your target platform.</p>
<h2><a class="anchor" id="autotoc_md175"></a>
Step 5: Integrating Optimized Kernel Implementations</h2>
<p>TFLM has optimized kernel implementations for a variety of targets that are in sub-folders of the <a href="https://github.com/tensorflow/tflite-micro/tree/main/tensorflow/lite/micro/kernels">kernels directory</a>.</p>
<p>It is possible to use the project generation script to create a tree with these optimized kernel implementations (and associated third party dependencies).</p>
<p>For example: </p><div class="fragment"><div class="line">python3 tensorflow/lite/micro/tools/project_generation/create_tflm_tree.py \</div>
<div class="line">  -e hello_world -e micro_speech -e person_detection \</div>
<div class="line">  --makefile_options=&quot;TARGET=cortex_m_generic OPTIMIZED_KERNEL_DIR=cmsis_nn TARGET_ARCH=project_generation&quot; \</div>
<div class="line">  /tmp/tflm-cmsis</div>
</div><!-- fragment --><p>will create an output tree with all the sources and headers needed to use the optimized <a href="https://github.com/tensorflow/tflite-micro/tree/main/tensorflow/lite/micro/kernels/cmsis_nn">cmsis_nn kernels</a> for Cortex-M platforms.</p>
<h1><a class="anchor" id="autotoc_md176"></a>
Advanced Integration Topics</h1>
<p>In order to have tighter coupling between your platform-specific TFLM integration and the upstream TFLM repository, you might want to consider the following:</p>
<ol type="1">
<li>Set up a GitHub repository for your platform</li>
</ol>
<ol type="1">
<li>Nightly sync between TFLM and your platform-specific GitHub repository</li>
</ol>
<ol type="1">
<li>Using GitHub actions for CI</li>
</ol>
<p>For some pointers on how to set this up, we refer you to the GitHub repositories that integrated TFLM for the:</p><ul>
<li><a href="https://github.com/tensorflow/tflite-micro-arduino-examples">Arduino</a>: supported by the TFLM team</li>
<li><a href="https://github.com/advaitjain/tflite-micro-sparkfun-edge-examples">Sparkfun Edge</a>: for demonstration purposes only, not officially supported.</li>
</ul>
<p>Once you are set up with continuous integration and the ability to integrate newer versions of TFLM with your platform, feel free to add a build badge to TFLM's <a href="https://github.com/tensorflow/tflite-micro#community-supported-tflm-examples">Community Supported TFLM Examples</a>.</p>
<h1><a class="anchor" id="autotoc_md177"></a>
Getting Help</h1>
<p><a href="https://github.com/tensorflow/tflite-micro#getting-help">Here are some ways</a> that you can reach out to get help. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.12.0
</small></address>
</div><!-- doc-content -->
</body>
</html>
