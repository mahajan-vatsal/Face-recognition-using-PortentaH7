<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.12.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Machine Vision using Portenta H7: Arduino/GetStartedWithMachineLearningOnArduino/tflite-micro-arduino-examples-main/src/tensorflow/lite/kernels/internal/portable_tensor_utils.h Source File</title>
<link rel="icon" href="logo.png" type="image/x-icon" />
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="logo.png"/></td>
  <td id="projectalign">
   <div id="projectname">Machine Vision using Portenta H7<span id="projectnumber">&#160;2</span>
   </div>
   <div id="projectbrief">This project aims to develop a face recognition-based access control system using the Arduino Portenta H7 and Vision Shield, leveraging Edge Impulse for machine learning. The system captures facial images, processes them locally using an AI model deployed on the Portenta H7 and determines access based on authorised personnel.</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.12.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search',false);
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){ initResizable(false); });
/* @license-end */
</script>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_a991eec27578c865874ede3d8ec657c2.html">Arduino</a></li><li class="navelem"><a class="el" href="dir_5b434fadadbc73afff09af364c4592fa.html">GetStartedWithMachineLearningOnArduino</a></li><li class="navelem"><a class="el" href="dir_0d2ed21f8b79a9b0d8abfa821a489de0.html">tflite-micro-arduino-examples-main</a></li><li class="navelem"><a class="el" href="dir_e866ddbbaec9cd84ea4c87a9de153242.html">src</a></li><li class="navelem"><a class="el" href="dir_3ad0fc18d1ae8b18d303c300862804a0.html">tensorflow</a></li><li class="navelem"><a class="el" href="dir_1b0dbadbd3f4c97dd60e5ba16d3f4ccc.html">lite</a></li><li class="navelem"><a class="el" href="dir_727b29f528d223ae4a1470460d8b9460.html">kernels</a></li><li class="navelem"><a class="el" href="dir_5135a68269ee8eaf841787df42ed18d9.html">internal</a></li>  </ul>
</div>
</div><!-- top -->
<div id="doc-content">
<div class="header">
  <div class="headertitle"><div class="title">portable_tensor_utils.h</div></div>
</div><!--header-->
<div class="contents">
<a href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcbb70f67f1bf5a135711b485fe7e54639.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a id="l00001" name="l00001"></a><span class="lineno">    1</span><span class="comment">/* Copyright 2021 The TensorFlow Authors. All Rights Reserved.</span></div>
<div class="line"><a id="l00002" name="l00002"></a><span class="lineno">    2</span><span class="comment"></span> </div>
<div class="line"><a id="l00003" name="l00003"></a><span class="lineno">    3</span><span class="comment">Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></div>
<div class="line"><a id="l00004" name="l00004"></a><span class="lineno">    4</span><span class="comment">you may not use this file except in compliance with the License.</span></div>
<div class="line"><a id="l00005" name="l00005"></a><span class="lineno">    5</span><span class="comment">You may obtain a copy of the License at</span></div>
<div class="line"><a id="l00006" name="l00006"></a><span class="lineno">    6</span><span class="comment"></span> </div>
<div class="line"><a id="l00007" name="l00007"></a><span class="lineno">    7</span><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></div>
<div class="line"><a id="l00008" name="l00008"></a><span class="lineno">    8</span><span class="comment"></span> </div>
<div class="line"><a id="l00009" name="l00009"></a><span class="lineno">    9</span><span class="comment">Unless required by applicable law or agreed to in writing, software</span></div>
<div class="line"><a id="l00010" name="l00010"></a><span class="lineno">   10</span><span class="comment">distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></div>
<div class="line"><a id="l00011" name="l00011"></a><span class="lineno">   11</span><span class="comment">WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></div>
<div class="line"><a id="l00012" name="l00012"></a><span class="lineno">   12</span><span class="comment">See the License for the specific language governing permissions and</span></div>
<div class="line"><a id="l00013" name="l00013"></a><span class="lineno">   13</span><span class="comment">limitations under the License.</span></div>
<div class="line"><a id="l00014" name="l00014"></a><span class="lineno">   14</span><span class="comment">==============================================================================*/</span></div>
<div class="line"><a id="l00015" name="l00015"></a><span class="lineno">   15</span> </div>
<div class="line"><a id="l00016" name="l00016"></a><span class="lineno">   16</span><span class="preprocessor">#ifndef TENSORFLOW_LITE_KERNELS_INTERNAL_PORTABLE_TENSOR_UTILS_H_</span></div>
<div class="line"><a id="l00017" name="l00017"></a><span class="lineno">   17</span><span class="preprocessor">#define TENSORFLOW_LITE_KERNELS_INTERNAL_PORTABLE_TENSOR_UTILS_H_</span></div>
<div class="line"><a id="l00018" name="l00018"></a><span class="lineno">   18</span> </div>
<div class="line"><a id="l00019" name="l00019"></a><span class="lineno">   19</span><span class="preprocessor">#include &lt;algorithm&gt;</span></div>
<div class="line"><a id="l00020" name="l00020"></a><span class="lineno">   20</span><span class="preprocessor">#include &lt;cmath&gt;</span></div>
<div class="line"><a id="l00021" name="l00021"></a><span class="lineno">   21</span><span class="preprocessor">#include &lt;cstdint&gt;</span></div>
<div class="line"><a id="l00022" name="l00022"></a><span class="lineno">   22</span> </div>
<div class="line"><a id="l00023" name="l00023"></a><span class="lineno">   23</span><span class="preprocessor">#include &quot;tensorflow/lite/core/c/builtin_op_data.h&quot;</span></div>
<div class="line"><a id="l00024" name="l00024"></a><span class="lineno">   24</span><span class="preprocessor">#include &quot;tensorflow/lite/core/c/common.h&quot;</span></div>
<div class="line"><a id="l00025" name="l00025"></a><span class="lineno">   25</span> </div>
<div class="line"><a id="l00026" name="l00026"></a><span class="lineno">   26</span><span class="preprocessor">#if defined(_MSC_VER)</span></div>
<div class="line"><a id="l00027" name="l00027"></a><span class="lineno">   27</span><span class="preprocessor">#define __restrict__ __restrict</span></div>
<div class="line"><a id="l00028" name="l00028"></a><span class="lineno">   28</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00029" name="l00029"></a><span class="lineno">   29</span> </div>
<div class="line"><a id="l00030" name="l00030"></a><span class="lineno">   30</span><span class="keyword">namespace </span><a class="code hl_namespace" href="namespacetflite.html">tflite</a> {</div>
<div class="line"><a id="l00031" name="l00031"></a><span class="lineno">   31</span> </div>
<div class="line"><a id="l00032" name="l00032"></a><span class="lineno">   32</span><span class="comment">// Not all backends support CpuBackendContext usage, so forward declare to avoid</span></div>
<div class="line"><a id="l00033" name="l00033"></a><span class="lineno">   33</span><span class="comment">// pulling in its implementation. Use of CpuBackendContext in method</span></div>
<div class="line"><a id="l00034" name="l00034"></a><span class="lineno">   34</span><span class="comment">// implementations is purely optional.</span></div>
<div class="line"><a id="l00035" name="l00035"></a><span class="lineno">   35</span><span class="keyword">class </span>CpuBackendContext;</div>
<div class="line"><a id="l00036" name="l00036"></a><span class="lineno">   36</span> </div>
<div class="line"><a id="l00037" name="l00037"></a><span class="lineno">   37</span><span class="keyword">namespace </span>tensor_utils {</div>
<div class="line"><a id="l00038" name="l00038"></a><span class="lineno">   38</span> </div>
<div class="line"><a id="l00039" name="l00039"></a><span class="lineno">   39</span><span class="comment">// Multiplies a matrix with a scalar and reduce the result on each row to a</span></div>
<div class="line"><a id="l00040" name="l00040"></a><span class="lineno">   40</span><span class="comment">// scalar.</span></div>
<div class="line"><a id="l00041" name="l00041"></a><span class="lineno">   41</span><span class="comment">// Parameters:</span></div>
<div class="line"><a id="l00042" name="l00042"></a><span class="lineno">   42</span><span class="comment">//     - matrix: matrix of size n_row * n_col</span></div>
<div class="line"><a id="l00043" name="l00043"></a><span class="lineno">   43</span><span class="comment">//     - scalar: the scalar that is multiplied to each element in the matrix</span></div>
<div class="line"><a id="l00044" name="l00044"></a><span class="lineno">   44</span><span class="comment">//     - n_row:  the row count of the matrix</span></div>
<div class="line"><a id="l00045" name="l00045"></a><span class="lineno">   45</span><span class="comment">//     - n_col:  the column count of the matrix</span></div>
<div class="line"><a id="l00046" name="l00046"></a><span class="lineno">   46</span><span class="comment">//     - output: the 32bit output</span></div>
<div class="line"><a id="l00047" name="l00047"></a><span class="lineno">   47</span><span class="comment">// Note: We do not need saturation because the int8 * int8 is safe from overflow</span></div>
<div class="line"><a id="l00048" name="l00048"></a><span class="lineno">   48</span><span class="comment">// in (2^31-1) / (2^14) = 131072, which is bigger than the n_row. Non-zero</span></div>
<div class="line"><a id="l00049" name="l00049"></a><span class="lineno">   49</span><span class="comment">// initial output value is not exceptionally large.</span></div>
<div class="line"><a id="l00050" name="l00050"></a><span class="lineno">   50</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#aa6ec4142f3565c0a51dfc30afc04faed">MatrixScalarMultiplyAccumulate</a>(<span class="keyword">const</span> int8_t* matrix, int32_t scalar,</div>
<div class="line"><a id="l00051" name="l00051"></a><span class="lineno">   51</span>                                    int32_t n_row, int32_t n_col,</div>
<div class="line"><a id="l00052" name="l00052"></a><span class="lineno">   52</span>                                    int32_t* <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcbcd3bbe90c4644d53fde1ce4e312f437.html#a7a2a916a8059078c2d7a05f46c7126fd">output</a>);</div>
<div class="line"><a id="l00053" name="l00053"></a><span class="lineno">   53</span> </div>
<div class="line"><a id="l00054" name="l00054"></a><span class="lineno">   54</span><span class="comment">// Add another vector for each batch in the batch vector.</span></div>
<div class="line"><a id="l00055" name="l00055"></a><span class="lineno">   55</span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00056" data-start="{" data-end="}">
<div class="line"><a id="l00056" name="l00056"></a><span class="lineno"><a class="line" href="namespacetflite_1_1tensor__utils.html#a19871bdff4f6f49d47a03aba2187f2e4">   56</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a19871bdff4f6f49d47a03aba2187f2e4">VectorBatchVectorAdd</a>(<span class="keyword">const</span> T* vector, <span class="keywordtype">int</span> v_size, <span class="keywordtype">int</span> n_batch,</div>
<div class="line"><a id="l00057" name="l00057"></a><span class="lineno">   57</span>                          T* batch_vector) {</div>
<div class="line"><a id="l00058" name="l00058"></a><span class="lineno">   58</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> <a class="code hl_variable" href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a> = 0; <a class="code hl_variable" href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a> &lt; n_batch; <a class="code hl_variable" href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a>++) {</div>
<div class="line"><a id="l00059" name="l00059"></a><span class="lineno">   59</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; v_size; ++i) {</div>
<div class="line"><a id="l00060" name="l00060"></a><span class="lineno">   60</span>      batch_vector[i] += vector[i];</div>
<div class="line"><a id="l00061" name="l00061"></a><span class="lineno">   61</span>    }</div>
<div class="line"><a id="l00062" name="l00062"></a><span class="lineno">   62</span>    batch_vector += v_size;</div>
<div class="line"><a id="l00063" name="l00063"></a><span class="lineno">   63</span>  }</div>
<div class="line"><a id="l00064" name="l00064"></a><span class="lineno">   64</span>}</div>
</div>
<div class="line"><a id="l00065" name="l00065"></a><span class="lineno">   65</span> </div>
<div class="line"><a id="l00066" name="l00066"></a><span class="lineno">   66</span><span class="comment">// Cwise product of two vectors.</span></div>
<div class="line"><a id="l00067" name="l00067"></a><span class="lineno">   67</span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00068" data-start="{" data-end="}">
<div class="line"><a id="l00068" name="l00068"></a><span class="lineno"><a class="line" href="namespacetflite_1_1tensor__utils.html#af2d6ac1d9d03ebac78f7d6346ac0ae83">   68</a></span><span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#af2d6ac1d9d03ebac78f7d6346ac0ae83">VectorVectorCwiseProduct</a>(<span class="keyword">const</span> T* vector1, <span class="keyword">const</span> T* vector2,</div>
<div class="line"><a id="l00069" name="l00069"></a><span class="lineno">   69</span>                                     <span class="keywordtype">int</span> v_size, T* <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>) {</div>
<div class="line"><a id="l00070" name="l00070"></a><span class="lineno">   70</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> v = 0; v &lt; v_size; v++) {</div>
<div class="line"><a id="l00071" name="l00071"></a><span class="lineno">   71</span>    *<a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>++ = *vector1++ * *vector2++;</div>
<div class="line"><a id="l00072" name="l00072"></a><span class="lineno">   72</span>  }</div>
<div class="line"><a id="l00073" name="l00073"></a><span class="lineno">   73</span>}</div>
</div>
<div class="line"><a id="l00074" name="l00074"></a><span class="lineno">   74</span> </div>
<div class="line"><a id="l00075" name="l00075"></a><span class="lineno">   75</span><span class="comment">// Cwise product of a vector and a batch-vector.</span></div>
<div class="line"><a id="l00076" name="l00076"></a><span class="lineno">   76</span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00077" data-start="{" data-end="}">
<div class="line"><a id="l00077" name="l00077"></a><span class="lineno"><a class="line" href="namespacetflite_1_1tensor__utils.html#a0ac4e61f41d58b070565ba9dc029bad3">   77</a></span><span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a0ac4e61f41d58b070565ba9dc029bad3">VectorBatchVectorCwiseProduct</a>(<span class="keyword">const</span> T* vector, <span class="keywordtype">int</span> v_size,</div>
<div class="line"><a id="l00078" name="l00078"></a><span class="lineno">   78</span>                                          <span class="keyword">const</span> T* batch_vector, <span class="keywordtype">int</span> n_batch,</div>
<div class="line"><a id="l00079" name="l00079"></a><span class="lineno">   79</span>                                          T* <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>) {</div>
<div class="line"><a id="l00080" name="l00080"></a><span class="lineno">   80</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> <a class="code hl_variable" href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a> = 0; <a class="code hl_variable" href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a> &lt; n_batch; <a class="code hl_variable" href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a>++) {</div>
<div class="line"><a id="l00081" name="l00081"></a><span class="lineno">   81</span>    <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#af2d6ac1d9d03ebac78f7d6346ac0ae83">VectorVectorCwiseProduct</a>(vector, batch_vector, v_size, <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>);</div>
<div class="line"><a id="l00082" name="l00082"></a><span class="lineno">   82</span>    <span class="comment">// Update the pointers.</span></div>
<div class="line"><a id="l00083" name="l00083"></a><span class="lineno">   83</span>    <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a> += v_size;</div>
<div class="line"><a id="l00084" name="l00084"></a><span class="lineno">   84</span>    batch_vector += v_size;</div>
<div class="line"><a id="l00085" name="l00085"></a><span class="lineno">   85</span>  }</div>
<div class="line"><a id="l00086" name="l00086"></a><span class="lineno">   86</span>}</div>
</div>
<div class="line"><a id="l00087" name="l00087"></a><span class="lineno">   87</span> </div>
<div class="line"><a id="l00088" name="l00088"></a><span class="lineno">   88</span><span class="comment">// Cwise product and accumulate of two vectors. Since it&#39;s a MAC operation, the</span></div>
<div class="line"><a id="l00089" name="l00089"></a><span class="lineno">   89</span><span class="comment">// assumption here is that result array is initialized to valid values.</span></div>
<div class="line"><a id="l00090" name="l00090"></a><span class="lineno">   90</span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00091" data-start="{" data-end="}">
<div class="line"><a id="l00091" name="l00091"></a><span class="lineno"><a class="line" href="namespacetflite_1_1tensor__utils.html#a8e089876da3bd7d112db1849f601cf95">   91</a></span><span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a8e089876da3bd7d112db1849f601cf95">VectorVectorCwiseProductAccumulate</a>(<span class="keyword">const</span> T* __restrict__ vector1,</div>
<div class="line"><a id="l00092" name="l00092"></a><span class="lineno">   92</span>                                               <span class="keyword">const</span> T* __restrict__ vector2,</div>
<div class="line"><a id="l00093" name="l00093"></a><span class="lineno">   93</span>                                               <span class="keywordtype">int</span> v_size,</div>
<div class="line"><a id="l00094" name="l00094"></a><span class="lineno">   94</span>                                               T* __restrict__ <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>) {</div>
<div class="line"><a id="l00095" name="l00095"></a><span class="lineno">   95</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> v = 0; v &lt; v_size; v++) {</div>
<div class="line"><a id="l00096" name="l00096"></a><span class="lineno">   96</span>    *<a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>++ += *vector1++ * *vector2++;</div>
<div class="line"><a id="l00097" name="l00097"></a><span class="lineno">   97</span>  }</div>
<div class="line"><a id="l00098" name="l00098"></a><span class="lineno">   98</span>}</div>
</div>
<div class="line"><a id="l00099" name="l00099"></a><span class="lineno">   99</span> </div>
<div class="line"><a id="l00100" name="l00100"></a><span class="lineno">  100</span><span class="comment">// Cwise product and accumulate of a vector and a batch-vector. Since it&#39;s a MAC</span></div>
<div class="line"><a id="l00101" name="l00101"></a><span class="lineno">  101</span><span class="comment">// operation, the assumption here is that result array is initialized to valid</span></div>
<div class="line"><a id="l00102" name="l00102"></a><span class="lineno">  102</span><span class="comment">// values.</span></div>
<div class="line"><a id="l00103" name="l00103"></a><span class="lineno">  103</span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00104" data-start="{" data-end="}">
<div class="line"><a id="l00104" name="l00104"></a><span class="lineno"><a class="line" href="namespacetflite_1_1tensor__utils.html#acd7492f35f64a6801fedf426f5f6a4fd">  104</a></span><span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#acd7492f35f64a6801fedf426f5f6a4fd">VectorBatchVectorCwiseProductAccumulate</a>(<span class="keyword">const</span> T* vector, <span class="keywordtype">int</span> v_size,</div>
<div class="line"><a id="l00105" name="l00105"></a><span class="lineno">  105</span>                                                    <span class="keyword">const</span> T* batch_vector,</div>
<div class="line"><a id="l00106" name="l00106"></a><span class="lineno">  106</span>                                                    <span class="keywordtype">int</span> n_batch, T* <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>) {</div>
<div class="line"><a id="l00107" name="l00107"></a><span class="lineno">  107</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> <a class="code hl_variable" href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a> = 0; <a class="code hl_variable" href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a> &lt; n_batch; <a class="code hl_variable" href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a>++) {</div>
<div class="line"><a id="l00108" name="l00108"></a><span class="lineno">  108</span>    <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a8e089876da3bd7d112db1849f601cf95">VectorVectorCwiseProductAccumulate</a>(vector, batch_vector, v_size, <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>);</div>
<div class="line"><a id="l00109" name="l00109"></a><span class="lineno">  109</span>    <span class="comment">// Update the pointers.</span></div>
<div class="line"><a id="l00110" name="l00110"></a><span class="lineno">  110</span>    <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a> += v_size;</div>
<div class="line"><a id="l00111" name="l00111"></a><span class="lineno">  111</span>    batch_vector += v_size;</div>
<div class="line"><a id="l00112" name="l00112"></a><span class="lineno">  112</span>  }</div>
<div class="line"><a id="l00113" name="l00113"></a><span class="lineno">  113</span>}</div>
</div>
<div class="line"><a id="l00114" name="l00114"></a><span class="lineno">  114</span> </div>
<div class="line"><a id="l00115" name="l00115"></a><span class="lineno">  115</span><span class="comment">// Batch vector initialization with another vector.</span></div>
<div class="line"><a id="l00116" name="l00116"></a><span class="lineno">  116</span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00117" data-start="{" data-end="}">
<div class="line"><a id="l00117" name="l00117"></a><span class="lineno"><a class="line" href="namespacetflite_1_1tensor__utils.html#ad73fe84d0b228eaaad81a948ad29af79">  117</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#ad73fe84d0b228eaaad81a948ad29af79">VectorBatchVectorAssign</a>(<span class="keyword">const</span> T* vector, <span class="keywordtype">int</span> v_size, <span class="keywordtype">int</span> n_batch,</div>
<div class="line"><a id="l00118" name="l00118"></a><span class="lineno">  118</span>                             T* batch_vector) {</div>
<div class="line"><a id="l00119" name="l00119"></a><span class="lineno">  119</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> <a class="code hl_variable" href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a> = 0; <a class="code hl_variable" href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a> &lt; n_batch; <a class="code hl_variable" href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a>++) {</div>
<div class="line"><a id="l00120" name="l00120"></a><span class="lineno">  120</span>    std::copy_n(vector, v_size, batch_vector + <a class="code hl_variable" href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a> * v_size);</div>
<div class="line"><a id="l00121" name="l00121"></a><span class="lineno">  121</span>  }</div>
<div class="line"><a id="l00122" name="l00122"></a><span class="lineno">  122</span>}</div>
</div>
<div class="line"><a id="l00123" name="l00123"></a><span class="lineno">  123</span> </div>
<div class="line"><a id="l00124" name="l00124"></a><span class="lineno">  124</span><span class="comment">// Checks if all entries of vector are zero for float.</span></div>
<div class="line"><a id="l00125" name="l00125"></a><span class="lineno">  125</span><span class="keywordtype">bool</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a1f49fa548503159cd9a4ca681bf2c978">IsZeroVector</a>(<span class="keyword">const</span> <span class="keywordtype">float</span>* vector, <span class="keywordtype">int</span> v_size);</div>
<div class="line"><a id="l00126" name="l00126"></a><span class="lineno">  126</span> </div>
<div class="line"><a id="l00127" name="l00127"></a><span class="lineno">  127</span><span class="comment">// Checks if all entries of vector are zero for int8.</span></div>
<div class="line"><a id="l00128" name="l00128"></a><span class="lineno">  128</span><span class="keywordtype">bool</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a1f49fa548503159cd9a4ca681bf2c978">IsZeroVector</a>(<span class="keyword">const</span> int8_t* vector, <span class="keywordtype">int</span> v_size);</div>
<div class="line"><a id="l00129" name="l00129"></a><span class="lineno">  129</span> </div>
<div class="line"><a id="l00130" name="l00130"></a><span class="lineno">  130</span><span class="comment">// Quantizes a buffer of floating point values using a symmetric quantization</span></div>
<div class="line"><a id="l00131" name="l00131"></a><span class="lineno">  131</span><span class="comment">// (i.e. linear quantization without an offset) to 8-bit signed integers.</span></div>
<div class="line"><a id="l00132" name="l00132"></a><span class="lineno">  132</span><span class="comment">// It also outputs the range (min, max) of the floating point buffer, and the</span></div>
<div class="line"><a id="l00133" name="l00133"></a><span class="lineno">  133</span><span class="comment">// scaling factor used to quantize the values.</span></div>
<div class="line"><a id="l00134" name="l00134"></a><span class="lineno">  134</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#ad6f6cd2bf307d9d709470b6ee892aa4d">SymmetricQuantizeFloats</a>(<span class="keyword">const</span> <span class="keywordtype">float</span>* values, <span class="keyword">const</span> <span class="keywordtype">int</span> <a class="code hl_variable" href="hello__world__model_8cc.html#a439227feff9d7f55384e8780cfc2eb82">size</a>,</div>
<div class="line"><a id="l00135" name="l00135"></a><span class="lineno">  135</span>                             int8_t* quantized_values, <span class="keywordtype">float</span>* min_value,</div>
<div class="line"><a id="l00136" name="l00136"></a><span class="lineno">  136</span>                             <span class="keywordtype">float</span>* max_value, <span class="keywordtype">float</span>* scaling_factor);</div>
<div class="line"><a id="l00137" name="l00137"></a><span class="lineno">  137</span> </div>
<div class="line"><a id="l00138" name="l00138"></a><span class="lineno">  138</span><span class="comment">// Quantizes a buffer of floating point values using a symmetric quantization</span></div>
<div class="line"><a id="l00139" name="l00139"></a><span class="lineno">  139</span><span class="comment">// (i.e. linear quantization without an offset) to 8-bit signed integers.</span></div>
<div class="line"><a id="l00140" name="l00140"></a><span class="lineno">  140</span><span class="comment">// It uses the range (min, max) provided to the function to calculate the</span></div>
<div class="line"><a id="l00141" name="l00141"></a><span class="lineno">  141</span><span class="comment">// appropriate scaling factor to quantize the values.</span></div>
<div class="line"><a id="l00142" name="l00142"></a><span class="lineno">  142</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#ad6f6cd2bf307d9d709470b6ee892aa4d">SymmetricQuantizeFloats</a>(<span class="keyword">const</span> <span class="keywordtype">float</span>* values, <span class="keyword">const</span> <span class="keywordtype">int</span> <a class="code hl_variable" href="hello__world__model_8cc.html#a439227feff9d7f55384e8780cfc2eb82">size</a>,</div>
<div class="line"><a id="l00143" name="l00143"></a><span class="lineno">  143</span>                             int8_t* quantized_values, <span class="keywordtype">float</span> min_value,</div>
<div class="line"><a id="l00144" name="l00144"></a><span class="lineno">  144</span>                             <span class="keywordtype">float</span> max_value, <span class="keywordtype">float</span>* scaling_factor);</div>
<div class="line"><a id="l00145" name="l00145"></a><span class="lineno">  145</span> </div>
<div class="line"><a id="l00146" name="l00146"></a><span class="lineno">  146</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#aaca4048cfd0807a5ddb517474f3178d7">AsymmetricQuantizeFloats</a>(<span class="keyword">const</span> <span class="keywordtype">float</span>* values, <span class="keyword">const</span> <span class="keywordtype">int</span> <a class="code hl_variable" href="hello__world__model_8cc.html#a439227feff9d7f55384e8780cfc2eb82">size</a>,</div>
<div class="line"><a id="l00147" name="l00147"></a><span class="lineno">  147</span>                              int8_t* quantized_values, <span class="keywordtype">float</span>* scaling_factor,</div>
<div class="line"><a id="l00148" name="l00148"></a><span class="lineno">  148</span>                              int32_t* <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcaf138809236f667e9686fdd4aaf17705.html#aed7ea92f45bd273dde380a45ddced592">offset</a>);</div>
<div class="line"><a id="l00149" name="l00149"></a><span class="lineno">  149</span> </div>
<div class="line"><a id="l00150" name="l00150"></a><span class="lineno">  150</span><span class="comment">// Helper function to quantize floats.</span></div>
<div class="line"><a id="l00151" name="l00151"></a><span class="lineno">  151</span><span class="comment">// float_data_ptr     input float vectors</span></div>
<div class="line"><a id="l00152" name="l00152"></a><span class="lineno">  152</span><span class="comment">// n_batch            number of input vectors</span></div>
<div class="line"><a id="l00153" name="l00153"></a><span class="lineno">  153</span><span class="comment">// n_data             size of a single input vector</span></div>
<div class="line"><a id="l00154" name="l00154"></a><span class="lineno">  154</span><span class="comment">// quantized_data_ptr (out) vector with quantized data</span></div>
<div class="line"><a id="l00155" name="l00155"></a><span class="lineno">  155</span><span class="comment">// scaling_factors    (out) scaling factors (one per vector)</span></div>
<div class="line"><a id="l00156" name="l00156"></a><span class="lineno">  156</span><span class="comment">// zero_points        (out) zero points (one per vector)</span></div>
<div class="line"><a id="l00157" name="l00157"></a><span class="lineno">  157</span><span class="comment">// do_asymmetric      controls if the quantization should be asymmetric.</span></div>
<div class="foldopen" id="foldopen00158" data-start="{" data-end="}">
<div class="line"><a id="l00158" name="l00158"></a><span class="lineno"><a class="line" href="namespacetflite_1_1tensor__utils.html#a641279c30789a1307fc603a4371694eb">  158</a></span><span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a641279c30789a1307fc603a4371694eb">BatchQuantizeFloats</a>(<span class="keyword">const</span> <span class="keywordtype">float</span>* float_data_ptr, <span class="keywordtype">int</span> n_batch,</div>
<div class="line"><a id="l00159" name="l00159"></a><span class="lineno">  159</span>                                <span class="keywordtype">int</span> n_data, int8_t* quantized_data_ptr,</div>
<div class="line"><a id="l00160" name="l00160"></a><span class="lineno">  160</span>                                <span class="keywordtype">float</span>* scaling_factors, int32_t* zero_points,</div>
<div class="line"><a id="l00161" name="l00161"></a><span class="lineno">  161</span>                                <span class="keywordtype">bool</span> do_asymmetric) {</div>
<div class="line"><a id="l00162" name="l00162"></a><span class="lineno">  162</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> <a class="code hl_variable" href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a> = 0; <a class="code hl_variable" href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a> &lt; n_batch; ++<a class="code hl_variable" href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a>) {</div>
<div class="line"><a id="l00163" name="l00163"></a><span class="lineno">  163</span>    <span class="keyword">const</span> <span class="keywordtype">int</span> <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcaf138809236f667e9686fdd4aaf17705.html#aed7ea92f45bd273dde380a45ddced592">offset</a> = <a class="code hl_variable" href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a> * n_data;</div>
<div class="line"><a id="l00164" name="l00164"></a><span class="lineno">  164</span>    <span class="keywordflow">if</span> (do_asymmetric) {</div>
<div class="line"><a id="l00165" name="l00165"></a><span class="lineno">  165</span>      <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#aaca4048cfd0807a5ddb517474f3178d7">tensor_utils::AsymmetricQuantizeFloats</a>(</div>
<div class="line"><a id="l00166" name="l00166"></a><span class="lineno">  166</span>          float_data_ptr + <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcaf138809236f667e9686fdd4aaf17705.html#aed7ea92f45bd273dde380a45ddced592">offset</a>, n_data, quantized_data_ptr + <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcaf138809236f667e9686fdd4aaf17705.html#aed7ea92f45bd273dde380a45ddced592">offset</a>,</div>
<div class="line"><a id="l00167" name="l00167"></a><span class="lineno">  167</span>          &amp;scaling_factors[<a class="code hl_variable" href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a>], &amp;zero_points[<a class="code hl_variable" href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a>]);</div>
<div class="line"><a id="l00168" name="l00168"></a><span class="lineno">  168</span>    } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00169" name="l00169"></a><span class="lineno">  169</span>      <span class="keywordtype">float</span> unused_min, unused_max;</div>
<div class="line"><a id="l00170" name="l00170"></a><span class="lineno">  170</span>      <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#ad6f6cd2bf307d9d709470b6ee892aa4d">tensor_utils::SymmetricQuantizeFloats</a>(</div>
<div class="line"><a id="l00171" name="l00171"></a><span class="lineno">  171</span>          float_data_ptr + <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcaf138809236f667e9686fdd4aaf17705.html#aed7ea92f45bd273dde380a45ddced592">offset</a>, n_data, quantized_data_ptr + <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcaf138809236f667e9686fdd4aaf17705.html#aed7ea92f45bd273dde380a45ddced592">offset</a>,</div>
<div class="line"><a id="l00172" name="l00172"></a><span class="lineno">  172</span>          &amp;unused_min, &amp;unused_max, &amp;scaling_factors[<a class="code hl_variable" href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a>]);</div>
<div class="line"><a id="l00173" name="l00173"></a><span class="lineno">  173</span>    }</div>
<div class="line"><a id="l00174" name="l00174"></a><span class="lineno">  174</span>  }</div>
<div class="line"><a id="l00175" name="l00175"></a><span class="lineno">  175</span>}</div>
</div>
<div class="line"><a id="l00176" name="l00176"></a><span class="lineno">  176</span> </div>
<div class="line"><a id="l00177" name="l00177"></a><span class="lineno">  177</span><span class="comment">// Multiplies a matrix by a &quot;batched&quot; vector (i.e. a matrix with a batch</span></div>
<div class="line"><a id="l00178" name="l00178"></a><span class="lineno">  178</span><span class="comment">// dimension composed by input vectors independent from each other). The result</span></div>
<div class="line"><a id="l00179" name="l00179"></a><span class="lineno">  179</span><span class="comment">// of the multiplication is accumulated to the passed result buffer.</span></div>
<div class="line"><a id="l00180" name="l00180"></a><span class="lineno">  180</span><span class="comment">// More specifically, for a matrix M of shape [n, i] and a batched-vector</span></div>
<div class="line"><a id="l00181" name="l00181"></a><span class="lineno">  181</span><span class="comment">// of shape [i, batch] it will first compute the product of shape [n, batch].</span></div>
<div class="line"><a id="l00182" name="l00182"></a><span class="lineno">  182</span><span class="comment">// This product will be accumulated to the result buffer.</span></div>
<div class="line"><a id="l00183" name="l00183"></a><span class="lineno">  183</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a7fa83cbe789fcec252e1f8fad0dded14">MatrixBatchVectorMultiplyAccumulate</a>(<span class="keyword">const</span> <span class="keywordtype">float</span>* matrix, <span class="keywordtype">int</span> m_rows,</div>
<div class="line"><a id="l00184" name="l00184"></a><span class="lineno">  184</span>                                         <span class="keywordtype">int</span> m_cols, <span class="keyword">const</span> <span class="keywordtype">float</span>* vector,</div>
<div class="line"><a id="l00185" name="l00185"></a><span class="lineno">  185</span>                                         <span class="keywordtype">int</span> n_batch, <span class="keywordtype">float</span>* <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>);</div>
<div class="line"><a id="l00186" name="l00186"></a><span class="lineno">  186</span> </div>
<div class="line"><a id="l00187" name="l00187"></a><span class="lineno">  187</span><span class="comment">// Same as the function above, but the matrix is a sparse tensor with block</span></div>
<div class="line"><a id="l00188" name="l00188"></a><span class="lineno">  188</span><span class="comment">// pattern 1x4.</span></div>
<div class="line"><a id="l00189" name="l00189"></a><span class="lineno">  189</span><span class="comment">// This function assumes that m_cols is a multiple of the block size (4 in this</span></div>
<div class="line"><a id="l00190" name="l00190"></a><span class="lineno">  190</span><span class="comment">// case) so that there&#39;s no incomplete block.</span></div>
<div class="line"><a id="l00191" name="l00191"></a><span class="lineno">  191</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#ac03f033f390956884a385cbfe69e81ee">SparseMatrixBatchVectorMultiplyAccumulate1x4</a>(</div>
<div class="line"><a id="l00192" name="l00192"></a><span class="lineno">  192</span>    <span class="keyword">const</span> <span class="keywordtype">float</span>* __restrict__ matrix, <span class="keyword">const</span> int32_t* __restrict__ segments,</div>
<div class="line"><a id="l00193" name="l00193"></a><span class="lineno">  193</span>    <span class="keyword">const</span> int32_t* __restrict__ indices, <span class="keywordtype">int</span> m_rows, <span class="keywordtype">int</span> m_cols,</div>
<div class="line"><a id="l00194" name="l00194"></a><span class="lineno">  194</span>    <span class="keyword">const</span> <span class="keywordtype">float</span>* __restrict__ vector, <span class="keywordtype">int</span> n_batch, <span class="keywordtype">float</span>* __restrict__ <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>);</div>
<div class="line"><a id="l00195" name="l00195"></a><span class="lineno">  195</span> </div>
<div class="line"><a id="l00196" name="l00196"></a><span class="lineno">  196</span><span class="comment">// Same as the function above, but the matrix is stored in block compressed</span></div>
<div class="line"><a id="l00197" name="l00197"></a><span class="lineno">  197</span><span class="comment">// sparse row format with block pattern 1x16 which consists of two arrays:</span></div>
<div class="line"><a id="l00198" name="l00198"></a><span class="lineno">  198</span><span class="comment">//   1. A matrix array stores non-zero blocks of the matrix in row major.</span></div>
<div class="line"><a id="l00199" name="l00199"></a><span class="lineno">  199</span><span class="comment">//   2. A ledger array stores nrows groups, one group per row. Each group starts</span></div>
<div class="line"><a id="l00200" name="l00200"></a><span class="lineno">  200</span><span class="comment">//      with an integer representing the number of non-zero blocks for the</span></div>
<div class="line"><a id="l00201" name="l00201"></a><span class="lineno">  201</span><span class="comment">//      corresponding row and follows with column indexes of the first element</span></div>
<div class="line"><a id="l00202" name="l00202"></a><span class="lineno">  202</span><span class="comment">//      of each non-zero block.</span></div>
<div class="line"><a id="l00203" name="l00203"></a><span class="lineno">  203</span><span class="comment">// This function assumes that</span></div>
<div class="line"><a id="l00204" name="l00204"></a><span class="lineno">  204</span><span class="comment">//   1. m_cols is a multiple of 16 so that all blocks are full blocks.</span></div>
<div class="line"><a id="l00205" name="l00205"></a><span class="lineno">  205</span><span class="comment">//   2. m_cols &lt; 254 * 16 so that block index can be represented by uint8.</span></div>
<div class="line"><a id="l00206" name="l00206"></a><span class="lineno">  206</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a246aaabdf1fa73214eabbd1953d2647b">SparseMatrixBatchVectorMultiplyAccumulate</a>(</div>
<div class="line"><a id="l00207" name="l00207"></a><span class="lineno">  207</span>    <span class="keyword">const</span> <span class="keywordtype">float</span>* __restrict__ matrix, <span class="keyword">const</span> uint8_t* __restrict__ ledger,</div>
<div class="line"><a id="l00208" name="l00208"></a><span class="lineno">  208</span>    <span class="keywordtype">int</span> m_rows, <span class="keywordtype">int</span> m_cols, <span class="keyword">const</span> <span class="keywordtype">float</span>* __restrict__ vector, <span class="keywordtype">int</span> n_batch,</div>
<div class="line"><a id="l00209" name="l00209"></a><span class="lineno">  209</span>    <span class="keywordtype">float</span>* __restrict__ <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>);</div>
<div class="line"><a id="l00210" name="l00210"></a><span class="lineno">  210</span> </div>
<div class="line"><a id="l00211" name="l00211"></a><span class="lineno">  211</span><span class="comment">// Same as the function above, but for values quantized using symmetric</span></div>
<div class="line"><a id="l00212" name="l00212"></a><span class="lineno">  212</span><span class="comment">// quantization (e.g. by calling SymmetricQuantizeFloats).</span></div>
<div class="line"><a id="l00213" name="l00213"></a><span class="lineno">  213</span><span class="comment">// The passed scaling factors is a buffer of the quantization scaling factors</span></div>
<div class="line"><a id="l00214" name="l00214"></a><span class="lineno">  214</span><span class="comment">// that will be used to dequentize the products into the final result buffer.</span></div>
<div class="line"><a id="l00215" name="l00215"></a><span class="lineno">  215</span><span class="comment">// These scaling factors are the multiplication of the matrix scaling factor</span></div>
<div class="line"><a id="l00216" name="l00216"></a><span class="lineno">  216</span><span class="comment">// by the vector&#39;s scaling factor, one per batch (i.e. this allows quantizing</span></div>
<div class="line"><a id="l00217" name="l00217"></a><span class="lineno">  217</span><span class="comment">// each batch in the batch-vector matrix independently).</span></div>
<div class="line"><a id="l00218" name="l00218"></a><span class="lineno"><a class="line" href="namespacetflite_1_1tensor__utils.html#a71e36ec27c1258f55aba82a3526ec7b9">  218</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a7fa83cbe789fcec252e1f8fad0dded14">MatrixBatchVectorMultiplyAccumulate</a>(</div>
<div class="line"><a id="l00219" name="l00219"></a><span class="lineno">  219</span>    <span class="keyword">const</span> int8_t* __restrict__ matrix, <span class="keyword">const</span> <span class="keywordtype">int</span> m_rows, <span class="keyword">const</span> <span class="keywordtype">int</span> m_cols,</div>
<div class="line"><a id="l00220" name="l00220"></a><span class="lineno">  220</span>    <span class="keyword">const</span> int8_t* __restrict__ vectors,</div>
<div class="line"><a id="l00221" name="l00221"></a><span class="lineno">  221</span>    <span class="keyword">const</span> <span class="keywordtype">float</span>* __restrict__ scaling_factors, <span class="keywordtype">int</span> n_batch,</div>
<div class="line"><a id="l00222" name="l00222"></a><span class="lineno">  222</span>    <span class="keywordtype">float</span>* __restrict__ <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>);</div>
<div class="line"><a id="l00223" name="l00223"></a><span class="lineno">  223</span> </div>
<div class="line"><a id="l00224" name="l00224"></a><span class="lineno">  224</span><span class="comment">// Same as the function above except that vector values</span></div>
<div class="line"><a id="l00225" name="l00225"></a><span class="lineno">  225</span><span class="comment">// are quantized with asymmetric quantization per-batch and the matrix</span></div>
<div class="line"><a id="l00226" name="l00226"></a><span class="lineno">  226</span><span class="comment">// is quantized per row.</span></div>
<div class="line"><a id="l00227" name="l00227"></a><span class="lineno"><a class="line" href="namespacetflite_1_1tensor__utils.html#a0557e0c4b35c90de79fd21e3ec657c6a">  227</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a7fa83cbe789fcec252e1f8fad0dded14">MatrixBatchVectorMultiplyAccumulate</a>(</div>
<div class="line"><a id="l00228" name="l00228"></a><span class="lineno">  228</span>    <span class="keyword">const</span> int8_t* __restrict__ matrix, <span class="keyword">const</span> <span class="keywordtype">int</span> m_rows, <span class="keyword">const</span> <span class="keywordtype">int</span> m_cols,</div>
<div class="line"><a id="l00229" name="l00229"></a><span class="lineno">  229</span>    <span class="keyword">const</span> int8_t* __restrict__ vectors,</div>
<div class="line"><a id="l00230" name="l00230"></a><span class="lineno">  230</span>    <span class="keyword">const</span> <span class="keywordtype">float</span>* __restrict__ scaling_factors, <span class="keywordtype">int</span> n_batch,</div>
<div class="line"><a id="l00231" name="l00231"></a><span class="lineno">  231</span>    <span class="keywordtype">float</span>* __restrict__ <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>, <span class="keyword">const</span> <span class="keywordtype">float</span>* __restrict__ per_channel_scale,</div>
<div class="line"><a id="l00232" name="l00232"></a><span class="lineno">  232</span>    <span class="keyword">const</span> int32_t* __restrict__ <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src07231aa9a2b381aa3c97687e9f0d823d.html#ad4670fdc658d0517928e6b2c10b2259d">input_offset</a>);</div>
<div class="line"><a id="l00233" name="l00233"></a><span class="lineno">  233</span> </div>
<div class="line"><a id="l00234" name="l00234"></a><span class="lineno">  234</span><span class="comment">// Same as the function above, but the matrix is a sparse tensor with block</span></div>
<div class="line"><a id="l00235" name="l00235"></a><span class="lineno">  235</span><span class="comment">// pattern 1x16.</span></div>
<div class="line"><a id="l00236" name="l00236"></a><span class="lineno">  236</span><span class="comment">// This function assumes that m_cols is a multiple of the block size (16 in this</span></div>
<div class="line"><a id="l00237" name="l00237"></a><span class="lineno">  237</span><span class="comment">// case) so that there&#39;s no incomplete block. Also, it assumes all offsets of</span></div>
<div class="line"><a id="l00238" name="l00238"></a><span class="lineno">  238</span><span class="comment">// input, output and filter are zero.</span></div>
<div class="line"><a id="l00239" name="l00239"></a><span class="lineno">  239</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a3687fefe4c0a7e3d9215f9fb2715a5b9">SparseMatrixBatchVectorMultiplyAccumulate1x16</a>(</div>
<div class="line"><a id="l00240" name="l00240"></a><span class="lineno">  240</span>    <span class="keyword">const</span> int8_t* __restrict__ matrix, <span class="keyword">const</span> int32_t* __restrict__ segments,</div>
<div class="line"><a id="l00241" name="l00241"></a><span class="lineno">  241</span>    <span class="keyword">const</span> int32_t* __restrict__ indices, <span class="keywordtype">int</span> m_rows, <span class="keywordtype">int</span> m_cols,</div>
<div class="line"><a id="l00242" name="l00242"></a><span class="lineno">  242</span>    <span class="keyword">const</span> int8_t* __restrict__ vector, <span class="keyword">const</span> int32_t* __restrict__ bias_vector,</div>
<div class="line"><a id="l00243" name="l00243"></a><span class="lineno">  243</span>    <span class="keywordtype">int</span> n_batch, <span class="keyword">const</span> int32_t <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src07231aa9a2b381aa3c97687e9f0d823d.html#ad4670fdc658d0517928e6b2c10b2259d">input_offset</a>, <span class="keyword">const</span> int32_t <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src07231aa9a2b381aa3c97687e9f0d823d.html#a23e9f0626e0fdd28687b85e5065f904a">output_multiplier</a>,</div>
<div class="line"><a id="l00244" name="l00244"></a><span class="lineno">  244</span>    <span class="keyword">const</span> int32_t <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src07231aa9a2b381aa3c97687e9f0d823d.html#a239169c76410c3a81fd9cba67cc0bc8f">output_shift</a>, <span class="keyword">const</span> int32_t <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src07231aa9a2b381aa3c97687e9f0d823d.html#ab1dde269b1116cc98371e23a97740a58">output_offset</a>,</div>
<div class="line"><a id="l00245" name="l00245"></a><span class="lineno">  245</span>    <span class="keyword">const</span> int32_t <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src07231aa9a2b381aa3c97687e9f0d823d.html#a2e6a27b448848b3057c45363e04b7d0d">output_activation_min</a>, <span class="keyword">const</span> int32_t <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src07231aa9a2b381aa3c97687e9f0d823d.html#aa889d7b51a3f84357d44f05993ac08a1">output_activation_max</a>,</div>
<div class="line"><a id="l00246" name="l00246"></a><span class="lineno">  246</span>    int8_t* __restrict__ <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>);</div>
<div class="line"><a id="l00247" name="l00247"></a><span class="lineno">  247</span> </div>
<div class="line"><a id="l00248" name="l00248"></a><span class="lineno">  248</span><span class="comment">// Same as the function above, but the matrix is stored in block compressed</span></div>
<div class="line"><a id="l00249" name="l00249"></a><span class="lineno">  249</span><span class="comment">// sparse row format with block pattern 1x16 which consists of two arrays:</span></div>
<div class="line"><a id="l00250" name="l00250"></a><span class="lineno">  250</span><span class="comment">//   1. A matrix array stores non-zero blocks of the matrix in row major.</span></div>
<div class="line"><a id="l00251" name="l00251"></a><span class="lineno">  251</span><span class="comment">//   2. A ledger array stores nrows groups, one group per row. Each group starts</span></div>
<div class="line"><a id="l00252" name="l00252"></a><span class="lineno">  252</span><span class="comment">//      with an integer representing the number of non-zero blocks for the</span></div>
<div class="line"><a id="l00253" name="l00253"></a><span class="lineno">  253</span><span class="comment">//      corresponding row followed by column index of the first element of</span></div>
<div class="line"><a id="l00254" name="l00254"></a><span class="lineno">  254</span><span class="comment">//      each non-zero block.</span></div>
<div class="line"><a id="l00255" name="l00255"></a><span class="lineno">  255</span><span class="comment">// This function assumes that</span></div>
<div class="line"><a id="l00256" name="l00256"></a><span class="lineno">  256</span><span class="comment">//   1. m_cols is a multiple of 16 so that all blocks are full blocks.</span></div>
<div class="line"><a id="l00257" name="l00257"></a><span class="lineno">  257</span><span class="comment">//   2. m_cols &lt; 254 * 16 so that block index can be represented by uint8.</span></div>
<div class="line"><a id="l00258" name="l00258"></a><span class="lineno"><a class="line" href="namespacetflite_1_1tensor__utils.html#aa653a719ff27001d66af8999c31422d5">  258</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a246aaabdf1fa73214eabbd1953d2647b">SparseMatrixBatchVectorMultiplyAccumulate</a>(</div>
<div class="line"><a id="l00259" name="l00259"></a><span class="lineno">  259</span>    <span class="keyword">const</span> int8_t* __restrict__ matrix, <span class="keyword">const</span> uint8_t* __restrict__ ledger,</div>
<div class="line"><a id="l00260" name="l00260"></a><span class="lineno">  260</span>    <span class="keyword">const</span> <span class="keywordtype">int</span> m_rows, <span class="keyword">const</span> <span class="keywordtype">int</span> m_cols, <span class="keyword">const</span> int8_t* __restrict__ vectors,</div>
<div class="line"><a id="l00261" name="l00261"></a><span class="lineno">  261</span>    <span class="keyword">const</span> <span class="keywordtype">float</span>* __restrict__ scaling_factors, <span class="keywordtype">int</span> n_batch,</div>
<div class="line"><a id="l00262" name="l00262"></a><span class="lineno">  262</span>    <span class="keywordtype">float</span>* __restrict__ <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>);</div>
<div class="line"><a id="l00263" name="l00263"></a><span class="lineno">  263</span> </div>
<div class="line"><a id="l00264" name="l00264"></a><span class="lineno">  264</span><span class="comment">// Same as the above 8, 8, 8 integer matmul except for the presence of zero</span></div>
<div class="line"><a id="l00265" name="l00265"></a><span class="lineno">  265</span><span class="comment">// point and non-accumulative.</span></div>
<div class="line"><a id="l00266" name="l00266"></a><span class="lineno">  266</span><span class="comment">// TODO(b/148688698): remove this function by folding zero point calculation in</span></div>
<div class="line"><a id="l00267" name="l00267"></a><span class="lineno">  267</span><span class="comment">// prepare() function.</span></div>
<div class="line"><a id="l00268" name="l00268"></a><span class="lineno">  268</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a5c3050bdbd554b288d59a1f909e3034c">MatrixBatchVectorMultiply</a>(<span class="keyword">const</span> int8_t* <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src5afb18c45f6346167aa977a363205143.html#a9cebfb3d6ddd692fbdd268cf4b9ad024">input</a>, int32_t input_zeropoint,</div>
<div class="line"><a id="l00269" name="l00269"></a><span class="lineno">  269</span>                               <span class="keyword">const</span> int8_t* input_to_gate_weights,</div>
<div class="line"><a id="l00270" name="l00270"></a><span class="lineno">  270</span>                               int32_t input_to_gate_effective_scale_a,</div>
<div class="line"><a id="l00271" name="l00271"></a><span class="lineno">  271</span>                               int32_t input_to_gate_effective_scale_b,</div>
<div class="line"><a id="l00272" name="l00272"></a><span class="lineno">  272</span>                               int32_t n_batch, int32_t n_input, int32_t n_cell,</div>
<div class="line"><a id="l00273" name="l00273"></a><span class="lineno">  273</span>                               int8_t* gate_output, int8_t gate_output_zp);</div>
<div class="line"><a id="l00274" name="l00274"></a><span class="lineno">  274</span> </div>
<div class="line"><a id="l00275" name="l00275"></a><span class="lineno">  275</span><span class="comment">// Same as above but has 16 bit and 8 bit input and 8 bit output.</span></div>
<div class="line"><a id="l00276" name="l00276"></a><span class="lineno">  276</span><span class="comment">// Used in projection when hidden is 16bit.</span></div>
<div class="line"><a id="l00277" name="l00277"></a><span class="lineno">  277</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a5c3050bdbd554b288d59a1f909e3034c">MatrixBatchVectorMultiply</a>(<span class="keyword">const</span> int16_t* hidden,</div>
<div class="line"><a id="l00278" name="l00278"></a><span class="lineno">  278</span>                               <span class="keyword">const</span> int8_t* hidden_to_output_weights,</div>
<div class="line"><a id="l00279" name="l00279"></a><span class="lineno">  279</span>                               int32_t proj_effective_scale_a,</div>
<div class="line"><a id="l00280" name="l00280"></a><span class="lineno">  280</span>                               int32_t proj_effective_scale_b,</div>
<div class="line"><a id="l00281" name="l00281"></a><span class="lineno">  281</span>                               <span class="keyword">const</span> int32_t* gate_bias, int32_t n_batch,</div>
<div class="line"><a id="l00282" name="l00282"></a><span class="lineno">  282</span>                               int32_t n_hidden, int32_t n_output,</div>
<div class="line"><a id="l00283" name="l00283"></a><span class="lineno">  283</span>                               int32_t output_zp, int8_t* proj_output);</div>
<div class="line"><a id="l00284" name="l00284"></a><span class="lineno">  284</span> </div>
<div class="line"><a id="l00285" name="l00285"></a><span class="lineno">  285</span><span class="comment">// Apply Layer Normalization (https://arxiv.org/abs/1607.06450) to a Quantized</span></div>
<div class="line"><a id="l00286" name="l00286"></a><span class="lineno">  286</span><span class="comment">// vector.</span></div>
<div class="line"><a id="l00287" name="l00287"></a><span class="lineno">  287</span><span class="comment">// Parameters:</span></div>
<div class="line"><a id="l00288" name="l00288"></a><span class="lineno">  288</span><span class="comment">//     - input: batch vector of size n_batch * n_input; 16 bit.</span></div>
<div class="line"><a id="l00289" name="l00289"></a><span class="lineno">  289</span><span class="comment">//     - layer_norm_weights:  the quantized layer normalization weights.</span></div>
<div class="line"><a id="l00290" name="l00290"></a><span class="lineno">  290</span><span class="comment">//     - bias: the bias for the layer normalization.</span></div>
<div class="line"><a id="l00291" name="l00291"></a><span class="lineno">  291</span><span class="comment">//     - layer_norm_scale_a: multiplier for scale factor.</span></div>
<div class="line"><a id="l00292" name="l00292"></a><span class="lineno">  292</span><span class="comment">//     - layer_norm_scale_b: shift for scale factor.</span></div>
<div class="line"><a id="l00293" name="l00293"></a><span class="lineno">  293</span><span class="comment">//     - variance_limit: the guard to make sure the inverse does not overflow.</span></div>
<div class="line"><a id="l00294" name="l00294"></a><span class="lineno">  294</span><span class="comment">//     - n_batch: the number of batches.</span></div>
<div class="line"><a id="l00295" name="l00295"></a><span class="lineno">  295</span><span class="comment">//     - n_input: the size for input and output.</span></div>
<div class="line"><a id="l00296" name="l00296"></a><span class="lineno">  296</span><span class="comment">//     - output:  the 16 bit output</span></div>
<div class="line"><a id="l00297" name="l00297"></a><span class="lineno">  297</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#ae3a437253dc60babd7f063cddb2f56a4">ApplyLayerNorm</a>(<span class="keyword">const</span> int16_t* <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src5afb18c45f6346167aa977a363205143.html#a9cebfb3d6ddd692fbdd268cf4b9ad024">input</a>, <span class="keyword">const</span> int16_t* layer_norm_weights,</div>
<div class="line"><a id="l00298" name="l00298"></a><span class="lineno">  298</span>                    <span class="keyword">const</span> int32_t* bias, int32_t layer_norm_scale_a,</div>
<div class="line"><a id="l00299" name="l00299"></a><span class="lineno">  299</span>                    int32_t layer_norm_scale_b, int32_t variance_limit,</div>
<div class="line"><a id="l00300" name="l00300"></a><span class="lineno">  300</span>                    <span class="keywordtype">int</span> n_batch, <span class="keywordtype">int</span> n_input, int16_t* <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcbcd3bbe90c4644d53fde1ce4e312f437.html#a7a2a916a8059078c2d7a05f46c7126fd">output</a>);</div>
<div class="line"><a id="l00301" name="l00301"></a><span class="lineno">  301</span> </div>
<div class="line"><a id="l00302" name="l00302"></a><span class="lineno">  302</span><span class="comment">// Same as above but the internal calculation is done in float.</span></div>
<div class="line"><a id="l00303" name="l00303"></a><span class="lineno">  303</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a67bc3bb5ec7593bd567afa6973cffd38">ApplyLayerNormFloat</a>(<span class="keyword">const</span> int16_t* <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src5afb18c45f6346167aa977a363205143.html#a9cebfb3d6ddd692fbdd268cf4b9ad024">input</a>,</div>
<div class="line"><a id="l00304" name="l00304"></a><span class="lineno">  304</span>                         <span class="keyword">const</span> int16_t* layer_norm_weights,</div>
<div class="line"><a id="l00305" name="l00305"></a><span class="lineno">  305</span>                         int32_t layer_norm_scale_a, int32_t layer_norm_scale_b,</div>
<div class="line"><a id="l00306" name="l00306"></a><span class="lineno">  306</span>                         <span class="keyword">const</span> int32_t* bias, <span class="keywordtype">int</span> n_batch, <span class="keywordtype">int</span> n_input,</div>
<div class="line"><a id="l00307" name="l00307"></a><span class="lineno">  307</span>                         int16_t* <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcbcd3bbe90c4644d53fde1ce4e312f437.html#a7a2a916a8059078c2d7a05f46c7126fd">output</a>);</div>
<div class="line"><a id="l00308" name="l00308"></a><span class="lineno">  308</span> </div>
<div class="line"><a id="l00309" name="l00309"></a><span class="lineno">  309</span><span class="comment">// Apply Sigmoid to a quantized vector.</span></div>
<div class="line"><a id="l00310" name="l00310"></a><span class="lineno">  310</span><span class="comment">// Parameters:</span></div>
<div class="line"><a id="l00311" name="l00311"></a><span class="lineno">  311</span><span class="comment">//     - input: batch vector of size n_batch * n_input; 16 bit.</span></div>
<div class="line"><a id="l00312" name="l00312"></a><span class="lineno">  312</span><span class="comment">//     - n_batch: the number of batches.</span></div>
<div class="line"><a id="l00313" name="l00313"></a><span class="lineno">  313</span><span class="comment">//     - n_input: the size for input and output.</span></div>
<div class="line"><a id="l00314" name="l00314"></a><span class="lineno">  314</span><span class="comment">//     - output:  the 16 bit output</span></div>
<div class="line"><a id="l00315" name="l00315"></a><span class="lineno">  315</span><span class="comment">// The input is in Q3.12 format and the output is in Q0.15 format.</span></div>
<div class="line"><a id="l00316" name="l00316"></a><span class="lineno">  316</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#ae8baef2267c575bc54ee5697a7a7277d">ApplySigmoid</a>(<span class="keyword">const</span> int16_t* <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src5afb18c45f6346167aa977a363205143.html#a9cebfb3d6ddd692fbdd268cf4b9ad024">input</a>, int32_t n_batch, int32_t n_input,</div>
<div class="line"><a id="l00317" name="l00317"></a><span class="lineno">  317</span>                  int16_t* <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcbcd3bbe90c4644d53fde1ce4e312f437.html#a7a2a916a8059078c2d7a05f46c7126fd">output</a>);</div>
<div class="line"><a id="l00318" name="l00318"></a><span class="lineno">  318</span> </div>
<div class="line"><a id="l00319" name="l00319"></a><span class="lineno">  319</span><span class="comment">// Same as above but the internal calcualtion is float.</span></div>
<div class="line"><a id="l00320" name="l00320"></a><span class="lineno">  320</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a670f91eba70d2d51dc385fc9f11c6c88">ApplySigmoidFloat</a>(<span class="keyword">const</span> int16_t* <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src5afb18c45f6346167aa977a363205143.html#a9cebfb3d6ddd692fbdd268cf4b9ad024">input</a>, int32_t n_batch, int32_t n_input,</div>
<div class="line"><a id="l00321" name="l00321"></a><span class="lineno">  321</span>                       int16_t* <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcbcd3bbe90c4644d53fde1ce4e312f437.html#a7a2a916a8059078c2d7a05f46c7126fd">output</a>);</div>
<div class="line"><a id="l00322" name="l00322"></a><span class="lineno">  322</span> </div>
<div class="line"><a id="l00323" name="l00323"></a><span class="lineno">  323</span><span class="comment">// Apply Tanh to a quantized vector.</span></div>
<div class="line"><a id="l00324" name="l00324"></a><span class="lineno">  324</span><span class="comment">// Parameters:</span></div>
<div class="line"><a id="l00325" name="l00325"></a><span class="lineno">  325</span><span class="comment">//     - integer_bits: the integer bits of the input.</span></div>
<div class="line"><a id="l00326" name="l00326"></a><span class="lineno">  326</span><span class="comment">//                     Currently supports 0, 1, 2, 3, 4, 5, 6.</span></div>
<div class="line"><a id="l00327" name="l00327"></a><span class="lineno">  327</span><span class="comment">//     - input: batch vector of size n_batch * n_input; 16 bit.</span></div>
<div class="line"><a id="l00328" name="l00328"></a><span class="lineno">  328</span><span class="comment">//     - n_batch: the number of batches.</span></div>
<div class="line"><a id="l00329" name="l00329"></a><span class="lineno">  329</span><span class="comment">//     - n_input: the size for input and output.</span></div>
<div class="line"><a id="l00330" name="l00330"></a><span class="lineno">  330</span><span class="comment">//     - output:  the 16 bit output</span></div>
<div class="line"><a id="l00331" name="l00331"></a><span class="lineno">  331</span><span class="comment">// The input is in Qm.15-m format and the output is in Q0.15 format.</span></div>
<div class="line"><a id="l00332" name="l00332"></a><span class="lineno">  332</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#af5224fd4d02e02759666a101f7ad9b56">ApplyTanh</a>(int32_t intger_bits, <span class="keyword">const</span> int16_t* <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src5afb18c45f6346167aa977a363205143.html#a9cebfb3d6ddd692fbdd268cf4b9ad024">input</a>, int32_t n_batch,</div>
<div class="line"><a id="l00333" name="l00333"></a><span class="lineno">  333</span>               int32_t n_input, int16_t* <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcbcd3bbe90c4644d53fde1ce4e312f437.html#a7a2a916a8059078c2d7a05f46c7126fd">output</a>);</div>
<div class="line"><a id="l00334" name="l00334"></a><span class="lineno">  334</span> </div>
<div class="line"><a id="l00335" name="l00335"></a><span class="lineno">  335</span><span class="comment">// Apply Tanh to a quantized vector. Tbe internal calculation is in float.</span></div>
<div class="line"><a id="l00336" name="l00336"></a><span class="lineno">  336</span><span class="comment">//    - Input has 2^(integer_bits) as scale.</span></div>
<div class="line"><a id="l00337" name="l00337"></a><span class="lineno">  337</span><span class="comment">//    - Output has Q0.15 as scale.</span></div>
<div class="line"><a id="l00338" name="l00338"></a><span class="lineno">  338</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#ad409d55a899099431b20de28fbd10ab0">ApplyTanhFloat</a>(<span class="keyword">const</span> int16_t* <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src5afb18c45f6346167aa977a363205143.html#a9cebfb3d6ddd692fbdd268cf4b9ad024">input</a>, int32_t n_batch, int32_t n_input,</div>
<div class="line"><a id="l00339" name="l00339"></a><span class="lineno">  339</span>                    int32_t integer_bits, int16_t* <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcbcd3bbe90c4644d53fde1ce4e312f437.html#a7a2a916a8059078c2d7a05f46c7126fd">output</a>);</div>
<div class="line"><a id="l00340" name="l00340"></a><span class="lineno">  340</span> </div>
<div class="line"><a id="l00341" name="l00341"></a><span class="lineno">  341</span><span class="comment">// Element-wise multiplication of two quantized vectors.</span></div>
<div class="line"><a id="l00342" name="l00342"></a><span class="lineno">  342</span><span class="comment">// Parameters:</span></div>
<div class="line"><a id="l00343" name="l00343"></a><span class="lineno">  343</span><span class="comment">//     - input_1: batch vector of size n_batch * n_input; 16 bit.</span></div>
<div class="line"><a id="l00344" name="l00344"></a><span class="lineno">  344</span><span class="comment">//     - input_2: batch vector of size n_batch * n_input; 16 bit.</span></div>
<div class="line"><a id="l00345" name="l00345"></a><span class="lineno">  345</span><span class="comment">//     - n_batch: the number of batches.</span></div>
<div class="line"><a id="l00346" name="l00346"></a><span class="lineno">  346</span><span class="comment">//     - n_input: the size for input and output.</span></div>
<div class="line"><a id="l00347" name="l00347"></a><span class="lineno">  347</span><span class="comment">//     - shift:   the shift needed to produce the output.</span></div>
<div class="line"><a id="l00348" name="l00348"></a><span class="lineno">  348</span><span class="comment">//     - output:  the 16 bit output of size n_batch * n_input.</span></div>
<div class="line"><a id="l00349" name="l00349"></a><span class="lineno">  349</span><span class="comment">// Output does not need to be initialized.</span></div>
<div class="line"><a id="l00350" name="l00350"></a><span class="lineno">  350</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a00b791515d2acb7d88f09cfd9cddd2bf">CwiseMul</a>(<span class="keyword">const</span> int16_t* input_1, <span class="keyword">const</span> int16_t* input_2, <span class="keywordtype">int</span> n_batch,</div>
<div class="line"><a id="l00351" name="l00351"></a><span class="lineno">  351</span>              <span class="keywordtype">int</span> n_input, <span class="keywordtype">int</span> <a class="code hl_variable" href="wm8960__regs_8h.html#ace4e4903c356d90d7a0e7548fc1e8b50">shift</a>, int16_t* <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcbcd3bbe90c4644d53fde1ce4e312f437.html#a7a2a916a8059078c2d7a05f46c7126fd">output</a>);</div>
<div class="line"><a id="l00352" name="l00352"></a><span class="lineno">  352</span> </div>
<div class="line"><a id="l00353" name="l00353"></a><span class="lineno">  353</span><span class="comment">// Element-wise multiplication of two quantized vectors.</span></div>
<div class="line"><a id="l00354" name="l00354"></a><span class="lineno">  354</span><span class="comment">// Parameters:</span></div>
<div class="line"><a id="l00355" name="l00355"></a><span class="lineno">  355</span><span class="comment">//     - input_1: batch vector of size n_batch * n_input; 16 bit.</span></div>
<div class="line"><a id="l00356" name="l00356"></a><span class="lineno">  356</span><span class="comment">//     - input_2: batch vector of size n_batch * n_input; 16 bit.</span></div>
<div class="line"><a id="l00357" name="l00357"></a><span class="lineno">  357</span><span class="comment">//     - n_batch: the number of batches.</span></div>
<div class="line"><a id="l00358" name="l00358"></a><span class="lineno">  358</span><span class="comment">//     - n_input: the size for input and output.</span></div>
<div class="line"><a id="l00359" name="l00359"></a><span class="lineno">  359</span><span class="comment">//     - shift:   the shift needed to produce the output.</span></div>
<div class="line"><a id="l00360" name="l00360"></a><span class="lineno">  360</span><span class="comment">//     - output:  the 8 bit output of size n_batch * n_input.</span></div>
<div class="line"><a id="l00361" name="l00361"></a><span class="lineno">  361</span><span class="comment">// Output does not need to be initialized.</span></div>
<div class="line"><a id="l00362" name="l00362"></a><span class="lineno"><a class="line" href="namespacetflite_1_1tensor__utils.html#a3aaf8841b23a739c231ff014ca1d761c">  362</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a00b791515d2acb7d88f09cfd9cddd2bf">CwiseMul</a>(<span class="keyword">const</span> int16_t* input_1, <span class="keyword">const</span> int16_t* input_2, <span class="keywordtype">int</span> n_batch,</div>
<div class="line"><a id="l00363" name="l00363"></a><span class="lineno">  363</span>              <span class="keywordtype">int</span> n_input, <span class="keywordtype">int</span> <a class="code hl_variable" href="wm8960__regs_8h.html#ace4e4903c356d90d7a0e7548fc1e8b50">shift</a>, int8_t* <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcbcd3bbe90c4644d53fde1ce4e312f437.html#a7a2a916a8059078c2d7a05f46c7126fd">output</a>);</div>
<div class="line"><a id="l00364" name="l00364"></a><span class="lineno">  364</span> </div>
<div class="line"><a id="l00365" name="l00365"></a><span class="lineno">  365</span><span class="comment">// Element-wise multiplication of two quantized vectors with rescaling.</span></div>
<div class="line"><a id="l00366" name="l00366"></a><span class="lineno">  366</span><span class="comment">// Parameters:</span></div>
<div class="line"><a id="l00367" name="l00367"></a><span class="lineno">  367</span><span class="comment">//     - input_1:    batch vector of size n_batch * n_input; 16 bit.</span></div>
<div class="line"><a id="l00368" name="l00368"></a><span class="lineno">  368</span><span class="comment">//     - input_2:    batch vector of size n_batch * n_input; 16 bit.</span></div>
<div class="line"><a id="l00369" name="l00369"></a><span class="lineno">  369</span><span class="comment">//     - multiplier: the multiplier part of scale.</span></div>
<div class="line"><a id="l00370" name="l00370"></a><span class="lineno">  370</span><span class="comment">//     - shift:      the shift part of scale.</span></div>
<div class="line"><a id="l00371" name="l00371"></a><span class="lineno">  371</span><span class="comment">//     - n_batch:    the number of batches.</span></div>
<div class="line"><a id="l00372" name="l00372"></a><span class="lineno">  372</span><span class="comment">//     - n_input:    the size for input and output.</span></div>
<div class="line"><a id="l00373" name="l00373"></a><span class="lineno">  373</span><span class="comment">//     - output:     the 8 bit output of size n_batch * n_input.</span></div>
<div class="line"><a id="l00374" name="l00374"></a><span class="lineno">  374</span><span class="comment">//     - output_zp:  the zero point of output.</span></div>
<div class="line"><a id="l00375" name="l00375"></a><span class="lineno">  375</span><span class="comment">// Output does not need to be initialized.</span></div>
<div class="line"><a id="l00376" name="l00376"></a><span class="lineno">  376</span><span class="comment">// Multiplier (&quot;m&quot;) and shift (&quot;s&quot;) are connected to scale (&quot;s&quot;) with s = m *</span></div>
<div class="line"><a id="l00377" name="l00377"></a><span class="lineno">  377</span><span class="comment">// 2^(s - 31).</span></div>
<div class="line"><a id="l00378" name="l00378"></a><span class="lineno">  378</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a00b791515d2acb7d88f09cfd9cddd2bf">CwiseMul</a>(<span class="keyword">const</span> int16_t* input_1, <span class="keyword">const</span> int16_t* input_2,</div>
<div class="line"><a id="l00379" name="l00379"></a><span class="lineno">  379</span>              int32_t <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srceb17155221795f6c84adc198b18f61e2.html#aa48e56822ed6e4a79d6c8c3b688ca8d3">multiplier</a>, int32_t <a class="code hl_variable" href="wm8960__regs_8h.html#ace4e4903c356d90d7a0e7548fc1e8b50">shift</a>, int32_t n_batch,</div>
<div class="line"><a id="l00380" name="l00380"></a><span class="lineno">  380</span>              int32_t n_input, int32_t output_zp, int8_t* <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcbcd3bbe90c4644d53fde1ce4e312f437.html#a7a2a916a8059078c2d7a05f46c7126fd">output</a>);</div>
<div class="line"><a id="l00381" name="l00381"></a><span class="lineno">  381</span> </div>
<div class="line"><a id="l00382" name="l00382"></a><span class="lineno">  382</span><span class="comment">// Element-wise saturating addition of two quantized vectors without rescaling.</span></div>
<div class="line"><a id="l00383" name="l00383"></a><span class="lineno">  383</span><span class="comment">// Parameters:</span></div>
<div class="line"><a id="l00384" name="l00384"></a><span class="lineno">  384</span><span class="comment">//     - input_1:    batch vector of size n_batch * n_input; 16 bit.</span></div>
<div class="line"><a id="l00385" name="l00385"></a><span class="lineno">  385</span><span class="comment">//     - input_2:    batch vector of size n_batch * n_input; 16 bit.</span></div>
<div class="line"><a id="l00386" name="l00386"></a><span class="lineno">  386</span><span class="comment">//     - n_batch:    the number of batches.</span></div>
<div class="line"><a id="l00387" name="l00387"></a><span class="lineno">  387</span><span class="comment">//     - n_input:    the size for input and output.</span></div>
<div class="line"><a id="l00388" name="l00388"></a><span class="lineno">  388</span><span class="comment">//     - output:     the 8 bit output of size n_batch * n_input.</span></div>
<div class="line"><a id="l00389" name="l00389"></a><span class="lineno">  389</span><span class="comment">// Output does not need to be initialized.</span></div>
<div class="line"><a id="l00390" name="l00390"></a><span class="lineno">  390</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a2e9fbef0ca0139e4da07d28b1fb70b88">CwiseAdd</a>(<span class="keyword">const</span> int16_t* input_1, <span class="keyword">const</span> int16_t* input_2, <span class="keywordtype">int</span> n_batch,</div>
<div class="line"><a id="l00391" name="l00391"></a><span class="lineno">  391</span>              <span class="keywordtype">int</span> n_input, int16_t* <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcbcd3bbe90c4644d53fde1ce4e312f437.html#a7a2a916a8059078c2d7a05f46c7126fd">output</a>);</div>
<div class="line"><a id="l00392" name="l00392"></a><span class="lineno">  392</span> </div>
<div class="line"><a id="l00393" name="l00393"></a><span class="lineno">  393</span><span class="comment">// Element-wise in-place clipping of a vector. Overloaded for float, int16_t,</span></div>
<div class="line"><a id="l00394" name="l00394"></a><span class="lineno">  394</span><span class="comment">// int8_t. Parameters:</span></div>
<div class="line"><a id="l00395" name="l00395"></a><span class="lineno">  395</span><span class="comment">//     - vector:         vector of size v_size.</span></div>
<div class="line"><a id="l00396" name="l00396"></a><span class="lineno">  396</span><span class="comment">//     - v_size:         the size of the vector.</span></div>
<div class="line"><a id="l00397" name="l00397"></a><span class="lineno">  397</span><span class="comment">//     - clipping_value: the value used for clipping.</span></div>
<div class="line"><a id="l00398" name="l00398"></a><span class="lineno">  398</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a270fcc4f2976c9fbfd85ec3ef5fbea4d">CwiseClipping</a>(<span class="keywordtype">float</span>* vector, <span class="keyword">const</span> <span class="keywordtype">int</span> v_size, <span class="keyword">const</span> <span class="keywordtype">float</span> clipping_value);</div>
<div class="line"><a id="l00399" name="l00399"></a><span class="lineno">  399</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a270fcc4f2976c9fbfd85ec3ef5fbea4d">CwiseClipping</a>(int16_t* vector, <span class="keyword">const</span> <span class="keywordtype">int</span> v_size,</div>
<div class="line"><a id="l00400" name="l00400"></a><span class="lineno">  400</span>                   <span class="keyword">const</span> int16_t clipping_value);</div>
<div class="line"><a id="l00401" name="l00401"></a><span class="lineno">  401</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a270fcc4f2976c9fbfd85ec3ef5fbea4d">CwiseClipping</a>(int8_t* vector, <span class="keyword">const</span> <span class="keywordtype">int</span> v_size,</div>
<div class="line"><a id="l00402" name="l00402"></a><span class="lineno">  402</span>                   <span class="keyword">const</span> int8_t clipping_value);</div>
<div class="line"><a id="l00403" name="l00403"></a><span class="lineno">  403</span> </div>
<div class="line"><a id="l00404" name="l00404"></a><span class="lineno">  404</span><span class="comment">// Dot product of two vectors.</span></div>
<div class="line"><a id="l00405" name="l00405"></a><span class="lineno">  405</span><span class="keywordtype">float</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a40dd958ab0746e89e6bfe23cf4a4c6d0">VectorVectorDotProduct</a>(<span class="keyword">const</span> <span class="keywordtype">float</span>* vector1, <span class="keyword">const</span> <span class="keywordtype">float</span>* vector2,</div>
<div class="line"><a id="l00406" name="l00406"></a><span class="lineno">  406</span>                             <span class="keywordtype">int</span> v_size);</div>
<div class="line"><a id="l00407" name="l00407"></a><span class="lineno">  407</span> </div>
<div class="line"><a id="l00408" name="l00408"></a><span class="lineno">  408</span><span class="comment">// Dot product of two batch vectors of size n_batch * v_size:</span></div>
<div class="line"><a id="l00409" name="l00409"></a><span class="lineno">  409</span><span class="comment">// vector1 = [x_1_1, x_1_2, ..., x_1_vsize,</span></div>
<div class="line"><a id="l00410" name="l00410"></a><span class="lineno">  410</span><span class="comment">//            x_2_1, x_2_2, ..., x_2_vsize,</span></div>
<div class="line"><a id="l00411" name="l00411"></a><span class="lineno">  411</span><span class="comment">//            ...</span></div>
<div class="line"><a id="l00412" name="l00412"></a><span class="lineno">  412</span><span class="comment">//            x_nbatch_1,..., x_nbatch_vsize]</span></div>
<div class="line"><a id="l00413" name="l00413"></a><span class="lineno">  413</span><span class="comment">// vector2 = [y_1_1, y_1_2, ..., y_1_vsize,</span></div>
<div class="line"><a id="l00414" name="l00414"></a><span class="lineno">  414</span><span class="comment">//            y_2_1, y_2_2, ..., y_2_vsize,</span></div>
<div class="line"><a id="l00415" name="l00415"></a><span class="lineno">  415</span><span class="comment">//            ...</span></div>
<div class="line"><a id="l00416" name="l00416"></a><span class="lineno">  416</span><span class="comment">//            y_nbatch_1,..., y_nbatch_vsize]</span></div>
<div class="line"><a id="l00417" name="l00417"></a><span class="lineno">  417</span><span class="comment">// Then result will be a vector of n_batch size starting from &#39;result&#39;:</span></div>
<div class="line"><a id="l00418" name="l00418"></a><span class="lineno">  418</span><span class="comment">// [x_1_1 * y_1_1 + x_1_2 * y_1_2 + ... + x_1_vsize * y_1_vsize,</span></div>
<div class="line"><a id="l00419" name="l00419"></a><span class="lineno">  419</span><span class="comment">//  x_2_1 * y_2_1 + x_2_2 * y_2_2 + ... + x_2_vsize * y_2_vsize,</span></div>
<div class="line"><a id="l00420" name="l00420"></a><span class="lineno">  420</span><span class="comment">//  ...</span></div>
<div class="line"><a id="l00421" name="l00421"></a><span class="lineno">  421</span><span class="comment">//  x_nbatch_1 * y_nbatch_1 + ... + x_nbatch_vsize * y_nbatch_vsize]</span></div>
<div class="line"><a id="l00422" name="l00422"></a><span class="lineno">  422</span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00423" data-start="{" data-end="}">
<div class="line"><a id="l00423" name="l00423"></a><span class="lineno"><a class="line" href="namespacetflite_1_1tensor__utils.html#a0a308694788d08a58efcd1371084f54f">  423</a></span><span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a0a308694788d08a58efcd1371084f54f">BatchVectorBatchVectorDotProduct</a>(<span class="keyword">const</span> T* vector1, <span class="keyword">const</span> T* vector2,</div>
<div class="line"><a id="l00424" name="l00424"></a><span class="lineno">  424</span>                                             <span class="keywordtype">int</span> v_size, <span class="keywordtype">int</span> n_batch,</div>
<div class="line"><a id="l00425" name="l00425"></a><span class="lineno">  425</span>                                             T* <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>) {</div>
<div class="line"><a id="l00426" name="l00426"></a><span class="lineno">  426</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> <a class="code hl_variable" href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a> = 0; <a class="code hl_variable" href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a> &lt; n_batch; <a class="code hl_variable" href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a>++) {</div>
<div class="line"><a id="l00427" name="l00427"></a><span class="lineno">  427</span>    <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>[<a class="code hl_variable" href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a>] = <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a40dd958ab0746e89e6bfe23cf4a4c6d0">VectorVectorDotProduct</a>(vector1, vector2, v_size);</div>
<div class="line"><a id="l00428" name="l00428"></a><span class="lineno">  428</span>    vector1 += v_size;</div>
<div class="line"><a id="l00429" name="l00429"></a><span class="lineno">  429</span>    vector2 += v_size;</div>
<div class="line"><a id="l00430" name="l00430"></a><span class="lineno">  430</span>  }</div>
<div class="line"><a id="l00431" name="l00431"></a><span class="lineno">  431</span>}</div>
</div>
<div class="line"><a id="l00432" name="l00432"></a><span class="lineno">  432</span> </div>
<div class="line"><a id="l00433" name="l00433"></a><span class="lineno">  433</span><span class="comment">// Same as above but input is 16bit and output is 32bit.</span></div>
<div class="line"><a id="l00434" name="l00434"></a><span class="lineno">  434</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a0a308694788d08a58efcd1371084f54f">BatchVectorBatchVectorDotProduct</a>(<span class="keyword">const</span> int16_t* vector1,</div>
<div class="line"><a id="l00435" name="l00435"></a><span class="lineno">  435</span>                                      <span class="keyword">const</span> int16_t* vector2, <span class="keywordtype">int</span> v_size,</div>
<div class="line"><a id="l00436" name="l00436"></a><span class="lineno">  436</span>                                      <span class="keywordtype">int</span> n_batch, int32_t* <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>);</div>
<div class="line"><a id="l00437" name="l00437"></a><span class="lineno">  437</span> </div>
<div class="line"><a id="l00438" name="l00438"></a><span class="lineno">  438</span><span class="comment">// Same as above, but inputs are 16bit integer and output is 16bit integer.</span></div>
<div class="line"><a id="l00439" name="l00439"></a><span class="lineno">  439</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#acd7492f35f64a6801fedf426f5f6a4fd">VectorBatchVectorCwiseProductAccumulate</a>(<span class="keyword">const</span> int16_t* vector, <span class="keywordtype">int</span> v_size,</div>
<div class="line"><a id="l00440" name="l00440"></a><span class="lineno">  440</span>                                             <span class="keyword">const</span> int16_t* batch_vector,</div>
<div class="line"><a id="l00441" name="l00441"></a><span class="lineno">  441</span>                                             <span class="keywordtype">int</span> n_batch, int32_t <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srceb17155221795f6c84adc198b18f61e2.html#aa48e56822ed6e4a79d6c8c3b688ca8d3">multiplier</a>,</div>
<div class="line"><a id="l00442" name="l00442"></a><span class="lineno">  442</span>                                             <span class="keywordtype">int</span> <a class="code hl_variable" href="wm8960__regs_8h.html#ace4e4903c356d90d7a0e7548fc1e8b50">shift</a>, int16_t* <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>);</div>
<div class="line"><a id="l00443" name="l00443"></a><span class="lineno">  443</span> </div>
<div class="line"><a id="l00444" name="l00444"></a><span class="lineno">  444</span><span class="comment">// Compute &quot;1.0f - elements of vector&quot; (used in CIFG).</span></div>
<div class="line"><a id="l00445" name="l00445"></a><span class="lineno">  445</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#ad9f5c03e42698153f0ab3979c8b98523">Sub1Vector</a>(<span class="keyword">const</span> <span class="keywordtype">float</span>* vector, <span class="keywordtype">int</span> v_size, <span class="keywordtype">float</span>* <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>);</div>
<div class="line"><a id="l00446" name="l00446"></a><span class="lineno">  446</span> </div>
<div class="line"><a id="l00447" name="l00447"></a><span class="lineno">  447</span><span class="comment">// Compute &quot;1.0f - elements of vector&quot; (used in CIFG) for int16 input.</span></div>
<div class="line"><a id="l00448" name="l00448"></a><span class="lineno">  448</span><span class="comment">// &quot;vector&quot; has range [0, 32767] because it is the output of sigmoid function.</span></div>
<div class="line"><a id="l00449" name="l00449"></a><span class="lineno">  449</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#ad9f5c03e42698153f0ab3979c8b98523">Sub1Vector</a>(<span class="keyword">const</span> int16_t* vector, <span class="keywordtype">int</span> v_size, int16_t* <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>);</div>
<div class="line"><a id="l00450" name="l00450"></a><span class="lineno">  450</span> </div>
<div class="line"><a id="l00451" name="l00451"></a><span class="lineno">  451</span><span class="comment">// Reduce-sum on a float input vector:</span></div>
<div class="line"><a id="l00452" name="l00452"></a><span class="lineno">  452</span><span class="comment">// input_vector: float pointer to input vector.</span></div>
<div class="line"><a id="l00453" name="l00453"></a><span class="lineno">  453</span><span class="comment">// output_vector: float pointer to vector.</span></div>
<div class="line"><a id="l00454" name="l00454"></a><span class="lineno">  454</span><span class="comment">// output_size: output vector size.</span></div>
<div class="line"><a id="l00455" name="l00455"></a><span class="lineno">  455</span><span class="comment">// reduction_size: number of consecutive elements from input vector which are</span></div>
<div class="line"><a id="l00456" name="l00456"></a><span class="lineno">  456</span><span class="comment">// added to get one element of output.</span></div>
<div class="line"><a id="l00457" name="l00457"></a><span class="lineno">  457</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a695680608ead1c5de98a426e9aed0c96">ReductionSumVector</a>(<span class="keyword">const</span> <span class="keywordtype">float</span>* input_vector, <span class="keywordtype">float</span>* output_vector,</div>
<div class="line"><a id="l00458" name="l00458"></a><span class="lineno">  458</span>                        <span class="keywordtype">int</span> <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcaf138809236f667e9686fdd4aaf17705.html#ad8d3d4ec9395e78bb589ab744c5fbaaa">output_size</a>, <span class="keywordtype">int</span> reduction_size);</div>
<div class="line"><a id="l00459" name="l00459"></a><span class="lineno">  459</span> </div>
<div class="line"><a id="l00460" name="l00460"></a><span class="lineno">  460</span><span class="comment">// Same as above but input/output is 32 bit integer.</span></div>
<div class="line"><a id="l00461" name="l00461"></a><span class="lineno">  461</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a695680608ead1c5de98a426e9aed0c96">ReductionSumVector</a>(<span class="keyword">const</span> int32_t* input_vector, int32_t* output_vector,</div>
<div class="line"><a id="l00462" name="l00462"></a><span class="lineno">  462</span>                        <span class="keywordtype">int</span> <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcaf138809236f667e9686fdd4aaf17705.html#ad8d3d4ec9395e78bb589ab744c5fbaaa">output_size</a>, <span class="keywordtype">int</span> reduction_size);</div>
<div class="line"><a id="l00463" name="l00463"></a><span class="lineno">  463</span> </div>
<div class="line"><a id="l00464" name="l00464"></a><span class="lineno">  464</span><span class="comment">// Same as above but input is 8 bit integer.</span></div>
<div class="line"><a id="l00465" name="l00465"></a><span class="lineno">  465</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a695680608ead1c5de98a426e9aed0c96">ReductionSumVector</a>(<span class="keyword">const</span> int8_t* input_vector, int32_t* output_vector,</div>
<div class="line"><a id="l00466" name="l00466"></a><span class="lineno">  466</span>                        <span class="keywordtype">int</span> <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcaf138809236f667e9686fdd4aaf17705.html#ad8d3d4ec9395e78bb589ab744c5fbaaa">output_size</a>, <span class="keywordtype">int</span> reduction_size);</div>
<div class="line"><a id="l00467" name="l00467"></a><span class="lineno">  467</span> </div>
<div class="line"><a id="l00468" name="l00468"></a><span class="lineno">  468</span><span class="comment">// Multiply all elements of vector with a scalar.</span></div>
<div class="line"><a id="l00469" name="l00469"></a><span class="lineno">  469</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#acb32e1681446e161dc3f1836f3a757ae">VectorScalarMultiply</a>(<span class="keyword">const</span> int8_t* vector, <span class="keywordtype">int</span> v_size, <span class="keywordtype">float</span> <a class="code hl_variable" href="batch__matmul__test_8cc.html#ab89fe30f475eefcbf59653d919c456bd">scale</a>,</div>
<div class="line"><a id="l00470" name="l00470"></a><span class="lineno">  470</span>                          <span class="keywordtype">float</span>* <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>);</div>
<div class="line"><a id="l00471" name="l00471"></a><span class="lineno">  471</span> </div>
<div class="line"><a id="l00472" name="l00472"></a><span class="lineno">  472</span><span class="comment">// Layer norm for each batch.</span></div>
<div class="line"><a id="l00473" name="l00473"></a><span class="lineno">  473</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a3de391bb3d11be44e4349d36f33320db">MeanStddevNormalization</a>(<span class="keyword">const</span> <span class="keywordtype">float</span>* input_vector, <span class="keywordtype">float</span>* output_vector,</div>
<div class="line"><a id="l00474" name="l00474"></a><span class="lineno">  474</span>                             <span class="keywordtype">int</span> v_size, <span class="keywordtype">int</span> n_batch);</div>
<div class="line"><a id="l00475" name="l00475"></a><span class="lineno">  475</span> </div>
<div class="line"><a id="l00476" name="l00476"></a><span class="lineno">  476</span><span class="comment">// Saturate Add with rescale on both inputs.</span></div>
<div class="line"><a id="l00477" name="l00477"></a><span class="lineno">  477</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a8bf1e3471ee86ce211a1f66afa9db512">TwoGateSaturatingAdd</a>(<span class="keyword">const</span> int8_t* <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src5afb18c45f6346167aa977a363205143.html#a9cebfb3d6ddd692fbdd268cf4b9ad024">input</a>, int8_t input_zp,</div>
<div class="line"><a id="l00478" name="l00478"></a><span class="lineno">  478</span>                          <span class="keyword">const</span> int8_t* recurrent, int8_t recurrent_zp,</div>
<div class="line"><a id="l00479" name="l00479"></a><span class="lineno">  479</span>                          int32_t input_effective_scale_a,</div>
<div class="line"><a id="l00480" name="l00480"></a><span class="lineno">  480</span>                          int32_t input_effective_scale_b,</div>
<div class="line"><a id="l00481" name="l00481"></a><span class="lineno">  481</span>                          int32_t recurrent_effective_scale_a,</div>
<div class="line"><a id="l00482" name="l00482"></a><span class="lineno">  482</span>                          int32_t recurrent_effective_scale_b, int32_t n_batch,</div>
<div class="line"><a id="l00483" name="l00483"></a><span class="lineno">  483</span>                          int32_t n_cell, int16_t* <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcbcd3bbe90c4644d53fde1ce4e312f437.html#a7a2a916a8059078c2d7a05f46c7126fd">output</a>);</div>
<div class="line"><a id="l00484" name="l00484"></a><span class="lineno">  484</span> </div>
<div class="line"><a id="l00485" name="l00485"></a><span class="lineno">  485</span><span class="comment">// Same as the function above, but provide a scratch buffer for the</span></div>
<div class="line"><a id="l00486" name="l00486"></a><span class="lineno">  486</span><span class="comment">// int8 x int8 -&gt; int32 and a CpuBackendContext for the accumulator</span></div>
<div class="line"><a id="l00487" name="l00487"></a><span class="lineno">  487</span><span class="comment">// computation.</span></div>
<div class="line"><a id="l00488" name="l00488"></a><span class="lineno"><a class="line" href="namespacetflite_1_1tensor__utils.html#a42a90bc04380d4d7b53c626785e246f5">  488</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a7fa83cbe789fcec252e1f8fad0dded14">MatrixBatchVectorMultiplyAccumulate</a>(</div>
<div class="line"><a id="l00489" name="l00489"></a><span class="lineno">  489</span>    <span class="keyword">const</span> int8_t* __restrict__ matrix, <span class="keyword">const</span> <span class="keywordtype">int</span> m_rows, <span class="keyword">const</span> <span class="keywordtype">int</span> m_cols,</div>
<div class="line"><a id="l00490" name="l00490"></a><span class="lineno">  490</span>    <span class="keyword">const</span> int8_t* __restrict__ vectors,</div>
<div class="line"><a id="l00491" name="l00491"></a><span class="lineno">  491</span>    <span class="keyword">const</span> <span class="keywordtype">float</span>* __restrict__ scaling_factors, <span class="keywordtype">int</span> n_batch,</div>
<div class="line"><a id="l00492" name="l00492"></a><span class="lineno">  492</span>    int32_t* __restrict__ scratch, <span class="keywordtype">float</span>* __restrict__ <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>,</div>
<div class="line"><a id="l00493" name="l00493"></a><span class="lineno">  493</span>    CpuBackendContext* __restrict__ context);</div>
<div class="line"><a id="l00494" name="l00494"></a><span class="lineno">  494</span> </div>
<div class="line"><a id="l00495" name="l00495"></a><span class="lineno">  495</span><span class="comment">// Same as the function above except that can make use of cached row sums.</span></div>
<div class="line"><a id="l00496" name="l00496"></a><span class="lineno">  496</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a7fa83cbe789fcec252e1f8fad0dded14">MatrixBatchVectorMultiplyAccumulate</a>(</div>
<div class="line"><a id="l00497" name="l00497"></a><span class="lineno">  497</span>    <span class="keyword">const</span> int8_t* __restrict__ matrix, <span class="keyword">const</span> <span class="keywordtype">int</span> m_rows, <span class="keyword">const</span> <span class="keywordtype">int</span> m_cols,</div>
<div class="line"><a id="l00498" name="l00498"></a><span class="lineno">  498</span>    <span class="keyword">const</span> int8_t* __restrict__ vectors, <span class="keyword">const</span> <span class="keywordtype">float</span>* scaling_factors,</div>
<div class="line"><a id="l00499" name="l00499"></a><span class="lineno">  499</span>    <span class="keywordtype">int</span> n_batch, <span class="keywordtype">float</span>* __restrict__ <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>, <span class="keyword">const</span> <span class="keywordtype">float</span>* per_channel_scale,</div>
<div class="line"><a id="l00500" name="l00500"></a><span class="lineno">  500</span>    <span class="keyword">const</span> int32_t* <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src07231aa9a2b381aa3c97687e9f0d823d.html#ad4670fdc658d0517928e6b2c10b2259d">input_offset</a>, int32_t* scratch, int32_t* row_sums,</div>
<div class="line"><a id="l00501" name="l00501"></a><span class="lineno">  501</span>    <span class="keywordtype">bool</span>* <a class="code hl_variable" href="xtensa_2unidirectional__sequence__lstm_8cc.html#a58b1f1cca64a5f505e2170a29e471ae9">compute_row_sums</a>, CpuBackendContext* context);</div>
<div class="line"><a id="l00502" name="l00502"></a><span class="lineno">  502</span> </div>
<div class="line"><a id="l00503" name="l00503"></a><span class="lineno">  503</span><span class="comment">// Same as the function above, but provides separate scaling factor for the</span></div>
<div class="line"><a id="l00504" name="l00504"></a><span class="lineno">  504</span><span class="comment">// matrix and the vectors. The scaling factors are multiplied in the</span></div>
<div class="line"><a id="l00505" name="l00505"></a><span class="lineno">  505</span><span class="comment">// scaling_factor_scratch buffer.</span></div>
<div class="foldopen" id="foldopen00506" data-start="{" data-end="}">
<div class="line"><a id="l00506" name="l00506"></a><span class="lineno"><a class="line" href="namespacetflite_1_1tensor__utils.html#abbecac6eb96471ff0b7dfd434dface7a">  506</a></span><span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a7fa83cbe789fcec252e1f8fad0dded14">MatrixBatchVectorMultiplyAccumulate</a>(</div>
<div class="line"><a id="l00507" name="l00507"></a><span class="lineno">  507</span>    <span class="keyword">const</span> int8_t* __restrict__ matrix, <span class="keyword">const</span> <span class="keywordtype">int</span> m_rows, <span class="keyword">const</span> <span class="keywordtype">int</span> m_cols,</div>
<div class="line"><a id="l00508" name="l00508"></a><span class="lineno">  508</span>    <span class="keyword">const</span> int8_t* __restrict__ vectors, <span class="keyword">const</span> <span class="keywordtype">float</span> matrix_scaling_factor,</div>
<div class="line"><a id="l00509" name="l00509"></a><span class="lineno">  509</span>    <span class="keyword">const</span> <span class="keywordtype">float</span>* vector_scaling_factors, <span class="keywordtype">int</span> n_batch,</div>
<div class="line"><a id="l00510" name="l00510"></a><span class="lineno">  510</span>    <span class="keywordtype">float</span>* __restrict__ <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>, <span class="keyword">const</span> <span class="keywordtype">float</span>* per_channel_scale,</div>
<div class="line"><a id="l00511" name="l00511"></a><span class="lineno">  511</span>    <span class="keyword">const</span> int32_t* <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src07231aa9a2b381aa3c97687e9f0d823d.html#ad4670fdc658d0517928e6b2c10b2259d">input_offset</a>, int32_t* scratch, int32_t* row_sums,</div>
<div class="line"><a id="l00512" name="l00512"></a><span class="lineno">  512</span>    <span class="keywordtype">bool</span>* <a class="code hl_variable" href="xtensa_2unidirectional__sequence__lstm_8cc.html#a58b1f1cca64a5f505e2170a29e471ae9">compute_row_sums</a>, <span class="keywordtype">float</span>* scaling_factor_scratch,</div>
<div class="line"><a id="l00513" name="l00513"></a><span class="lineno">  513</span>    CpuBackendContext* context) {</div>
<div class="line"><a id="l00514" name="l00514"></a><span class="lineno">  514</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> <a class="code hl_variable" href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a> = 0; <a class="code hl_variable" href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a> &lt; n_batch; ++<a class="code hl_variable" href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a>) {</div>
<div class="line"><a id="l00515" name="l00515"></a><span class="lineno">  515</span>    scaling_factor_scratch[<a class="code hl_variable" href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a>] =</div>
<div class="line"><a id="l00516" name="l00516"></a><span class="lineno">  516</span>        vector_scaling_factors[<a class="code hl_variable" href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a>] * matrix_scaling_factor;</div>
<div class="line"><a id="l00517" name="l00517"></a><span class="lineno">  517</span>  }</div>
<div class="line"><a id="l00518" name="l00518"></a><span class="lineno">  518</span>  <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a7fa83cbe789fcec252e1f8fad0dded14">MatrixBatchVectorMultiplyAccumulate</a>(matrix, m_rows, m_cols, vectors,</div>
<div class="line"><a id="l00519" name="l00519"></a><span class="lineno">  519</span>                                      scaling_factor_scratch, n_batch, <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>,</div>
<div class="line"><a id="l00520" name="l00520"></a><span class="lineno">  520</span>                                      per_channel_scale, <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src07231aa9a2b381aa3c97687e9f0d823d.html#ad4670fdc658d0517928e6b2c10b2259d">input_offset</a>, scratch,</div>
<div class="line"><a id="l00521" name="l00521"></a><span class="lineno">  521</span>                                      row_sums, <a class="code hl_variable" href="xtensa_2unidirectional__sequence__lstm_8cc.html#a58b1f1cca64a5f505e2170a29e471ae9">compute_row_sums</a>, context);</div>
<div class="line"><a id="l00522" name="l00522"></a><span class="lineno">  522</span>}</div>
</div>
<div class="line"><a id="l00523" name="l00523"></a><span class="lineno">  523</span> </div>
<div class="line"><a id="l00524" name="l00524"></a><span class="lineno">  524</span><span class="comment">// Multiplies a matrix by a &quot;batched&quot; vector (i.e. a matrix with a batch</span></div>
<div class="line"><a id="l00525" name="l00525"></a><span class="lineno">  525</span><span class="comment">// dimension composed by input vectors independent from each other). The result</span></div>
<div class="line"><a id="l00526" name="l00526"></a><span class="lineno">  526</span><span class="comment">// of the multiplication is accumulated to the passed result buffer.</span></div>
<div class="line"><a id="l00527" name="l00527"></a><span class="lineno">  527</span><span class="comment">// More specifically, for a matrix M of shape [n, i] and a batched-vector</span></div>
<div class="line"><a id="l00528" name="l00528"></a><span class="lineno">  528</span><span class="comment">// of shape [i, batch] it will first compute the product of shape [n, batch].</span></div>
<div class="line"><a id="l00529" name="l00529"></a><span class="lineno">  529</span><span class="comment">// This product will be accumulated to the result buffer,</span></div>
<div class="line"><a id="l00530" name="l00530"></a><span class="lineno">  530</span><span class="comment">// Parameters:</span></div>
<div class="line"><a id="l00531" name="l00531"></a><span class="lineno">  531</span><span class="comment">//     - input: batch vector of size n_batch * n_input</span></div>
<div class="line"><a id="l00532" name="l00532"></a><span class="lineno">  532</span><span class="comment">//     - bias:  vector of size b_input</span></div>
<div class="line"><a id="l00533" name="l00533"></a><span class="lineno">  533</span><span class="comment">//     - input_to_gate_weights: matrix of size n_input * n_output</span></div>
<div class="line"><a id="l00534" name="l00534"></a><span class="lineno">  534</span><span class="comment">//     - multiplier: scalar</span></div>
<div class="line"><a id="l00535" name="l00535"></a><span class="lineno">  535</span><span class="comment">//     - shift: scalar</span></div>
<div class="line"><a id="l00536" name="l00536"></a><span class="lineno">  536</span><span class="comment">//     - n_batch: the batch size</span></div>
<div class="line"><a id="l00537" name="l00537"></a><span class="lineno">  537</span><span class="comment">//     - n_input: the input size</span></div>
<div class="line"><a id="l00538" name="l00538"></a><span class="lineno">  538</span><span class="comment">//     - n_output: the output size</span></div>
<div class="line"><a id="l00539" name="l00539"></a><span class="lineno">  539</span><span class="comment">//     - output_zp: the zero point of the output.</span></div>
<div class="line"><a id="l00540" name="l00540"></a><span class="lineno">  540</span><span class="comment">//     - scratch: batch vector of size n_batch * n_output</span></div>
<div class="line"><a id="l00541" name="l00541"></a><span class="lineno">  541</span><span class="comment">//     - output: the 16 bit output</span></div>
<div class="line"><a id="l00542" name="l00542"></a><span class="lineno">  542</span><span class="comment">// Notes:</span></div>
<div class="line"><a id="l00543" name="l00543"></a><span class="lineno">  543</span><span class="comment">//     - this is used for gate matmul: for non-cifg it is for input, forget,</span></div>
<div class="line"><a id="l00544" name="l00544"></a><span class="lineno">  544</span><span class="comment">//       cell, output gates; for cifg, it is for forget, cell, output gates.</span></div>
<div class="line"><a id="l00545" name="l00545"></a><span class="lineno">  545</span><span class="comment">//     - multiplier and shift combined gives the scale.</span></div>
<div class="line"><a id="l00546" name="l00546"></a><span class="lineno">  546</span><span class="comment">//     - assumes input zero point is 0.</span></div>
<div class="line"><a id="l00547" name="l00547"></a><span class="lineno">  547</span><span class="comment">//     - scratch is created for optimization purpose only.</span></div>
<div class="line"><a id="l00548" name="l00548"></a><span class="lineno">  548</span><span class="comment">// TODO(b/152066492): this can be removed if some future optimization</span></div>
<div class="line"><a id="l00549" name="l00549"></a><span class="lineno">  549</span><span class="comment">// work makes it unnecessary.</span></div>
<div class="line"><a id="l00550" name="l00550"></a><span class="lineno">  550</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a7fa83cbe789fcec252e1f8fad0dded14">MatrixBatchVectorMultiplyAccumulate</a>(</div>
<div class="line"><a id="l00551" name="l00551"></a><span class="lineno">  551</span>    <span class="keyword">const</span> int8_t* <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src5afb18c45f6346167aa977a363205143.html#a9cebfb3d6ddd692fbdd268cf4b9ad024">input</a>, <span class="keyword">const</span> int32_t* bias,</div>
<div class="line"><a id="l00552" name="l00552"></a><span class="lineno">  552</span>    <span class="keyword">const</span> int8_t* input_to_gate_weights, int32_t <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srceb17155221795f6c84adc198b18f61e2.html#aa48e56822ed6e4a79d6c8c3b688ca8d3">multiplier</a>, int32_t <a class="code hl_variable" href="wm8960__regs_8h.html#ace4e4903c356d90d7a0e7548fc1e8b50">shift</a>,</div>
<div class="line"><a id="l00553" name="l00553"></a><span class="lineno">  553</span>    int32_t n_batch, int32_t n_input, int32_t n_output, int32_t output_zp,</div>
<div class="line"><a id="l00554" name="l00554"></a><span class="lineno">  554</span>    int32_t* scratch, int16_t* <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcbcd3bbe90c4644d53fde1ce4e312f437.html#a7a2a916a8059078c2d7a05f46c7126fd">output</a>, CpuBackendContext* context);</div>
<div class="line"><a id="l00555" name="l00555"></a><span class="lineno">  555</span> </div>
<div class="line"><a id="l00556" name="l00556"></a><span class="lineno">  556</span><span class="comment">// Multiplies a matrix by a &quot;batched&quot; vector (i.e. a matrix with a batch</span></div>
<div class="line"><a id="l00557" name="l00557"></a><span class="lineno">  557</span><span class="comment">// dimension composed by input vectors independent from each other). The result</span></div>
<div class="line"><a id="l00558" name="l00558"></a><span class="lineno">  558</span><span class="comment">// of the multiplication is accumulated to the passed result buffer.</span></div>
<div class="line"><a id="l00559" name="l00559"></a><span class="lineno">  559</span><span class="comment">// More specifically, for a matrix M of shape [n, i] and a batched-vector</span></div>
<div class="line"><a id="l00560" name="l00560"></a><span class="lineno">  560</span><span class="comment">// of shape [i, batch] it will first compute the product of shape [n, batch].</span></div>
<div class="line"><a id="l00561" name="l00561"></a><span class="lineno">  561</span><span class="comment">// This product will be accumulated to the result buffer,</span></div>
<div class="line"><a id="l00562" name="l00562"></a><span class="lineno">  562</span><span class="comment">// Parameters:</span></div>
<div class="line"><a id="l00563" name="l00563"></a><span class="lineno">  563</span><span class="comment">//     - input: batch vector of size n_batch * n_input</span></div>
<div class="line"><a id="l00564" name="l00564"></a><span class="lineno">  564</span><span class="comment">//     - bias:  vector of size b_input</span></div>
<div class="line"><a id="l00565" name="l00565"></a><span class="lineno">  565</span><span class="comment">//     - input_to_gate_weights: matrix of size n_input * n_output</span></div>
<div class="line"><a id="l00566" name="l00566"></a><span class="lineno">  566</span><span class="comment">//     - multiplier: scalar</span></div>
<div class="line"><a id="l00567" name="l00567"></a><span class="lineno">  567</span><span class="comment">//     - shift: scalar</span></div>
<div class="line"><a id="l00568" name="l00568"></a><span class="lineno">  568</span><span class="comment">//     - n_batch: the batch size</span></div>
<div class="line"><a id="l00569" name="l00569"></a><span class="lineno">  569</span><span class="comment">//     - n_input: the input size</span></div>
<div class="line"><a id="l00570" name="l00570"></a><span class="lineno">  570</span><span class="comment">//     - n_output: the output size</span></div>
<div class="line"><a id="l00571" name="l00571"></a><span class="lineno">  571</span><span class="comment">//     - output_zp: the zero point of the output.</span></div>
<div class="line"><a id="l00572" name="l00572"></a><span class="lineno">  572</span><span class="comment">//     - scratch: batch vector of size n_batch * n_output</span></div>
<div class="line"><a id="l00573" name="l00573"></a><span class="lineno">  573</span><span class="comment">//     - output: the 8 bit output</span></div>
<div class="line"><a id="l00574" name="l00574"></a><span class="lineno">  574</span><span class="comment">// Notes:</span></div>
<div class="line"><a id="l00575" name="l00575"></a><span class="lineno">  575</span><span class="comment">//     - this is used for projection matmul.</span></div>
<div class="line"><a id="l00576" name="l00576"></a><span class="lineno">  576</span><span class="comment">//     - multiplier and shift combined gives the scale.</span></div>
<div class="line"><a id="l00577" name="l00577"></a><span class="lineno">  577</span><span class="comment">//     - assumes input zero point is 0.</span></div>
<div class="line"><a id="l00578" name="l00578"></a><span class="lineno">  578</span><span class="comment">//     - scratch is created for optimization purpose only.</span></div>
<div class="line"><a id="l00579" name="l00579"></a><span class="lineno">  579</span><span class="comment">// TODO(b/152066492): this can be removed if some future optimization</span></div>
<div class="line"><a id="l00580" name="l00580"></a><span class="lineno">  580</span><span class="comment">// work makes it unnecessary.</span></div>
<div class="line"><a id="l00581" name="l00581"></a><span class="lineno">  581</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a7fa83cbe789fcec252e1f8fad0dded14">MatrixBatchVectorMultiplyAccumulate</a>(</div>
<div class="line"><a id="l00582" name="l00582"></a><span class="lineno">  582</span>    <span class="keyword">const</span> int8_t* <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src5afb18c45f6346167aa977a363205143.html#a9cebfb3d6ddd692fbdd268cf4b9ad024">input</a>, <span class="keyword">const</span> int32_t* bias,</div>
<div class="line"><a id="l00583" name="l00583"></a><span class="lineno">  583</span>    <span class="keyword">const</span> int8_t* input_to_gate_weights, int32_t <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srceb17155221795f6c84adc198b18f61e2.html#aa48e56822ed6e4a79d6c8c3b688ca8d3">multiplier</a>, int32_t <a class="code hl_variable" href="wm8960__regs_8h.html#ace4e4903c356d90d7a0e7548fc1e8b50">shift</a>,</div>
<div class="line"><a id="l00584" name="l00584"></a><span class="lineno">  584</span>    int32_t n_batch, int32_t n_input, int32_t n_output, int32_t output_zp,</div>
<div class="line"><a id="l00585" name="l00585"></a><span class="lineno">  585</span>    int32_t* scratch, int8_t* <a class="code hl_variable" href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcbcd3bbe90c4644d53fde1ce4e312f437.html#a7a2a916a8059078c2d7a05f46c7126fd">output</a>, CpuBackendContext* context);</div>
<div class="line"><a id="l00586" name="l00586"></a><span class="lineno">  586</span> </div>
<div class="line"><a id="l00587" name="l00587"></a><span class="lineno">  587</span><span class="comment">// Apply Rectified Linear to elements of a vector.</span></div>
<div class="line"><a id="l00588" name="l00588"></a><span class="lineno">  588</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#aa03ade239cf0c0cfdf5a4e8a721a48f2">ApplyReluToVector</a>(<span class="keyword">const</span> <span class="keywordtype">float</span>* __restrict__ vector, <span class="keywordtype">int</span> v_size,</div>
<div class="line"><a id="l00589" name="l00589"></a><span class="lineno">  589</span>                       <span class="keywordtype">float</span>* __restrict__ <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>);</div>
<div class="line"><a id="l00590" name="l00590"></a><span class="lineno">  590</span> </div>
<div class="line"><a id="l00591" name="l00591"></a><span class="lineno">  591</span><span class="comment">// Apply Rectified Linear 1 (cap to [-1;1]) to elements of a vector</span></div>
<div class="line"><a id="l00592" name="l00592"></a><span class="lineno">  592</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a1a52621a880a5f7cda611280acf41f3f">ApplyRelu1ToVector</a>(<span class="keyword">const</span> <span class="keywordtype">float</span>* __restrict__ vector, <span class="keywordtype">int</span> v_size,</div>
<div class="line"><a id="l00593" name="l00593"></a><span class="lineno">  593</span>                        <span class="keywordtype">float</span>* __restrict__ <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>);</div>
<div class="line"><a id="l00594" name="l00594"></a><span class="lineno">  594</span> </div>
<div class="line"><a id="l00595" name="l00595"></a><span class="lineno">  595</span><span class="comment">// Apply Rectified Linear 6 (cap to [0;6]) to elements of a vector</span></div>
<div class="line"><a id="l00596" name="l00596"></a><span class="lineno">  596</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#ac736f360f79851978af17098b0de7b04">ApplyRelu6ToVector</a>(<span class="keyword">const</span> <span class="keywordtype">float</span>* __restrict__ vector, <span class="keywordtype">int</span> v_size,</div>
<div class="line"><a id="l00597" name="l00597"></a><span class="lineno">  597</span>                        <span class="keywordtype">float</span>* __restrict__ <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>);</div>
<div class="line"><a id="l00598" name="l00598"></a><span class="lineno">  598</span> </div>
<div class="line"><a id="l00599" name="l00599"></a><span class="lineno">  599</span><span class="comment">// Apply signbit to elements of a vector</span></div>
<div class="line"><a id="l00600" name="l00600"></a><span class="lineno">  600</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#a63ee5b071bf3024141202c1f43bb8d52">ApplySignbitToVector</a>(<span class="keyword">const</span> <span class="keywordtype">float</span>* __restrict__ vector, <span class="keywordtype">int</span> v_size,</div>
<div class="line"><a id="l00601" name="l00601"></a><span class="lineno">  601</span>                          <span class="keywordtype">float</span>* __restrict__ <a class="code hl_variable" href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a>);</div>
<div class="line"><a id="l00602" name="l00602"></a><span class="lineno">  602</span> </div>
<div class="line"><a id="l00603" name="l00603"></a><span class="lineno">  603</span><span class="comment">// Unpack or inflate `src_buffer` by taking each element and splitting it as</span></div>
<div class="line"><a id="l00604" name="l00604"></a><span class="lineno">  604</span><span class="comment">// two elements into `dst_buffer`.</span></div>
<div class="line"><a id="l00605" name="l00605"></a><span class="lineno">  605</span><span class="comment">// Parameters:</span></div>
<div class="line"><a id="l00606" name="l00606"></a><span class="lineno">  606</span><span class="comment">//   src_buffer   : Densely packed buffer containing int4 values</span></div>
<div class="line"><a id="l00607" name="l00607"></a><span class="lineno">  607</span><span class="comment">//   num_elements : Number of elements stored in the buffer. Note that this can</span></div>
<div class="line"><a id="l00608" name="l00608"></a><span class="lineno">  608</span><span class="comment">//                  be smaller than the size of `src_buffer` by 1 if it&#39;s odd,</span></div>
<div class="line"><a id="l00609" name="l00609"></a><span class="lineno">  609</span><span class="comment">//                  in which case the last nibble in `src_buffer` is ignored.</span></div>
<div class="line"><a id="l00610" name="l00610"></a><span class="lineno">  610</span><span class="comment">//                  This should be equal to the size of `dst_buffer`.</span></div>
<div class="line"><a id="l00611" name="l00611"></a><span class="lineno">  611</span><span class="comment">//   dst_buffer   : Buffer to unpack into. Should be allocated by the caller.</span></div>
<div class="line"><a id="l00612" name="l00612"></a><span class="lineno">  612</span><span class="comment">//                  Size should be at least `num_elements`.</span></div>
<div class="line"><a id="l00613" name="l00613"></a><span class="lineno">  613</span><span class="comment">// Notes:</span></div>
<div class="line"><a id="l00614" name="l00614"></a><span class="lineno">  614</span><span class="comment">//   For example, given `src_buffer = {0x12, 0x34};`, calling this function</span></div>
<div class="line"><a id="l00615" name="l00615"></a><span class="lineno">  615</span><span class="comment">//   will return `dst_buffer = {0x02, 0x01, 0x04, 0x03}`.</span></div>
<div class="line"><a id="l00616" name="l00616"></a><span class="lineno">  616</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacetflite_1_1tensor__utils.html#af14e9223f3b393e2c7760b3363936557">UnpackDenseInt4IntoInt8</a>(<span class="keyword">const</span> int8_t* src_buffer, <span class="keywordtype">int</span> num_elements,</div>
<div class="line"><a id="l00617" name="l00617"></a><span class="lineno">  617</span>                             int8_t* dst_buffer);</div>
<div class="line"><a id="l00618" name="l00618"></a><span class="lineno">  618</span> </div>
<div class="line"><a id="l00619" name="l00619"></a><span class="lineno">  619</span>}  <span class="comment">// namespace tensor_utils</span></div>
<div class="line"><a id="l00620" name="l00620"></a><span class="lineno">  620</span> </div>
<div class="line"><a id="l00621" name="l00621"></a><span class="lineno">  621</span>}  <span class="comment">// namespace tflite</span></div>
<div class="line"><a id="l00622" name="l00622"></a><span class="lineno">  622</span> </div>
<div class="line"><a id="l00623" name="l00623"></a><span class="lineno">  623</span><span class="preprocessor">#endif  </span><span class="comment">// TENSORFLOW_LITE_KERNELS_INTERNAL_PORTABLE_TENSOR_UTILS_H_</span></div>
<div class="ttc" id="a_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src07231aa9a2b381aa3c97687e9f0d823d_html_a239169c76410c3a81fd9cba67cc0bc8f"><div class="ttname"><a href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src07231aa9a2b381aa3c97687e9f0d823d.html#a239169c76410c3a81fd9cba67cc0bc8f">output_shift</a></div><div class="ttdeci">int output_shift</div><div class="ttdef"><b>Definition</b> add_n.cpp:44</div></div>
<div class="ttc" id="a_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src07231aa9a2b381aa3c97687e9f0d823d_html_a23e9f0626e0fdd28687b85e5065f904a"><div class="ttname"><a href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src07231aa9a2b381aa3c97687e9f0d823d.html#a23e9f0626e0fdd28687b85e5065f904a">output_multiplier</a></div><div class="ttdeci">int32_t output_multiplier</div><div class="ttdef"><b>Definition</b> add_n.cpp:42</div></div>
<div class="ttc" id="a_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src07231aa9a2b381aa3c97687e9f0d823d_html_a2e6a27b448848b3057c45363e04b7d0d"><div class="ttname"><a href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src07231aa9a2b381aa3c97687e9f0d823d.html#a2e6a27b448848b3057c45363e04b7d0d">output_activation_min</a></div><div class="ttdeci">int32_t output_activation_min</div><div class="ttdef"><b>Definition</b> add_n.cpp:37</div></div>
<div class="ttc" id="a_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src07231aa9a2b381aa3c97687e9f0d823d_html_aa889d7b51a3f84357d44f05993ac08a1"><div class="ttname"><a href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src07231aa9a2b381aa3c97687e9f0d823d.html#aa889d7b51a3f84357d44f05993ac08a1">output_activation_max</a></div><div class="ttdeci">int32_t output_activation_max</div><div class="ttdef"><b>Definition</b> add_n.cpp:38</div></div>
<div class="ttc" id="a_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src07231aa9a2b381aa3c97687e9f0d823d_html_ab1dde269b1116cc98371e23a97740a58"><div class="ttname"><a href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src07231aa9a2b381aa3c97687e9f0d823d.html#ab1dde269b1116cc98371e23a97740a58">output_offset</a></div><div class="ttdeci">int32_t output_offset</div><div class="ttdef"><b>Definition</b> add_n.cpp:40</div></div>
<div class="ttc" id="a_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src07231aa9a2b381aa3c97687e9f0d823d_html_ad4670fdc658d0517928e6b2c10b2259d"><div class="ttname"><a href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src07231aa9a2b381aa3c97687e9f0d823d.html#ad4670fdc658d0517928e6b2c10b2259d">input_offset</a></div><div class="ttdeci">int32_t input_offset</div><div class="ttdef"><b>Definition</b> add_n.cpp:39</div></div>
<div class="ttc" id="a_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src5afb18c45f6346167aa977a363205143_html_a9cebfb3d6ddd692fbdd268cf4b9ad024"><div class="ttname"><a href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2src5afb18c45f6346167aa977a363205143.html#a9cebfb3d6ddd692fbdd268cf4b9ad024">input</a></div><div class="ttdeci">TfLiteTensor * input</div><div class="ttdef"><b>Definition</b> squeeze.cpp:43</div></div>
<div class="ttc" id="a_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcaf138809236f667e9686fdd4aaf17705_html_ad8d3d4ec9395e78bb589ab744c5fbaaa"><div class="ttname"><a href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcaf138809236f667e9686fdd4aaf17705.html#ad8d3d4ec9395e78bb589ab744c5fbaaa">output_size</a></div><div class="ttdeci">int output_size</div><div class="ttdef"><b>Definition</b> mirror_pad.cpp:26</div></div>
<div class="ttc" id="a_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcaf138809236f667e9686fdd4aaf17705_html_aed7ea92f45bd273dde380a45ddced592"><div class="ttname"><a href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcaf138809236f667e9686fdd4aaf17705.html#aed7ea92f45bd273dde380a45ddced592">offset</a></div><div class="ttdeci">int offset</div><div class="ttdef"><b>Definition</b> mirror_pad.cpp:27</div></div>
<div class="ttc" id="a_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcbcd3bbe90c4644d53fde1ce4e312f437_html_a7a2a916a8059078c2d7a05f46c7126fd"><div class="ttname"><a href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srcbcd3bbe90c4644d53fde1ce4e312f437.html#a7a2a916a8059078c2d7a05f46c7126fd">output</a></div><div class="ttdeci">TfLiteEvalTensor * output</div><div class="ttdef"><b>Definition</b> maximum_minimum.cpp:49</div></div>
<div class="ttc" id="a_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srceb17155221795f6c84adc198b18f61e2_html_aa48e56822ed6e4a79d6c8c3b688ca8d3"><div class="ttname"><a href="_arduino_2_get_started_with_machine_learning_on_arduino_2tflite-micro-arduino-examples-main_2srceb17155221795f6c84adc198b18f61e2.html#aa48e56822ed6e4a79d6c8c3b688ca8d3">multiplier</a></div><div class="ttdeci">int32_t multiplier</div><div class="ttdef"><b>Definition</b> elementwise.cpp:40</div></div>
<div class="ttc" id="a_test_a_p_d_s9960_color_8ino_html_a148e3876077787926724625411d6e7a9"><div class="ttname"><a href="_test_a_p_d_s9960_color_8ino.html#a148e3876077787926724625411d6e7a9">b</a></div><div class="ttdeci">int b</div><div class="ttdef"><b>Definition</b> TestAPDS9960Color.ino:12</div></div>
<div class="ttc" id="abatch__matmul__test_8cc_html_ab89fe30f475eefcbf59653d919c456bd"><div class="ttname"><a href="batch__matmul__test_8cc.html#ab89fe30f475eefcbf59653d919c456bd">scale</a></div><div class="ttdeci">float scale</div><div class="ttdef"><b>Definition</b> batch_matmul_test.cc:44</div></div>
<div class="ttc" id="agroup__ei__functions_html_gaf4ad914acba713176b1f00a800e781ba"><div class="ttname"><a href="group__ei__functions.html#gaf4ad914acba713176b1f00a800e781ba">result</a></div><div class="ttdeci">const ei_learning_block_config_tflite_graph_t ei_impulse_result_t * result</div><div class="ttdef"><b>Definition</b> ei_fill_result_struct.h:206</div></div>
<div class="ttc" id="ahello__world__model_8cc_html_a439227feff9d7f55384e8780cfc2eb82"><div class="ttname"><a href="hello__world__model_8cc.html#a439227feff9d7f55384e8780cfc2eb82">size</a></div><div class="ttdeci">int size</div><div class="ttdef"><b>Definition</b> hello_world_model.cc:113</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_a00b791515d2acb7d88f09cfd9cddd2bf"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#a00b791515d2acb7d88f09cfd9cddd2bf">tflite::tensor_utils::CwiseMul</a></div><div class="ttdeci">void CwiseMul(const int16_t *input_1, const int16_t *input_2, int n_batch, int n_input, int shift, int16_t *output)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:228</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_a0a308694788d08a58efcd1371084f54f"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#a0a308694788d08a58efcd1371084f54f">tflite::tensor_utils::BatchVectorBatchVectorDotProduct</a></div><div class="ttdeci">void BatchVectorBatchVectorDotProduct(const T *vector1, const T *vector2, int v_size, int n_batch, T *result)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:423</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_a0ac4e61f41d58b070565ba9dc029bad3"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#a0ac4e61f41d58b070565ba9dc029bad3">tflite::tensor_utils::VectorBatchVectorCwiseProduct</a></div><div class="ttdeci">void VectorBatchVectorCwiseProduct(const T *vector, int v_size, const T *batch_vector, int n_batch, T *result)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:77</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_a19871bdff4f6f49d47a03aba2187f2e4"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#a19871bdff4f6f49d47a03aba2187f2e4">tflite::tensor_utils::VectorBatchVectorAdd</a></div><div class="ttdeci">void VectorBatchVectorAdd(const T *vector, int v_size, int n_batch, T *batch_vector)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:56</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_a1a52621a880a5f7cda611280acf41f3f"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#a1a52621a880a5f7cda611280acf41f3f">tflite::tensor_utils::ApplyRelu1ToVector</a></div><div class="ttdeci">void ApplyRelu1ToVector(const float *__restrict__ vector, int v_size, float *__restrict__ result)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.cpp:48</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_a1f49fa548503159cd9a4ca681bf2c978"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#a1f49fa548503159cd9a4ca681bf2c978">tflite::tensor_utils::IsZeroVector</a></div><div class="ttdeci">bool IsZeroVector(const float *vector, int v_size)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:28</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_a246aaabdf1fa73214eabbd1953d2647b"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#a246aaabdf1fa73214eabbd1953d2647b">tflite::tensor_utils::SparseMatrixBatchVectorMultiplyAccumulate</a></div><div class="ttdeci">void SparseMatrixBatchVectorMultiplyAccumulate(const float *__restrict__ matrix, const uint8_t *__restrict__ ledger, int m_rows, int m_cols, const float *__restrict__ vector, int n_batch, float *__restrict__ result)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:106</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_a270fcc4f2976c9fbfd85ec3ef5fbea4d"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#a270fcc4f2976c9fbfd85ec3ef5fbea4d">tflite::tensor_utils::CwiseClipping</a></div><div class="ttdeci">void CwiseClipping(float *vector, const int v_size, const float clipping_value)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:245</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_a2e9fbef0ca0139e4da07d28b1fb70b88"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#a2e9fbef0ca0139e4da07d28b1fb70b88">tflite::tensor_utils::CwiseAdd</a></div><div class="ttdeci">void CwiseAdd(const int16_t *input_1, const int16_t *input_2, int n_batch, int n_input, int16_t *output)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:240</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_a3687fefe4c0a7e3d9215f9fb2715a5b9"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#a3687fefe4c0a7e3d9215f9fb2715a5b9">tflite::tensor_utils::SparseMatrixBatchVectorMultiplyAccumulate1x16</a></div><div class="ttdeci">void SparseMatrixBatchVectorMultiplyAccumulate1x16(const int8_t *__restrict__ matrix, const int32_t *__restrict__ segments, const int32_t *__restrict__ indices, int m_rows, int m_cols, const int8_t *__restrict__ vector, const int32_t *__restrict__ bias_vector, int n_batch, const int32_t input_offset, const int32_t output_multiplier, const int32_t output_shift, const int32_t output_offset, const int32_t output_activation_min, const int32_t output_activation_max, int8_t *__restrict__ result)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:114</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_a3de391bb3d11be44e4349d36f33320db"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#a3de391bb3d11be44e4349d36f33320db">tflite::tensor_utils::MeanStddevNormalization</a></div><div class="ttdeci">void MeanStddevNormalization(const float *input_vector, float *output_vector, int v_size, int n_batch)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:312</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_a40dd958ab0746e89e6bfe23cf4a4c6d0"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#a40dd958ab0746e89e6bfe23cf4a4c6d0">tflite::tensor_utils::VectorVectorDotProduct</a></div><div class="ttdeci">float VectorVectorDotProduct(const float *vector1, const float *vector2, int v_size)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:268</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_a5c3050bdbd554b288d59a1f909e3034c"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#a5c3050bdbd554b288d59a1f909e3034c">tflite::tensor_utils::MatrixBatchVectorMultiply</a></div><div class="ttdeci">void MatrixBatchVectorMultiply(const int8_t *input, int32_t input_zeropoint, const int8_t *input_to_gate_weights, int32_t input_to_gate_effective_scale_a, int32_t input_to_gate_effective_scale_b, int32_t n_batch, int32_t n_input, int32_t n_cell, int8_t *gate_output, int8_t gate_output_zp)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:164</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_a63ee5b071bf3024141202c1f43bb8d52"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#a63ee5b071bf3024141202c1f43bb8d52">tflite::tensor_utils::ApplySignbitToVector</a></div><div class="ttdeci">void ApplySignbitToVector(const float *__restrict__ vector, int v_size, float *__restrict__ result)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.cpp:64</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_a641279c30789a1307fc603a4371694eb"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#a641279c30789a1307fc603a4371694eb">tflite::tensor_utils::BatchQuantizeFloats</a></div><div class="ttdeci">void BatchQuantizeFloats(const float *float_data_ptr, int n_batch, int n_data, int8_t *quantized_data_ptr, float *scaling_factors, int32_t *zero_points, bool do_asymmetric)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:158</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_a670f91eba70d2d51dc385fc9f11c6c88"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#a670f91eba70d2d51dc385fc9f11c6c88">tflite::tensor_utils::ApplySigmoidFloat</a></div><div class="ttdeci">void ApplySigmoidFloat(const int16_t *input, int32_t n_batch, int32_t n_input, int16_t *output)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:213</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_a67bc3bb5ec7593bd567afa6973cffd38"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#a67bc3bb5ec7593bd567afa6973cffd38">tflite::tensor_utils::ApplyLayerNormFloat</a></div><div class="ttdeci">void ApplyLayerNormFloat(const int16_t *input, const int16_t *layer_norm_weights, int32_t layer_norm_scale_a, int32_t layer_norm_scale_b, const int32_t *bias, int n_batch, int n_input, int16_t *output)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:198</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_a695680608ead1c5de98a426e9aed0c96"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#a695680608ead1c5de98a426e9aed0c96">tflite::tensor_utils::ReductionSumVector</a></div><div class="ttdeci">void ReductionSumVector(const float *input_vector, float *output_vector, int output_size, int reduction_size)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:294</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_a7fa83cbe789fcec252e1f8fad0dded14"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#a7fa83cbe789fcec252e1f8fad0dded14">tflite::tensor_utils::MatrixBatchVectorMultiplyAccumulate</a></div><div class="ttdeci">void MatrixBatchVectorMultiplyAccumulate(const float *matrix, int m_rows, int m_cols, const float *vector, int n_batch, float *result)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:58</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_a8bf1e3471ee86ce211a1f66afa9db512"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#a8bf1e3471ee86ce211a1f66afa9db512">tflite::tensor_utils::TwoGateSaturatingAdd</a></div><div class="ttdeci">void TwoGateSaturatingAdd(const int8_t *input, int8_t input_zp, const int8_t *recurrent, int8_t recurrent_zp, int32_t input_effective_scale_a, int32_t input_effective_scale_b, int32_t recurrent_effective_scale_a, int32_t recurrent_effective_scale_b, int32_t n_batch, int32_t n_cell, int16_t *output)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:317</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_a8e089876da3bd7d112db1849f601cf95"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#a8e089876da3bd7d112db1849f601cf95">tflite::tensor_utils::VectorVectorCwiseProductAccumulate</a></div><div class="ttdeci">void VectorVectorCwiseProductAccumulate(const T *__restrict__ vector1, const T *__restrict__ vector2, int v_size, T *__restrict__ result)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:91</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_aa03ade239cf0c0cfdf5a4e8a721a48f2"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#aa03ade239cf0c0cfdf5a4e8a721a48f2">tflite::tensor_utils::ApplyReluToVector</a></div><div class="ttdeci">void ApplyReluToVector(const float *__restrict__ vector, int v_size, float *__restrict__ result)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.cpp:40</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_aa6ec4142f3565c0a51dfc30afc04faed"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#aa6ec4142f3565c0a51dfc30afc04faed">tflite::tensor_utils::MatrixScalarMultiplyAccumulate</a></div><div class="ttdeci">void MatrixScalarMultiplyAccumulate(const int8_t *matrix, int32_t scalar, int32_t n_row, int32_t n_col, int32_t *output)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:158</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_aaca4048cfd0807a5ddb517474f3178d7"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#aaca4048cfd0807a5ddb517474f3178d7">tflite::tensor_utils::AsymmetricQuantizeFloats</a></div><div class="ttdeci">void AsymmetricQuantizeFloats(const float *values, const int size, int8_t *quantized_values, float *scaling_factor, int32_t *offset)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:51</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_ac03f033f390956884a385cbfe69e81ee"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#ac03f033f390956884a385cbfe69e81ee">tflite::tensor_utils::SparseMatrixBatchVectorMultiplyAccumulate1x4</a></div><div class="ttdeci">void SparseMatrixBatchVectorMultiplyAccumulate1x4(const float *__restrict__ matrix, const int32_t *__restrict__ segments, const int32_t *__restrict__ indices, int m_rows, int m_cols, const float *__restrict__ vector, int n_batch, float *__restrict__ result)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:98</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_ac736f360f79851978af17098b0de7b04"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#ac736f360f79851978af17098b0de7b04">tflite::tensor_utils::ApplyRelu6ToVector</a></div><div class="ttdeci">void ApplyRelu6ToVector(const float *__restrict__ vector, int v_size, float *__restrict__ result)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.cpp:56</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_acb32e1681446e161dc3f1836f3a757ae"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#acb32e1681446e161dc3f1836f3a757ae">tflite::tensor_utils::VectorScalarMultiply</a></div><div class="ttdeci">void VectorScalarMultiply(const int8_t *vector, int v_size, float scale, float *result)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:289</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_acd7492f35f64a6801fedf426f5f6a4fd"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#acd7492f35f64a6801fedf426f5f6a4fd">tflite::tensor_utils::VectorBatchVectorCwiseProductAccumulate</a></div><div class="ttdeci">void VectorBatchVectorCwiseProductAccumulate(const T *vector, int v_size, const T *batch_vector, int n_batch, T *result)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:104</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_ad409d55a899099431b20de28fbd10ab0"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#ad409d55a899099431b20de28fbd10ab0">tflite::tensor_utils::ApplyTanhFloat</a></div><div class="ttdeci">void ApplyTanhFloat(const int16_t *input, int32_t n_batch, int32_t n_input, int32_t integer_bits, int16_t *output)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:223</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_ad6f6cd2bf307d9d709470b6ee892aa4d"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#ad6f6cd2bf307d9d709470b6ee892aa4d">tflite::tensor_utils::SymmetricQuantizeFloats</a></div><div class="ttdeci">void SymmetricQuantizeFloats(const float *values, const int size, int8_t *quantized_values, float *min_value, float *max_value, float *scaling_factor)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:37</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_ad73fe84d0b228eaaad81a948ad29af79"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#ad73fe84d0b228eaaad81a948ad29af79">tflite::tensor_utils::VectorBatchVectorAssign</a></div><div class="ttdeci">void VectorBatchVectorAssign(const T *vector, int v_size, int n_batch, T *batch_vector)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:117</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_ad9f5c03e42698153f0ab3979c8b98523"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#ad9f5c03e42698153f0ab3979c8b98523">tflite::tensor_utils::Sub1Vector</a></div><div class="ttdeci">void Sub1Vector(const float *vector, int v_size, float *result)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:280</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_ae3a437253dc60babd7f063cddb2f56a4"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#ae3a437253dc60babd7f063cddb2f56a4">tflite::tensor_utils::ApplyLayerNorm</a></div><div class="ttdeci">void ApplyLayerNorm(const int16_t *input, const int16_t *layer_norm_weights, const int32_t *bias, int32_t layer_norm_scale_a, int32_t layer_norm_scale_b, int32_t variance_limit, int n_batch, int n_input, int16_t *output)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:189</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_ae8baef2267c575bc54ee5697a7a7277d"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#ae8baef2267c575bc54ee5697a7a7277d">tflite::tensor_utils::ApplySigmoid</a></div><div class="ttdeci">void ApplySigmoid(const int16_t *input, int32_t n_batch, int32_t n_input, int16_t *output)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:208</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_af14e9223f3b393e2c7760b3363936557"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#af14e9223f3b393e2c7760b3363936557">tflite::tensor_utils::UnpackDenseInt4IntoInt8</a></div><div class="ttdeci">void UnpackDenseInt4IntoInt8(const int8_t *src_buffer, int num_elements, int8_t *dst_buffer)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.cpp:71</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_af2d6ac1d9d03ebac78f7d6346ac0ae83"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#af2d6ac1d9d03ebac78f7d6346ac0ae83">tflite::tensor_utils::VectorVectorCwiseProduct</a></div><div class="ttdeci">void VectorVectorCwiseProduct(const T *vector1, const T *vector2, int v_size, T *result)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:68</div></div>
<div class="ttc" id="anamespacetflite_1_1tensor__utils_html_af5224fd4d02e02759666a101f7ad9b56"><div class="ttname"><a href="namespacetflite_1_1tensor__utils.html#af5224fd4d02e02759666a101f7ad9b56">tflite::tensor_utils::ApplyTanh</a></div><div class="ttdeci">void ApplyTanh(int32_t intger_bits, const int16_t *input, int32_t n_batch, int32_t n_input, int16_t *output)</div><div class="ttdef"><b>Definition</b> portable_tensor_utils.h:218</div></div>
<div class="ttc" id="anamespacetflite_html"><div class="ttname"><a href="namespacetflite.html">tflite</a></div><div class="ttdef"><b>Definition</b> context_util.h:26</div></div>
<div class="ttc" id="awm8960__regs_8h_html_ace4e4903c356d90d7a0e7548fc1e8b50"><div class="ttname"><a href="wm8960__regs_8h.html#ace4e4903c356d90d7a0e7548fc1e8b50">shift</a></div><div class="ttdeci">const uint8_t shift</div><div class="ttdef"><b>Definition</b> wm8960_regs.h:95</div></div>
<div class="ttc" id="axtensa_2unidirectional__sequence__lstm_8cc_html_a58b1f1cca64a5f505e2170a29e471ae9"><div class="ttname"><a href="xtensa_2unidirectional__sequence__lstm_8cc.html#a58b1f1cca64a5f505e2170a29e471ae9">compute_row_sums</a></div><div class="ttdeci">bool compute_row_sums</div><div class="ttdef"><b>Definition</b> unidirectional_sequence_lstm.cc:44</div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.12.0
</small></address>
</div><!-- doc-content -->
</body>
</html>
