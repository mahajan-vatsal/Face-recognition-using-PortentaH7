<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.12.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Machine Vision using Portenta H7: The &lt;tt&gt;tflite_micro&lt;/tt&gt; Python Package</title>
<link rel="icon" href="logo.png" type="image/x-icon" />
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="logo.png"/></td>
  <td id="projectalign">
   <div id="projectname">Machine Vision using Portenta H7<span id="projectnumber">&#160;2</span>
   </div>
   <div id="projectbrief">This project aims to develop a face recognition-based access control system using the Arduino Portenta H7 and Vision Shield, leveraging Edge Impulse for machine learning. The system captures facial images, processes them locally using an AI model deployed on the Portenta H7 and determines access based on authorised personnel.</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.12.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search',false);
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){ initResizable(false); });
/* @license-end */
</script>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

</div><!-- top -->
<div id="doc-content">
<div><div class="header">
  <div class="headertitle"><div class="title">The &lt;tt&gt;tflite_micro&lt;/tt&gt; Python Package</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="autotoc_md113"></a></p>
<p>This directory contains the <code><a class="el" href="namespacetflite__micro.html">tflite_micro</a></code> Python package. The following is mainly documentation for its developers.</p>
<p>The <code><a class="el" href="namespacetflite__micro.html">tflite_micro</a></code> package contains a complete TFLM interpreter built as a CPython extension module. The build of simple Python packages may be driven by standard Python package builders such as <code>build</code>, <code>setuptools</code>, and <code>flit</code>; however, as TFLM is first and foremost a large C/C++ project, <code><a class="el" href="namespacetflite__micro.html">tflite_micro</a></code>'s build is instead driven by its C/C++ build system Bazel.</p>
<h1><a class="anchor" id="autotoc_md114"></a>
Building and installing locally</h1>
<h2><a class="anchor" id="autotoc_md115"></a>
Building</h2>
<p>The Bazel target <code>//python/tflite_micro:whl.dist</code> builds a <code><a class="el" href="namespacetflite__micro.html">tflite_micro</a></code> Python <em>.whl</em> under the output directory <code>bazel-bin/python/tflite_micro/whl_dist</code>. For example: </p><div class="fragment"><div class="line">% bazel build //python/tflite_micro:whl.dist</div>
<div class="line">....</div>
<div class="line">Target //python/tflite_micro:whl.dist up-to-date:</div>
<div class="line">  bazel-bin/python/tflite_micro/whl_dist</div>
<div class="line"> </div>
<div class="line">% tree bazel-bin/python/tflite_micro/whl_dist</div>
<div class="line">bazel-bin/python/tflite_micro/whl_dist</div>
<div class="line">└── tflite_micro-0.dev20230920161638-py3-none-any.whl</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md116"></a>
Installing</h2>
<p>Install the resulting <em>.whl</em> via pip. For example, in a Python virtual environment: </p><div class="fragment"><div class="line">% python3 -m venv ~/tmp/venv</div>
<div class="line">% source ~/tmp/venv/bin/activate</div>
<div class="line">(venv) $ pip install bazel-bin/python/tflite_micro/whl_dist/tflite_micro-0.dev20230920161638-py3-none-any.whl</div>
<div class="line">Processing ./bazel-bin/python/tflite_micro/whl_dist/tflite_micro-0.dev20230920161638-py3-none-any.whl</div>
<div class="line">....</div>
<div class="line">Installing collected packages: [....]</div>
</div><!-- fragment --><p>The package should now be importable and usable. For example: </p><div class="fragment"><div class="line">(venv) $ python</div>
<div class="line">Python 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0] on linux</div>
<div class="line">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</div>
<div class="line">&gt;&gt;&gt; import tflite_micro</div>
<div class="line">&gt;&gt;&gt; tflite_micro.postinstall_check.passed()</div>
<div class="line">True</div>
<div class="line">&gt;&gt;&gt;  i = tflite_micro.runtime.Interpreter.from_file(&quot;foo.tflite&quot;)</div>
<div class="line">&gt;&gt;&gt; # etc.</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md117"></a>
Building and uploading to PyPI</h1>
<p>The <em>.whl</em> generated above is unsuitable for distribution to the wider world via PyPI. The extension module is inevitably compiled against a particular Python implementation and platform C library. The resulting package is only binary-compatible with a system running the same Python implementation and a compatible (typically the same or newer) C library.</p>
<p>The solution is to distribute multiple *.whl*s, one built for each Python implementation and platform combination. TFLM accomplishes this by running Bazel builds from within multiple, uniquely configured Docker containers. The images used are based on standards-conforming images published by the Python Package Authority (PyPA) for exactly such use.</p>
<p>Python *.whl*s contain metadata used by installers such as <code>pip</code> to determine which distributions (*.whl*s) are compatible with the target platform. See the PyPA specification for <a href="https://packaging.python.org/en/latest/specifications/platform-compatibility-tags/">platform compatibility tags</a>.</p>
<h2><a class="anchor" id="autotoc_md118"></a>
Building</h2>
<p>In an environment with a working Docker installation, run the script <code>python/tflite_micro/pypi_build.sh &lt;python-tag&gt;</code> once for each tag. The script's online help (<code>--help</code>) lists the available tags. The script builds an appropriate Docker container and invokes a Bazel build and test within it. For example: </p><div class="fragment"><div class="line">% python/tflite_micro/pypi_build.sh cp310</div>
<div class="line">[+] Building 2.6s (7/7) FINISHED</div>
<div class="line">=&gt; writing image sha256:900704dad7fa27938dcc1c5057c0e760fb4ab0dff676415182455ae66546bbd4</div>
<div class="line">bazel build //python/tflite_micro:whl.dist \</div>
<div class="line">    --//python/tflite_micro:compatibility_tag=cp310_cp310_manylinux_2_28_x86_64</div>
<div class="line">bazel test //python/tflite_micro:whl_test \</div>
<div class="line">    --//python/tflite_micro:compatibility_tag=cp310_cp310_manylinux_2_28_x86_64</div>
<div class="line">//python/tflite_micro:whl_test</div>
<div class="line">Executed 1 out of 1 test: 1 test passes.</div>
<div class="line">Output:</div>
<div class="line">bazel-pypi-out/tflite_micro-0.dev20230920031310-cp310-cp310-manylinux_2_28_x86_64.whl</div>
</div><!-- fragment --><p>By default, *.whl*s are generated under the output directory <code>bazel-pypi-out/</code>.</p>
<h2><a class="anchor" id="autotoc_md119"></a>
Uploading to PyPI</h2>
<p>Upload the generated *.whl*s to PyPI with the script <code>python/tflite_micro/pypi_upload.sh</code>. This script lightly wraps the standard upload tool <code>twine</code>. A PyPI authentication token must be assigned to <code>TWINE_PASSWORD</code> in the environment. For example: </p><div class="fragment"><div class="line">% export TWINE_PASSWORD=pypi-AgENdGV[....]</div>
<div class="line">% ./python/tflite_micro/pypi_upload.sh --test-pypi bazel-pypi-out/tflite_micro-*.whl</div>
<div class="line">Uploading distributions to https://test.pypi.org/legacy/</div>
<div class="line">Uploading tflite_micro-0.dev20230920031310-cp310-cp310-manylinux_2_28_x86_64.whl</div>
<div class="line">Uploading tflite_micro-0.dev20230920031310-cp311-cp311-manylinux_2_28_x86_64.whl</div>
<div class="line">View at:</div>
<div class="line">https://test.pypi.org/project/tflite-micro/0.dev20230920031310/</div>
</div><!-- fragment --><p>See the script's online help (<code>--help</code>) for more.</p>
<h1><a class="anchor" id="autotoc_md120"></a>
Using <code>tflite_micro</code> from within the TFLM source tree</h1>
<p>:construction: <em>The remainder of this document is under construction and may contain some obsolete information.</em> :construction:</p>
<p>The only package that needs to be included in the <code><a class="el" href="namespace_b_u_i_l_d.html">BUILD</a></code> file is <code>//python/tflite_micro:runtime</code>. It contains all the correct dependencies to build the Python interpreter.</p>
<h2><a class="anchor" id="autotoc_md121"></a>
Examples</h2>
<p>Depending on the workflow, the package import path may be slightly different.</p>
<p>A simple end-to-end example is the test <code><a class="el" href="runtime__test_8py.html">python/tflite_micro/runtime_test.py</a>:testCompareWithTFLite()</code>. It shows how to compare inference results between TFLite and TFLM.</p>
<p>A basic usage of the TFLM Python interpreter looks like the following. The input to the Python interpreter should be a converted TFLite flatbuffer in either bytearray format or file format.</p>
<div class="fragment"><div class="line"># For the Bazel workflow</div>
<div class="line">from tflite_micro.python.tflite_micro import runtime</div>
<div class="line"> </div>
<div class="line"> </div>
<div class="line"># If model is a bytearray</div>
<div class="line">tflm_interpreter = runtime.Interpreter.from_bytes(model_data)</div>
<div class="line"># If model is a file</div>
<div class="line">tflm_interpreter = runtime.Interpreter.from_file(model_filepath)</div>
<div class="line"> </div>
<div class="line"># Run inference on TFLM using an ndarray `data_x`</div>
<div class="line">tflm_interpreter.set_input(data_x, 0)</div>
<div class="line">tflm_interpreter.invoke()</div>
<div class="line">tflm_output = tflm_interpreter.get_output(0)</div>
</div><!-- fragment --><p>Input and output tensor details can also be queried using the Python API:</p>
<div class="fragment"><div class="line">print(tflm_interpreter.get_input_details(0))</div>
<div class="line">print(tflm_interpreter.get_output_details(0))</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md122"></a>
Technical Details</h2>
<p>The Python interpreter uses <a href="https://github.com/pybind/pybind11">pybind11</a> to expose an evolving set of C++ APIs. The Bazel build leverages the <a href="https://github.com/pybind/pybind11_bazel">pybind11_bazel extension</a>.</p>
<p>The most updated Python APIs can be found in <code><a class="el" href="python_2tflite__micro_2runtime_8py.html">python/tflite_micro/runtime.py</a></code>.</p>
<h2><a class="anchor" id="autotoc_md123"></a>
Custom Ops</h2>
<p>The Python interpreter works with models with <a href="https://www.tensorflow.org/lite/guide/ops_custom">custom ops</a> but special steps need to be taken to make sure that it can retrieve the right implementation. This is currently compatible with the Bazel workflow only.</p>
<ol type="1">
<li>Implement the custom op in C++</li>
</ol>
<p>Assuming that the custom is already implemented according to the linked guide,</p>
<div class="fragment"><div class="line">// custom_op.cc</div>
<div class="line">TfLiteRegistration *Register_YOUR_CUSTOM_OP() {</div>
<div class="line">    // Do custom op stuff</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">// custom_op.h</div>
<div class="line">TfLiteRegistration *Register_YOUR_CUSTOM_OP();</div>
</div><!-- fragment --><ol type="1">
<li>Implement a custom op Registerer</li>
</ol>
<p>A Registerer of the following signature is required to wrap the custom op and add it to TFLM's ops resolver. For example,</p>
<div class="fragment"><div class="line">#include &quot;custom_op.h&quot;</div>
<div class="line">#include &quot;tensorflow/lite/micro/all_ops_resolver.h&quot;</div>
<div class="line"> </div>
<div class="line">namespace tflite {</div>
<div class="line"> </div>
<div class="line">extern &quot;C&quot; bool SomeCustomRegisterer(tflite::PythonOpsResolver* resolver) {</div>
<div class="line">    TfLiteStatus status = resolver-&gt;AddCustom(&quot;CustomOp&quot;, tflite::Register_YOUR_CUSTOM_OP());</div>
<div class="line">    if (status != kTfLiteOk) {</div>
<div class="line">        return false;</div>
<div class="line">    }</div>
<div class="line">    return true;</div>
<div class="line">}</div>
</div><!-- fragment --><ol type="1">
<li>Include the implementation of custom op and registerer in the caller's build</li>
</ol>
<p>For the Bazel workflow, it's recommended to create a package that includes the custom op's and the registerer's implementation, because it needs to be included in the target that calls the Python interpreter with custom ops.</p>
<ol type="1">
<li>Pass the registerer into the Python interpreter during instantiation</li>
</ol>
<p>For example,</p>
<div class="fragment"><div class="line">interpreter = runtime.Interpreter.from_file(</div>
<div class="line">    model_path=model_path,</div>
<div class="line">    custom_op_registerers=[&#39;SomeCustomRegisterer&#39;])</div>
</div><!-- fragment --><p>The interpreter will then perform a dynamic lookup for the symbol called <code>SomeCustomRegisterer()</code> and call it. This ensures that the custom op is properly included in TFLM's op resolver. This approach is very similar to TFLite's custom op support.</p>
<h2><a class="anchor" id="autotoc_md124"></a>
Print Allocations</h2>
<p>The Python interpreter can also be used to print memory arena allocations. This is very helpful to figure out actual memory arena usage.</p>
<p>For example,</p>
<div class="fragment"><div class="line">tflm_interpreter.print_allocations()</div>
</div><!-- fragment --><p>will print</p>
<div class="fragment"><div class="line">[RecordingMicroAllocator] Arena allocation total 10016 bytes</div>
<div class="line">[RecordingMicroAllocator] Arena allocation head 7744 bytes</div>
<div class="line">[RecordingMicroAllocator] Arena allocation tail 2272 bytes</div>
<div class="line">[RecordingMicroAllocator] &#39;TfLiteEvalTensor data&#39; used 312 bytes with alignment overhead (requested 312 bytes for 13 allocations)</div>
<div class="line">[RecordingMicroAllocator] &#39;Persistent TfLiteTensor data&#39; used 224 bytes with alignment overhead (requested 224 bytes for 2 tensors)</div>
<div class="line">[RecordingMicroAllocator] &#39;Persistent TfLiteTensor quantization data&#39; used 64 bytes with alignment overhead (requested 64 bytes for 4 allocations)</div>
<div class="line">[RecordingMicroAllocator] &#39;Persistent buffer data&#39; used 640 bytes with alignment overhead (requested 608 bytes for 10 allocations)</div>
<div class="line">[RecordingMicroAllocator] &#39;NodeAndRegistration struct&#39; used 440 bytes with alignment overhead (requested 440 bytes for 5 NodeAndRegistration structs)</div>
</div><!-- fragment --><p>10016 bytes is the actual memory arena size.</p>
<p>During instantiation via the class methods <code>runtime.Interpreter.from_file</code> or <code>runtime.Interpreter.from_bytes</code>, if <code>arena_size</code> is not explicitly specified, the interpreter will default to a heuristic which is 10x the model size. This can be adjusted manually if desired. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.12.0
</small></address>
</div><!-- doc-content -->
</body>
</html>
