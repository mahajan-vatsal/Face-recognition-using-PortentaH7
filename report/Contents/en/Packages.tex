\chapter{Packages}
\section{edge-impulse-sdk, Version 1.3.0}
\subsection{Introduction}
The \SHELL{edge-impulse-sdk} is a versatile library designed to run machine learning inferences on edge devices like the Portenta H7. In our face recognition project, this SDK allows us to deploy the model trained using Edge Impulse, simplifying the integration of AI into our system for real-time facial recognition tasks. \cite{edgeimpulse_cpp_library:2024}

\subsection{Installation}

To install the ‘edge-impulse-sdk‘, follow these steps:
\begin{itemize}
	\item Download the C++ library from the Edge Impulse Studio.
	\item Unzip the library into your project directory.
	\item Ensure you have a C compiler, a C++ compiler, and Make installed on your system.
\end{itemize}

For detailed instructions, refer to the \href{https://docs.edgeimpulse.com/doc}{Edge Impulse Documentation}.

\subsection{Example - Description}
This example demonstrates how to set up and use the ‘edge-impulse-sdk‘ to perform inference on raw sensor data. The setup involves creating a C++ project, integrating the SDK, and running the impulse to get the model’s output.


\subsection{Example - Manual}

\begin{enumerate}
	\item \textbf{Create a Project:} Set up a directory for your project and unzip the C++ library.
	
	\item \textbf{Write Code:} Create a main application file (\texttt{main.cpp}) that includes the necessary headers and defines the main function to run the classifier.
	
	\item \textbf{Build the Project:} Use \texttt{Make} to compile the project and generate the executable.
	
	\item \textbf{Run Inference:} Execute the program to run inference on the test data.
\end{enumerate}

\subsection{Example - code}
Here is a simple example ~\ref{ExampleCode_EdgeImpulseSDK.ino} of a main.cpp file:


{
	\captionof{code}{Package exmaple code}\label{ExampleCode_EdgeImpulseSDK.ino}
	\ArduinoExternal{}{../Code/EdgeImpulse/Packages/ExampleCodeSDK.ino}
}


\subsection{Future Reading}
For more information on deploying your model as a C++ library, check the \href{https://docs.edgeimpulse.com/docs/run-inference/cpp-library/deploy-your-model-as-a-c-library}{Edge Impulse Documentation}

\newpage
\section{TensorFlow Lite, Version 2.12.0}
\subsection{Introduction}
TensorFlow Lite is a lightweight solution for deploying machine learning models on mobile and embedded devices. It is designed to run TensorFlow models on resource-constrained devices with low latency and high efficiency. \cite{tensorflowLiteGuide:2024}


\subsection{Installation}
To install TensorFlow Lite, run \SHELL{pip install tensorflow} in command prompt window, refer ~\ref{tf_install}

\subsection{Example - Description}
This example demonstrates how to use TensorFlow Lite to perform image classification on a mobile device. The steps include loading a model, preprocessing input data, running inference, and interpreting the results.

\subsection{Example - Manual}
The manual steps for running a TensorFlow Lite model include:
\begin{enumerate}
	\item Convert the TensorFlow model to TensorFlow Lite format.
	\item Load the TensorFlow Lite model on the device.
	\item Preprocess the input data to match the model’s requirements.
	\item Use the TensorFlow Lite interpreter to run the model.
	\item Postprocess the results to interpret the model’s output.
\end{enumerate}

\subsection{Example - Code}

{
	\captionof{code}{Example Code for running Tensorflow Lite model.}\label{ExampleCode_TensorFlow.ino}
	\ArduinoExternal{}{../Code/EdgeImpulse/Packages/ExampleCodeTensorFlow.ino}
}



	
\subsection{Example - Files}
The example files include:
\begin{itemize}
	\item \texttt{model.tflite} - The TensorFlow Lite model file.
	\item \texttt{image.jpg} - The input image file for inference.
	\item \texttt{tflite\_example.py} - The Python script to run the model.
\end{itemize}

\subsection{Futher reading}
For more detailed information, refer to the TensorFlow Lite documentation:
\begin{itemize}
		\item \href{https://www.tensorflow.org/lite/guide}{TensorFlow Lite Guide}.
		\item \href{https://www.tensorflow.org/lite/models}{TensorFlow Lite Models}.
		\item \href{https://www.tensorflow.org/lite/convert}{TensorFlow Lite Conversion}.
	
\end{itemize}


